[10/29 16:58:47] detectron2 INFO: Rank of current process: 1. World size: 4
[10/29 16:58:47] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/29 16:58:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[10/29 16:58:47] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("openvocab_pascal20_sem_seg_val",[39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[10/29 16:59:04] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[10/29 16:59:04] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[10/29 16:59:04] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[10/29 16:59:04] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[10/29 16:59:04] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/29 16:59:04] detectron2.data.common INFO: Serializing 1449 elements to byte tensors and concatenating them all ...
[10/29 16:59:04] detectron2.data.common INFO: Serialized dataset takes 1.38 MiB
[10/29 16:59:05] detectron2.evaluation.evaluator INFO: Start inference on 362 batches
[10/29 16:59:18] detectron2.evaluation.evaluator INFO: Inference done 1/362. Dataloading: 7.9787 s/iter. Inference: 5.4377 s/iter. Eval: 0.0145 s/iter. Total: 13.4334 s/iter. ETA=1:20:49
[10/29 16:59:23] detectron2.evaluation.evaluator INFO: Inference done 15/362. Dataloading: 0.0021 s/iter. Inference: 0.3393 s/iter. Eval: 0.0106 s/iter. Total: 0.3519 s/iter. ETA=0:02:02
[10/29 16:59:28] detectron2.evaluation.evaluator INFO: Inference done 30/362. Dataloading: 0.0022 s/iter. Inference: 0.3396 s/iter. Eval: 0.0103 s/iter. Total: 0.3528 s/iter. ETA=0:01:57
[10/29 16:59:34] detectron2.evaluation.evaluator INFO: Inference done 45/362. Dataloading: 0.0022 s/iter. Inference: 0.3402 s/iter. Eval: 0.0102 s/iter. Total: 0.3531 s/iter. ETA=0:01:51
[10/29 16:59:39] detectron2.evaluation.evaluator INFO: Inference done 59/362. Dataloading: 0.0022 s/iter. Inference: 0.3431 s/iter. Eval: 0.0100 s/iter. Total: 0.3556 s/iter. ETA=0:01:47
[10/29 16:59:44] detectron2.evaluation.evaluator INFO: Inference done 74/362. Dataloading: 0.0022 s/iter. Inference: 0.3423 s/iter. Eval: 0.0101 s/iter. Total: 0.3549 s/iter. ETA=0:01:42
[10/29 16:59:49] detectron2.evaluation.evaluator INFO: Inference done 89/362. Dataloading: 0.0022 s/iter. Inference: 0.3413 s/iter. Eval: 0.0098 s/iter. Total: 0.3536 s/iter. ETA=0:01:36
[10/29 16:59:54] detectron2.evaluation.evaluator INFO: Inference done 104/362. Dataloading: 0.0022 s/iter. Inference: 0.3413 s/iter. Eval: 0.0096 s/iter. Total: 0.3534 s/iter. ETA=0:01:31
[10/29 16:59:59] detectron2.evaluation.evaluator INFO: Inference done 118/362. Dataloading: 0.0022 s/iter. Inference: 0.3423 s/iter. Eval: 0.0096 s/iter. Total: 0.3543 s/iter. ETA=0:01:26
[10/29 17:00:05] detectron2.evaluation.evaluator INFO: Inference done 133/362. Dataloading: 0.0022 s/iter. Inference: 0.3416 s/iter. Eval: 0.0097 s/iter. Total: 0.3537 s/iter. ETA=0:01:21
[10/29 17:00:10] detectron2.evaluation.evaluator INFO: Inference done 147/362. Dataloading: 0.0022 s/iter. Inference: 0.3439 s/iter. Eval: 0.0096 s/iter. Total: 0.3559 s/iter. ETA=0:01:16
[10/29 17:00:15] detectron2.evaluation.evaluator INFO: Inference done 161/362. Dataloading: 0.0022 s/iter. Inference: 0.3448 s/iter. Eval: 0.0096 s/iter. Total: 0.3568 s/iter. ETA=0:01:11
[10/29 17:00:20] detectron2.evaluation.evaluator INFO: Inference done 175/362. Dataloading: 0.0022 s/iter. Inference: 0.3457 s/iter. Eval: 0.0096 s/iter. Total: 0.3577 s/iter. ETA=0:01:06
[10/29 17:00:25] detectron2.evaluation.evaluator INFO: Inference done 189/362. Dataloading: 0.0022 s/iter. Inference: 0.3469 s/iter. Eval: 0.0096 s/iter. Total: 0.3589 s/iter. ETA=0:01:02
[10/29 17:00:31] detectron2.evaluation.evaluator INFO: Inference done 203/362. Dataloading: 0.0023 s/iter. Inference: 0.3476 s/iter. Eval: 0.0096 s/iter. Total: 0.3596 s/iter. ETA=0:00:57
[10/29 17:00:36] detectron2.evaluation.evaluator INFO: Inference done 217/362. Dataloading: 0.0023 s/iter. Inference: 0.3486 s/iter. Eval: 0.0096 s/iter. Total: 0.3606 s/iter. ETA=0:00:52
[10/29 17:00:41] detectron2.evaluation.evaluator INFO: Inference done 231/362. Dataloading: 0.0023 s/iter. Inference: 0.3487 s/iter. Eval: 0.0096 s/iter. Total: 0.3608 s/iter. ETA=0:00:47
[10/29 17:00:46] detectron2.evaluation.evaluator INFO: Inference done 245/362. Dataloading: 0.0022 s/iter. Inference: 0.3495 s/iter. Eval: 0.0096 s/iter. Total: 0.3615 s/iter. ETA=0:00:42
[10/29 17:00:51] detectron2.evaluation.evaluator INFO: Inference done 259/362. Dataloading: 0.0022 s/iter. Inference: 0.3499 s/iter. Eval: 0.0096 s/iter. Total: 0.3618 s/iter. ETA=0:00:37
[10/29 17:00:56] detectron2.evaluation.evaluator INFO: Inference done 273/362. Dataloading: 0.0022 s/iter. Inference: 0.3500 s/iter. Eval: 0.0096 s/iter. Total: 0.3619 s/iter. ETA=0:00:32
[10/29 17:01:02] detectron2.evaluation.evaluator INFO: Inference done 287/362. Dataloading: 0.0022 s/iter. Inference: 0.3506 s/iter. Eval: 0.0096 s/iter. Total: 0.3625 s/iter. ETA=0:00:27
[10/29 17:01:07] detectron2.evaluation.evaluator INFO: Inference done 301/362. Dataloading: 0.0022 s/iter. Inference: 0.3508 s/iter. Eval: 0.0096 s/iter. Total: 0.3627 s/iter. ETA=0:00:22
[10/29 17:01:12] detectron2.evaluation.evaluator INFO: Inference done 315/362. Dataloading: 0.0022 s/iter. Inference: 0.3508 s/iter. Eval: 0.0096 s/iter. Total: 0.3627 s/iter. ETA=0:00:17
[10/29 17:01:17] detectron2.evaluation.evaluator INFO: Inference done 329/362. Dataloading: 0.0022 s/iter. Inference: 0.3518 s/iter. Eval: 0.0095 s/iter. Total: 0.3637 s/iter. ETA=0:00:12
[10/29 17:01:23] detectron2.evaluation.evaluator INFO: Inference done 344/362. Dataloading: 0.0022 s/iter. Inference: 0.3515 s/iter. Eval: 0.0095 s/iter. Total: 0.3634 s/iter. ETA=0:00:06
[10/29 17:01:28] detectron2.evaluation.evaluator INFO: Inference done 358/362. Dataloading: 0.0022 s/iter. Inference: 0.3519 s/iter. Eval: 0.0095 s/iter. Total: 0.3638 s/iter. ETA=0:00:01
[10/29 17:01:31] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:11.400941 (0.368070 s / iter per device, on 4 devices)
[10/29 17:01:31] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:05 (0.352195 s / iter per device, on 4 devices)
[10/29 17:01:40] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[10/29 17:01:40] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/29 17:01:40] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[10/29 17:01:40] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[10/29 17:01:40] detectron2.evaluation.evaluator INFO: Start inference on 500 batches
[10/29 17:03:15] detectron2.evaluation.evaluator INFO: Inference done 1/500. Dataloading: 7.5254 s/iter. Inference: 86.9475 s/iter. Eval: 0.0353 s/iter. Total: 94.5115 s/iter. ETA=13:06:01
[10/29 17:03:20] detectron2.evaluation.evaluator INFO: Inference done 14/500. Dataloading: 0.0020 s/iter. Inference: 0.3702 s/iter. Eval: 0.0250 s/iter. Total: 0.3973 s/iter. ETA=0:03:13
[10/29 17:03:25] detectron2.evaluation.evaluator INFO: Inference done 26/500. Dataloading: 0.0024 s/iter. Inference: 0.3806 s/iter. Eval: 0.0293 s/iter. Total: 0.4124 s/iter. ETA=0:03:15
[10/29 17:03:31] detectron2.evaluation.evaluator INFO: Inference done 39/500. Dataloading: 0.0024 s/iter. Inference: 0.3790 s/iter. Eval: 0.0283 s/iter. Total: 0.4098 s/iter. ETA=0:03:08
[10/29 17:03:36] detectron2.evaluation.evaluator INFO: Inference done 52/500. Dataloading: 0.0024 s/iter. Inference: 0.3779 s/iter. Eval: 0.0273 s/iter. Total: 0.4077 s/iter. ETA=0:03:02
[10/29 17:03:41] detectron2.evaluation.evaluator INFO: Inference done 68/500. Dataloading: 0.0024 s/iter. Inference: 0.3608 s/iter. Eval: 0.0249 s/iter. Total: 0.3881 s/iter. ETA=0:02:47
[10/29 17:03:46] detectron2.evaluation.evaluator INFO: Inference done 81/500. Dataloading: 0.0024 s/iter. Inference: 0.3615 s/iter. Eval: 0.0258 s/iter. Total: 0.3897 s/iter. ETA=0:02:43
[10/29 17:03:51] detectron2.evaluation.evaluator INFO: Inference done 94/500. Dataloading: 0.0024 s/iter. Inference: 0.3617 s/iter. Eval: 0.0260 s/iter. Total: 0.3902 s/iter. ETA=0:02:38
[10/29 17:03:56] detectron2.evaluation.evaluator INFO: Inference done 107/500. Dataloading: 0.0024 s/iter. Inference: 0.3617 s/iter. Eval: 0.0258 s/iter. Total: 0.3899 s/iter. ETA=0:02:33
[10/29 17:04:02] detectron2.evaluation.evaluator INFO: Inference done 122/500. Dataloading: 0.0024 s/iter. Inference: 0.3573 s/iter. Eval: 0.0244 s/iter. Total: 0.3841 s/iter. ETA=0:02:25
[10/29 17:04:07] detectron2.evaluation.evaluator INFO: Inference done 136/500. Dataloading: 0.0024 s/iter. Inference: 0.3564 s/iter. Eval: 0.0234 s/iter. Total: 0.3822 s/iter. ETA=0:02:19
[10/29 17:04:12] detectron2.evaluation.evaluator INFO: Inference done 150/500. Dataloading: 0.0024 s/iter. Inference: 0.3553 s/iter. Eval: 0.0229 s/iter. Total: 0.3806 s/iter. ETA=0:02:13
[10/29 17:04:17] detectron2.evaluation.evaluator INFO: Inference done 163/500. Dataloading: 0.0024 s/iter. Inference: 0.3562 s/iter. Eval: 0.0226 s/iter. Total: 0.3812 s/iter. ETA=0:02:08
[10/29 17:04:22] detectron2.evaluation.evaluator INFO: Inference done 176/500. Dataloading: 0.0024 s/iter. Inference: 0.3587 s/iter. Eval: 0.0223 s/iter. Total: 0.3835 s/iter. ETA=0:02:04
[10/29 17:04:27] detectron2.evaluation.evaluator INFO: Inference done 190/500. Dataloading: 0.0024 s/iter. Inference: 0.3586 s/iter. Eval: 0.0221 s/iter. Total: 0.3831 s/iter. ETA=0:01:58
[10/29 17:04:33] detectron2.evaluation.evaluator INFO: Inference done 204/500. Dataloading: 0.0024 s/iter. Inference: 0.3580 s/iter. Eval: 0.0221 s/iter. Total: 0.3826 s/iter. ETA=0:01:53
[10/29 17:04:38] detectron2.evaluation.evaluator INFO: Inference done 217/500. Dataloading: 0.0024 s/iter. Inference: 0.3593 s/iter. Eval: 0.0220 s/iter. Total: 0.3837 s/iter. ETA=0:01:48
[10/29 17:04:43] detectron2.evaluation.evaluator INFO: Inference done 231/500. Dataloading: 0.0024 s/iter. Inference: 0.3590 s/iter. Eval: 0.0216 s/iter. Total: 0.3831 s/iter. ETA=0:01:43
[10/29 17:04:48] detectron2.evaluation.evaluator INFO: Inference done 245/500. Dataloading: 0.0024 s/iter. Inference: 0.3585 s/iter. Eval: 0.0213 s/iter. Total: 0.3822 s/iter. ETA=0:01:37
[10/29 17:04:53] detectron2.evaluation.evaluator INFO: Inference done 261/500. Dataloading: 0.0024 s/iter. Inference: 0.3550 s/iter. Eval: 0.0209 s/iter. Total: 0.3783 s/iter. ETA=0:01:30
[10/29 17:04:59] detectron2.evaluation.evaluator INFO: Inference done 278/500. Dataloading: 0.0024 s/iter. Inference: 0.3517 s/iter. Eval: 0.0205 s/iter. Total: 0.3747 s/iter. ETA=0:01:23
[10/29 17:05:04] detectron2.evaluation.evaluator INFO: Inference done 291/500. Dataloading: 0.0024 s/iter. Inference: 0.3523 s/iter. Eval: 0.0207 s/iter. Total: 0.3755 s/iter. ETA=0:01:18
[10/29 17:05:09] detectron2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0024 s/iter. Inference: 0.3528 s/iter. Eval: 0.0210 s/iter. Total: 0.3762 s/iter. ETA=0:01:13
[10/29 17:05:14] detectron2.evaluation.evaluator INFO: Inference done 317/500. Dataloading: 0.0024 s/iter. Inference: 0.3532 s/iter. Eval: 0.0212 s/iter. Total: 0.3769 s/iter. ETA=0:01:08
[10/29 17:05:19] detectron2.evaluation.evaluator INFO: Inference done 330/500. Dataloading: 0.0024 s/iter. Inference: 0.3535 s/iter. Eval: 0.0214 s/iter. Total: 0.3774 s/iter. ETA=0:01:04
[10/29 17:05:24] detectron2.evaluation.evaluator INFO: Inference done 343/500. Dataloading: 0.0024 s/iter. Inference: 0.3542 s/iter. Eval: 0.0216 s/iter. Total: 0.3782 s/iter. ETA=0:00:59
[10/29 17:05:29] detectron2.evaluation.evaluator INFO: Inference done 356/500. Dataloading: 0.0024 s/iter. Inference: 0.3545 s/iter. Eval: 0.0217 s/iter. Total: 0.3787 s/iter. ETA=0:00:54
[10/29 17:05:35] detectron2.evaluation.evaluator INFO: Inference done 375/500. Dataloading: 0.0024 s/iter. Inference: 0.3500 s/iter. Eval: 0.0212 s/iter. Total: 0.3736 s/iter. ETA=0:00:46
[10/29 17:05:40] detectron2.evaluation.evaluator INFO: Inference done 389/500. Dataloading: 0.0024 s/iter. Inference: 0.3504 s/iter. Eval: 0.0210 s/iter. Total: 0.3738 s/iter. ETA=0:00:41
[10/29 17:05:45] detectron2.evaluation.evaluator INFO: Inference done 404/500. Dataloading: 0.0024 s/iter. Inference: 0.3492 s/iter. Eval: 0.0208 s/iter. Total: 0.3725 s/iter. ETA=0:00:35
[10/29 17:05:50] detectron2.evaluation.evaluator INFO: Inference done 418/500. Dataloading: 0.0024 s/iter. Inference: 0.3495 s/iter. Eval: 0.0207 s/iter. Total: 0.3727 s/iter. ETA=0:00:30
[10/29 17:05:56] detectron2.evaluation.evaluator INFO: Inference done 431/500. Dataloading: 0.0024 s/iter. Inference: 0.3501 s/iter. Eval: 0.0207 s/iter. Total: 0.3732 s/iter. ETA=0:00:25
[10/29 17:06:01] detectron2.evaluation.evaluator INFO: Inference done 444/500. Dataloading: 0.0024 s/iter. Inference: 0.3504 s/iter. Eval: 0.0208 s/iter. Total: 0.3737 s/iter. ETA=0:00:20
[10/29 17:06:06] detectron2.evaluation.evaluator INFO: Inference done 459/500. Dataloading: 0.0024 s/iter. Inference: 0.3495 s/iter. Eval: 0.0207 s/iter. Total: 0.3727 s/iter. ETA=0:00:15
[10/29 17:06:11] detectron2.evaluation.evaluator INFO: Inference done 472/500. Dataloading: 0.0024 s/iter. Inference: 0.3500 s/iter. Eval: 0.0209 s/iter. Total: 0.3734 s/iter. ETA=0:00:10
[10/29 17:06:16] detectron2.evaluation.evaluator INFO: Inference done 487/500. Dataloading: 0.0024 s/iter. Inference: 0.3491 s/iter. Eval: 0.0208 s/iter. Total: 0.3723 s/iter. ETA=0:00:04
[10/29 17:06:22] detectron2.evaluation.evaluator INFO: Total inference time: 0:03:05.610552 (0.374971 s / iter per device, on 4 devices)
[10/29 17:06:22] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:52 (0.348515 s / iter per device, on 4 devices)
[10/29 17:06:47] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[10/29 17:06:47] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/29 17:06:47] detectron2.data.common INFO: Serializing 5104 elements to byte tensors and concatenating them all ...
[10/29 17:06:47] detectron2.data.common INFO: Serialized dataset takes 39.02 MiB
[10/29 17:06:47] detectron2.evaluation.evaluator INFO: Start inference on 1276 batches
[10/29 17:07:30] detectron2.evaluation.evaluator INFO: Inference done 1/1276. Dataloading: 6.0900 s/iter. Inference: 36.5288 s/iter. Eval: 0.0119 s/iter. Total: 42.6331 s/iter. ETA=15:05:57
[10/29 17:07:35] detectron2.evaluation.evaluator INFO: Inference done 14/1276. Dataloading: 0.0019 s/iter. Inference: 0.3662 s/iter. Eval: 0.0127 s/iter. Total: 0.3808 s/iter. ETA=0:08:00
[10/29 17:07:40] detectron2.evaluation.evaluator INFO: Inference done 28/1276. Dataloading: 0.0022 s/iter. Inference: 0.3593 s/iter. Eval: 0.0129 s/iter. Total: 0.3744 s/iter. ETA=0:07:47
[10/29 17:07:45] detectron2.evaluation.evaluator INFO: Inference done 42/1276. Dataloading: 0.0022 s/iter. Inference: 0.3587 s/iter. Eval: 0.0127 s/iter. Total: 0.3737 s/iter. ETA=0:07:41
[10/29 17:07:50] detectron2.evaluation.evaluator INFO: Inference done 55/1276. Dataloading: 0.0024 s/iter. Inference: 0.3623 s/iter. Eval: 0.0127 s/iter. Total: 0.3774 s/iter. ETA=0:07:40
[10/29 17:07:55] detectron2.evaluation.evaluator INFO: Inference done 68/1276. Dataloading: 0.0025 s/iter. Inference: 0.3639 s/iter. Eval: 0.0128 s/iter. Total: 0.3792 s/iter. ETA=0:07:38
[10/29 17:08:01] detectron2.evaluation.evaluator INFO: Inference done 82/1276. Dataloading: 0.0025 s/iter. Inference: 0.3637 s/iter. Eval: 0.0129 s/iter. Total: 0.3792 s/iter. ETA=0:07:32
[10/29 17:08:06] detectron2.evaluation.evaluator INFO: Inference done 96/1276. Dataloading: 0.0025 s/iter. Inference: 0.3624 s/iter. Eval: 0.0127 s/iter. Total: 0.3777 s/iter. ETA=0:07:25
[10/29 17:08:11] detectron2.evaluation.evaluator INFO: Inference done 110/1276. Dataloading: 0.0024 s/iter. Inference: 0.3642 s/iter. Eval: 0.0125 s/iter. Total: 0.3793 s/iter. ETA=0:07:22
[10/29 17:08:17] detectron2.evaluation.evaluator INFO: Inference done 124/1276. Dataloading: 0.0024 s/iter. Inference: 0.3631 s/iter. Eval: 0.0125 s/iter. Total: 0.3781 s/iter. ETA=0:07:15
[10/29 17:08:22] detectron2.evaluation.evaluator INFO: Inference done 137/1276. Dataloading: 0.0024 s/iter. Inference: 0.3647 s/iter. Eval: 0.0125 s/iter. Total: 0.3796 s/iter. ETA=0:07:12
[10/29 17:08:27] detectron2.evaluation.evaluator INFO: Inference done 151/1276. Dataloading: 0.0024 s/iter. Inference: 0.3631 s/iter. Eval: 0.0125 s/iter. Total: 0.3781 s/iter. ETA=0:07:05
[10/29 17:08:32] detectron2.evaluation.evaluator INFO: Inference done 164/1276. Dataloading: 0.0024 s/iter. Inference: 0.3639 s/iter. Eval: 0.0124 s/iter. Total: 0.3788 s/iter. ETA=0:07:01
[10/29 17:08:37] detectron2.evaluation.evaluator INFO: Inference done 178/1276. Dataloading: 0.0024 s/iter. Inference: 0.3639 s/iter. Eval: 0.0124 s/iter. Total: 0.3788 s/iter. ETA=0:06:55
[10/29 17:08:42] detectron2.evaluation.evaluator INFO: Inference done 192/1276. Dataloading: 0.0024 s/iter. Inference: 0.3634 s/iter. Eval: 0.0125 s/iter. Total: 0.3783 s/iter. ETA=0:06:50
[10/29 17:08:48] detectron2.evaluation.evaluator INFO: Inference done 206/1276. Dataloading: 0.0024 s/iter. Inference: 0.3635 s/iter. Eval: 0.0125 s/iter. Total: 0.3784 s/iter. ETA=0:06:44
[10/29 17:08:53] detectron2.evaluation.evaluator INFO: Inference done 219/1276. Dataloading: 0.0024 s/iter. Inference: 0.3643 s/iter. Eval: 0.0125 s/iter. Total: 0.3792 s/iter. ETA=0:06:40
[10/29 17:08:58] detectron2.evaluation.evaluator INFO: Inference done 233/1276. Dataloading: 0.0024 s/iter. Inference: 0.3631 s/iter. Eval: 0.0125 s/iter. Total: 0.3781 s/iter. ETA=0:06:34
[10/29 17:09:03] detectron2.evaluation.evaluator INFO: Inference done 247/1276. Dataloading: 0.0024 s/iter. Inference: 0.3633 s/iter. Eval: 0.0125 s/iter. Total: 0.3782 s/iter. ETA=0:06:29
[10/29 17:09:08] detectron2.evaluation.evaluator INFO: Inference done 261/1276. Dataloading: 0.0024 s/iter. Inference: 0.3632 s/iter. Eval: 0.0126 s/iter. Total: 0.3782 s/iter. ETA=0:06:23
[10/29 17:09:14] detectron2.evaluation.evaluator INFO: Inference done 275/1276. Dataloading: 0.0024 s/iter. Inference: 0.3630 s/iter. Eval: 0.0125 s/iter. Total: 0.3780 s/iter. ETA=0:06:18
[10/29 17:09:19] detectron2.evaluation.evaluator INFO: Inference done 289/1276. Dataloading: 0.0024 s/iter. Inference: 0.3629 s/iter. Eval: 0.0126 s/iter. Total: 0.3779 s/iter. ETA=0:06:12
[10/29 17:09:24] detectron2.evaluation.evaluator INFO: Inference done 302/1276. Dataloading: 0.0024 s/iter. Inference: 0.3636 s/iter. Eval: 0.0126 s/iter. Total: 0.3786 s/iter. ETA=0:06:08
[10/29 17:09:29] detectron2.evaluation.evaluator INFO: Inference done 316/1276. Dataloading: 0.0024 s/iter. Inference: 0.3633 s/iter. Eval: 0.0126 s/iter. Total: 0.3784 s/iter. ETA=0:06:03
[10/29 17:09:34] detectron2.evaluation.evaluator INFO: Inference done 330/1276. Dataloading: 0.0024 s/iter. Inference: 0.3633 s/iter. Eval: 0.0125 s/iter. Total: 0.3783 s/iter. ETA=0:05:57
[10/29 17:09:40] detectron2.evaluation.evaluator INFO: Inference done 344/1276. Dataloading: 0.0024 s/iter. Inference: 0.3635 s/iter. Eval: 0.0125 s/iter. Total: 0.3784 s/iter. ETA=0:05:52
[10/29 17:09:45] detectron2.evaluation.evaluator INFO: Inference done 358/1276. Dataloading: 0.0024 s/iter. Inference: 0.3636 s/iter. Eval: 0.0125 s/iter. Total: 0.3785 s/iter. ETA=0:05:47
[10/29 17:09:50] detectron2.evaluation.evaluator INFO: Inference done 372/1276. Dataloading: 0.0024 s/iter. Inference: 0.3629 s/iter. Eval: 0.0125 s/iter. Total: 0.3778 s/iter. ETA=0:05:41
[10/29 17:09:55] detectron2.evaluation.evaluator INFO: Inference done 385/1276. Dataloading: 0.0024 s/iter. Inference: 0.3634 s/iter. Eval: 0.0125 s/iter. Total: 0.3783 s/iter. ETA=0:05:37
[10/29 17:10:01] detectron2.evaluation.evaluator INFO: Inference done 399/1276. Dataloading: 0.0024 s/iter. Inference: 0.3633 s/iter. Eval: 0.0125 s/iter. Total: 0.3782 s/iter. ETA=0:05:31
[10/29 17:10:06] detectron2.evaluation.evaluator INFO: Inference done 413/1276. Dataloading: 0.0024 s/iter. Inference: 0.3632 s/iter. Eval: 0.0125 s/iter. Total: 0.3781 s/iter. ETA=0:05:26
[10/29 17:10:11] detectron2.evaluation.evaluator INFO: Inference done 427/1276. Dataloading: 0.0024 s/iter. Inference: 0.3628 s/iter. Eval: 0.0125 s/iter. Total: 0.3777 s/iter. ETA=0:05:20
[10/29 17:10:16] detectron2.evaluation.evaluator INFO: Inference done 440/1276. Dataloading: 0.0024 s/iter. Inference: 0.3632 s/iter. Eval: 0.0126 s/iter. Total: 0.3782 s/iter. ETA=0:05:16
[10/29 17:10:21] detectron2.evaluation.evaluator INFO: Inference done 453/1276. Dataloading: 0.0024 s/iter. Inference: 0.3636 s/iter. Eval: 0.0125 s/iter. Total: 0.3785 s/iter. ETA=0:05:11
[10/29 17:10:26] detectron2.evaluation.evaluator INFO: Inference done 467/1276. Dataloading: 0.0024 s/iter. Inference: 0.3633 s/iter. Eval: 0.0125 s/iter. Total: 0.3782 s/iter. ETA=0:05:05
[10/29 17:10:32] detectron2.evaluation.evaluator INFO: Inference done 481/1276. Dataloading: 0.0024 s/iter. Inference: 0.3631 s/iter. Eval: 0.0125 s/iter. Total: 0.3781 s/iter. ETA=0:05:00
[10/29 17:10:37] detectron2.evaluation.evaluator INFO: Inference done 495/1276. Dataloading: 0.0024 s/iter. Inference: 0.3628 s/iter. Eval: 0.0125 s/iter. Total: 0.3778 s/iter. ETA=0:04:55
[10/29 17:10:42] detectron2.evaluation.evaluator INFO: Inference done 509/1276. Dataloading: 0.0024 s/iter. Inference: 0.3629 s/iter. Eval: 0.0125 s/iter. Total: 0.3778 s/iter. ETA=0:04:49
[10/29 17:10:47] detectron2.evaluation.evaluator INFO: Inference done 522/1276. Dataloading: 0.0024 s/iter. Inference: 0.3631 s/iter. Eval: 0.0125 s/iter. Total: 0.3780 s/iter. ETA=0:04:45
[10/29 17:10:52] detectron2.evaluation.evaluator INFO: Inference done 535/1276. Dataloading: 0.0024 s/iter. Inference: 0.3636 s/iter. Eval: 0.0125 s/iter. Total: 0.3785 s/iter. ETA=0:04:40
[10/29 17:10:57] detectron2.evaluation.evaluator INFO: Inference done 549/1276. Dataloading: 0.0024 s/iter. Inference: 0.3635 s/iter. Eval: 0.0125 s/iter. Total: 0.3784 s/iter. ETA=0:04:35
[10/29 17:11:03] detectron2.evaluation.evaluator INFO: Inference done 563/1276. Dataloading: 0.0024 s/iter. Inference: 0.3635 s/iter. Eval: 0.0125 s/iter. Total: 0.3785 s/iter. ETA=0:04:29
[10/29 17:11:08] detectron2.evaluation.evaluator INFO: Inference done 578/1276. Dataloading: 0.0024 s/iter. Inference: 0.3631 s/iter. Eval: 0.0125 s/iter. Total: 0.3780 s/iter. ETA=0:04:23
[10/29 17:11:13] detectron2.evaluation.evaluator INFO: Inference done 592/1276. Dataloading: 0.0024 s/iter. Inference: 0.3628 s/iter. Eval: 0.0125 s/iter. Total: 0.3777 s/iter. ETA=0:04:18
[10/29 17:11:19] detectron2.evaluation.evaluator INFO: Inference done 606/1276. Dataloading: 0.0024 s/iter. Inference: 0.3629 s/iter. Eval: 0.0125 s/iter. Total: 0.3778 s/iter. ETA=0:04:13
[10/29 17:11:24] detectron2.evaluation.evaluator INFO: Inference done 620/1276. Dataloading: 0.0024 s/iter. Inference: 0.3629 s/iter. Eval: 0.0125 s/iter. Total: 0.3778 s/iter. ETA=0:04:07
[10/29 17:11:29] detectron2.evaluation.evaluator INFO: Inference done 634/1276. Dataloading: 0.0024 s/iter. Inference: 0.3626 s/iter. Eval: 0.0125 s/iter. Total: 0.3775 s/iter. ETA=0:04:02
[10/29 17:11:34] detectron2.evaluation.evaluator INFO: Inference done 648/1276. Dataloading: 0.0023 s/iter. Inference: 0.3626 s/iter. Eval: 0.0125 s/iter. Total: 0.3775 s/iter. ETA=0:03:57
[10/29 17:11:39] detectron2.evaluation.evaluator INFO: Inference done 662/1276. Dataloading: 0.0023 s/iter. Inference: 0.3624 s/iter. Eval: 0.0125 s/iter. Total: 0.3774 s/iter. ETA=0:03:51
[10/29 17:11:45] detectron2.evaluation.evaluator INFO: Inference done 675/1276. Dataloading: 0.0023 s/iter. Inference: 0.3627 s/iter. Eval: 0.0125 s/iter. Total: 0.3776 s/iter. ETA=0:03:46
[10/29 17:11:50] detectron2.evaluation.evaluator INFO: Inference done 689/1276. Dataloading: 0.0023 s/iter. Inference: 0.3625 s/iter. Eval: 0.0125 s/iter. Total: 0.3774 s/iter. ETA=0:03:41
[10/29 17:11:55] detectron2.evaluation.evaluator INFO: Inference done 703/1276. Dataloading: 0.0023 s/iter. Inference: 0.3625 s/iter. Eval: 0.0125 s/iter. Total: 0.3775 s/iter. ETA=0:03:36
[10/29 17:12:00] detectron2.evaluation.evaluator INFO: Inference done 717/1276. Dataloading: 0.0023 s/iter. Inference: 0.3623 s/iter. Eval: 0.0125 s/iter. Total: 0.3772 s/iter. ETA=0:03:30
[10/29 17:12:05] detectron2.evaluation.evaluator INFO: Inference done 732/1276. Dataloading: 0.0023 s/iter. Inference: 0.3616 s/iter. Eval: 0.0125 s/iter. Total: 0.3765 s/iter. ETA=0:03:24
[10/29 17:12:10] detectron2.evaluation.evaluator INFO: Inference done 745/1276. Dataloading: 0.0023 s/iter. Inference: 0.3619 s/iter. Eval: 0.0126 s/iter. Total: 0.3769 s/iter. ETA=0:03:20
[10/29 17:12:16] detectron2.evaluation.evaluator INFO: Inference done 759/1276. Dataloading: 0.0023 s/iter. Inference: 0.3619 s/iter. Eval: 0.0126 s/iter. Total: 0.3768 s/iter. ETA=0:03:14
[10/29 17:12:21] detectron2.evaluation.evaluator INFO: Inference done 773/1276. Dataloading: 0.0023 s/iter. Inference: 0.3619 s/iter. Eval: 0.0125 s/iter. Total: 0.3769 s/iter. ETA=0:03:09
[10/29 17:12:26] detectron2.evaluation.evaluator INFO: Inference done 787/1276. Dataloading: 0.0023 s/iter. Inference: 0.3617 s/iter. Eval: 0.0126 s/iter. Total: 0.3766 s/iter. ETA=0:03:04
[10/29 17:12:31] detectron2.evaluation.evaluator INFO: Inference done 801/1276. Dataloading: 0.0023 s/iter. Inference: 0.3618 s/iter. Eval: 0.0126 s/iter. Total: 0.3767 s/iter. ETA=0:02:58
[10/29 17:12:36] detectron2.evaluation.evaluator INFO: Inference done 814/1276. Dataloading: 0.0023 s/iter. Inference: 0.3620 s/iter. Eval: 0.0126 s/iter. Total: 0.3769 s/iter. ETA=0:02:54
[10/29 17:12:42] detectron2.evaluation.evaluator INFO: Inference done 828/1276. Dataloading: 0.0023 s/iter. Inference: 0.3617 s/iter. Eval: 0.0126 s/iter. Total: 0.3766 s/iter. ETA=0:02:48
[10/29 17:12:47] detectron2.evaluation.evaluator INFO: Inference done 842/1276. Dataloading: 0.0023 s/iter. Inference: 0.3617 s/iter. Eval: 0.0126 s/iter. Total: 0.3767 s/iter. ETA=0:02:43
[10/29 17:12:52] detectron2.evaluation.evaluator INFO: Inference done 856/1276. Dataloading: 0.0023 s/iter. Inference: 0.3616 s/iter. Eval: 0.0126 s/iter. Total: 0.3766 s/iter. ETA=0:02:38
[10/29 17:12:57] detectron2.evaluation.evaluator INFO: Inference done 869/1276. Dataloading: 0.0023 s/iter. Inference: 0.3618 s/iter. Eval: 0.0126 s/iter. Total: 0.3768 s/iter. ETA=0:02:33
[10/29 17:13:02] detectron2.evaluation.evaluator INFO: Inference done 883/1276. Dataloading: 0.0023 s/iter. Inference: 0.3619 s/iter. Eval: 0.0126 s/iter. Total: 0.3768 s/iter. ETA=0:02:28
[10/29 17:13:08] detectron2.evaluation.evaluator INFO: Inference done 897/1276. Dataloading: 0.0023 s/iter. Inference: 0.3617 s/iter. Eval: 0.0126 s/iter. Total: 0.3767 s/iter. ETA=0:02:22
[10/29 17:13:13] detectron2.evaluation.evaluator INFO: Inference done 911/1276. Dataloading: 0.0023 s/iter. Inference: 0.3616 s/iter. Eval: 0.0125 s/iter. Total: 0.3766 s/iter. ETA=0:02:17
[10/29 17:13:18] detectron2.evaluation.evaluator INFO: Inference done 926/1276. Dataloading: 0.0023 s/iter. Inference: 0.3613 s/iter. Eval: 0.0125 s/iter. Total: 0.3762 s/iter. ETA=0:02:11
[10/29 17:13:23] detectron2.evaluation.evaluator INFO: Inference done 940/1276. Dataloading: 0.0023 s/iter. Inference: 0.3613 s/iter. Eval: 0.0126 s/iter. Total: 0.3762 s/iter. ETA=0:02:06
[10/29 17:13:29] detectron2.evaluation.evaluator INFO: Inference done 954/1276. Dataloading: 0.0023 s/iter. Inference: 0.3613 s/iter. Eval: 0.0125 s/iter. Total: 0.3762 s/iter. ETA=0:02:01
[10/29 17:13:34] detectron2.evaluation.evaluator INFO: Inference done 968/1276. Dataloading: 0.0023 s/iter. Inference: 0.3614 s/iter. Eval: 0.0125 s/iter. Total: 0.3763 s/iter. ETA=0:01:55
[10/29 17:13:39] detectron2.evaluation.evaluator INFO: Inference done 982/1276. Dataloading: 0.0023 s/iter. Inference: 0.3615 s/iter. Eval: 0.0125 s/iter. Total: 0.3764 s/iter. ETA=0:01:50
[10/29 17:13:44] detectron2.evaluation.evaluator INFO: Inference done 996/1276. Dataloading: 0.0023 s/iter. Inference: 0.3614 s/iter. Eval: 0.0125 s/iter. Total: 0.3763 s/iter. ETA=0:01:45
[10/29 17:13:50] detectron2.evaluation.evaluator INFO: Inference done 1010/1276. Dataloading: 0.0023 s/iter. Inference: 0.3614 s/iter. Eval: 0.0125 s/iter. Total: 0.3763 s/iter. ETA=0:01:40
[10/29 17:13:55] detectron2.evaluation.evaluator INFO: Inference done 1023/1276. Dataloading: 0.0023 s/iter. Inference: 0.3616 s/iter. Eval: 0.0125 s/iter. Total: 0.3765 s/iter. ETA=0:01:35
[10/29 17:14:00] detectron2.evaluation.evaluator INFO: Inference done 1037/1276. Dataloading: 0.0023 s/iter. Inference: 0.3617 s/iter. Eval: 0.0125 s/iter. Total: 0.3765 s/iter. ETA=0:01:29
[10/29 17:14:05] detectron2.evaluation.evaluator INFO: Inference done 1051/1276. Dataloading: 0.0023 s/iter. Inference: 0.3616 s/iter. Eval: 0.0125 s/iter. Total: 0.3765 s/iter. ETA=0:01:24
[10/29 17:14:11] detectron2.evaluation.evaluator INFO: Inference done 1065/1276. Dataloading: 0.0023 s/iter. Inference: 0.3615 s/iter. Eval: 0.0125 s/iter. Total: 0.3764 s/iter. ETA=0:01:19
[10/29 17:14:16] detectron2.evaluation.evaluator INFO: Inference done 1079/1276. Dataloading: 0.0023 s/iter. Inference: 0.3615 s/iter. Eval: 0.0125 s/iter. Total: 0.3764 s/iter. ETA=0:01:14
[10/29 17:14:21] detectron2.evaluation.evaluator INFO: Inference done 1092/1276. Dataloading: 0.0023 s/iter. Inference: 0.3616 s/iter. Eval: 0.0125 s/iter. Total: 0.3765 s/iter. ETA=0:01:09
[10/29 17:14:26] detectron2.evaluation.evaluator INFO: Inference done 1105/1276. Dataloading: 0.0023 s/iter. Inference: 0.3617 s/iter. Eval: 0.0125 s/iter. Total: 0.3766 s/iter. ETA=0:01:04
[10/29 17:14:31] detectron2.evaluation.evaluator INFO: Inference done 1119/1276. Dataloading: 0.0023 s/iter. Inference: 0.3616 s/iter. Eval: 0.0125 s/iter. Total: 0.3765 s/iter. ETA=0:00:59
[10/29 17:14:36] detectron2.evaluation.evaluator INFO: Inference done 1132/1276. Dataloading: 0.0023 s/iter. Inference: 0.3618 s/iter. Eval: 0.0125 s/iter. Total: 0.3767 s/iter. ETA=0:00:54
[10/29 17:14:41] detectron2.evaluation.evaluator INFO: Inference done 1145/1276. Dataloading: 0.0023 s/iter. Inference: 0.3621 s/iter. Eval: 0.0125 s/iter. Total: 0.3770 s/iter. ETA=0:00:49
[10/29 17:14:46] detectron2.evaluation.evaluator INFO: Inference done 1159/1276. Dataloading: 0.0023 s/iter. Inference: 0.3620 s/iter. Eval: 0.0125 s/iter. Total: 0.3768 s/iter. ETA=0:00:44
[10/29 17:14:51] detectron2.evaluation.evaluator INFO: Inference done 1172/1276. Dataloading: 0.0023 s/iter. Inference: 0.3621 s/iter. Eval: 0.0125 s/iter. Total: 0.3769 s/iter. ETA=0:00:39
[10/29 17:14:57] detectron2.evaluation.evaluator INFO: Inference done 1186/1276. Dataloading: 0.0023 s/iter. Inference: 0.3620 s/iter. Eval: 0.0125 s/iter. Total: 0.3769 s/iter. ETA=0:00:33
[10/29 17:15:02] detectron2.evaluation.evaluator INFO: Inference done 1199/1276. Dataloading: 0.0023 s/iter. Inference: 0.3622 s/iter. Eval: 0.0125 s/iter. Total: 0.3770 s/iter. ETA=0:00:29
[10/29 17:15:07] detectron2.evaluation.evaluator INFO: Inference done 1212/1276. Dataloading: 0.0023 s/iter. Inference: 0.3624 s/iter. Eval: 0.0125 s/iter. Total: 0.3772 s/iter. ETA=0:00:24
[10/29 17:15:12] detectron2.evaluation.evaluator INFO: Inference done 1227/1276. Dataloading: 0.0023 s/iter. Inference: 0.3620 s/iter. Eval: 0.0125 s/iter. Total: 0.3769 s/iter. ETA=0:00:18
[10/29 17:15:17] detectron2.evaluation.evaluator INFO: Inference done 1240/1276. Dataloading: 0.0023 s/iter. Inference: 0.3621 s/iter. Eval: 0.0125 s/iter. Total: 0.3770 s/iter. ETA=0:00:13
[10/29 17:15:22] detectron2.evaluation.evaluator INFO: Inference done 1254/1276. Dataloading: 0.0023 s/iter. Inference: 0.3620 s/iter. Eval: 0.0125 s/iter. Total: 0.3769 s/iter. ETA=0:00:08
[10/29 17:15:27] detectron2.evaluation.evaluator INFO: Inference done 1267/1276. Dataloading: 0.0023 s/iter. Inference: 0.3622 s/iter. Eval: 0.0125 s/iter. Total: 0.3770 s/iter. ETA=0:00:03
[10/29 17:15:32] detectron2.evaluation.evaluator INFO: Total inference time: 0:08:00.720741 (0.378222 s / iter per device, on 4 devices)
[10/29 17:15:32] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:40 (0.362308 s / iter per device, on 4 devices)
[10/29 17:16:08] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[10/29 17:16:08] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/29 17:16:08] detectron2.data.common INFO: Serializing 5104 elements to byte tensors and concatenating them all ...
[10/29 17:16:09] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[10/29 17:16:09] detectron2.evaluation.evaluator INFO: Start inference on 1276 batches
[10/29 17:16:27] detectron2.evaluation.evaluator INFO: Inference done 1/1276. Dataloading: 8.3364 s/iter. Inference: 10.3685 s/iter. Eval: 0.0081 s/iter. Total: 18.7162 s/iter. ETA=6:37:43
[10/29 17:16:33] detectron2.evaluation.evaluator INFO: Inference done 15/1276. Dataloading: 0.0018 s/iter. Inference: 0.3555 s/iter. Eval: 0.0100 s/iter. Total: 0.3674 s/iter. ETA=0:07:43
[10/29 17:16:38] detectron2.evaluation.evaluator INFO: Inference done 29/1276. Dataloading: 0.0020 s/iter. Inference: 0.3543 s/iter. Eval: 0.0105 s/iter. Total: 0.3668 s/iter. ETA=0:07:37
[10/29 17:16:43] detectron2.evaluation.evaluator INFO: Inference done 43/1276. Dataloading: 0.0021 s/iter. Inference: 0.3555 s/iter. Eval: 0.0106 s/iter. Total: 0.3683 s/iter. ETA=0:07:34
[10/29 17:16:48] detectron2.evaluation.evaluator INFO: Inference done 56/1276. Dataloading: 0.0022 s/iter. Inference: 0.3602 s/iter. Eval: 0.0106 s/iter. Total: 0.3730 s/iter. ETA=0:07:35
[10/29 17:16:53] detectron2.evaluation.evaluator INFO: Inference done 70/1276. Dataloading: 0.0021 s/iter. Inference: 0.3613 s/iter. Eval: 0.0106 s/iter. Total: 0.3742 s/iter. ETA=0:07:31
[10/29 17:16:58] detectron2.evaluation.evaluator INFO: Inference done 84/1276. Dataloading: 0.0022 s/iter. Inference: 0.3597 s/iter. Eval: 0.0105 s/iter. Total: 0.3724 s/iter. ETA=0:07:23
[10/29 17:17:04] detectron2.evaluation.evaluator INFO: Inference done 98/1276. Dataloading: 0.0022 s/iter. Inference: 0.3597 s/iter. Eval: 0.0105 s/iter. Total: 0.3725 s/iter. ETA=0:07:18
[10/29 17:17:09] detectron2.evaluation.evaluator INFO: Inference done 112/1276. Dataloading: 0.0022 s/iter. Inference: 0.3604 s/iter. Eval: 0.0105 s/iter. Total: 0.3732 s/iter. ETA=0:07:14
[10/29 17:17:14] detectron2.evaluation.evaluator INFO: Inference done 126/1276. Dataloading: 0.0022 s/iter. Inference: 0.3590 s/iter. Eval: 0.0104 s/iter. Total: 0.3717 s/iter. ETA=0:07:07
[10/29 17:17:19] detectron2.evaluation.evaluator INFO: Inference done 139/1276. Dataloading: 0.0022 s/iter. Inference: 0.3605 s/iter. Eval: 0.0104 s/iter. Total: 0.3733 s/iter. ETA=0:07:04
[10/29 17:17:24] detectron2.evaluation.evaluator INFO: Inference done 153/1276. Dataloading: 0.0022 s/iter. Inference: 0.3592 s/iter. Eval: 0.0104 s/iter. Total: 0.3719 s/iter. ETA=0:06:57
[10/29 17:17:29] detectron2.evaluation.evaluator INFO: Inference done 167/1276. Dataloading: 0.0022 s/iter. Inference: 0.3598 s/iter. Eval: 0.0103 s/iter. Total: 0.3724 s/iter. ETA=0:06:53
[10/29 17:17:34] detectron2.evaluation.evaluator INFO: Inference done 181/1276. Dataloading: 0.0022 s/iter. Inference: 0.3596 s/iter. Eval: 0.0103 s/iter. Total: 0.3721 s/iter. ETA=0:06:47
[10/29 17:17:40] detectron2.evaluation.evaluator INFO: Inference done 195/1276. Dataloading: 0.0022 s/iter. Inference: 0.3595 s/iter. Eval: 0.0103 s/iter. Total: 0.3721 s/iter. ETA=0:06:42
[10/29 17:17:45] detectron2.evaluation.evaluator INFO: Inference done 209/1276. Dataloading: 0.0022 s/iter. Inference: 0.3599 s/iter. Eval: 0.0103 s/iter. Total: 0.3724 s/iter. ETA=0:06:37
[10/29 17:17:50] detectron2.evaluation.evaluator INFO: Inference done 223/1276. Dataloading: 0.0022 s/iter. Inference: 0.3597 s/iter. Eval: 0.0102 s/iter. Total: 0.3722 s/iter. ETA=0:06:31
[10/29 17:17:55] detectron2.evaluation.evaluator INFO: Inference done 238/1276. Dataloading: 0.0022 s/iter. Inference: 0.3587 s/iter. Eval: 0.0102 s/iter. Total: 0.3712 s/iter. ETA=0:06:25
[10/29 17:18:01] detectron2.evaluation.evaluator INFO: Inference done 252/1276. Dataloading: 0.0022 s/iter. Inference: 0.3589 s/iter. Eval: 0.0102 s/iter. Total: 0.3714 s/iter. ETA=0:06:20
[10/29 17:18:06] detectron2.evaluation.evaluator INFO: Inference done 266/1276. Dataloading: 0.0022 s/iter. Inference: 0.3583 s/iter. Eval: 0.0102 s/iter. Total: 0.3708 s/iter. ETA=0:06:14
[10/29 17:18:11] detectron2.evaluation.evaluator INFO: Inference done 280/1276. Dataloading: 0.0022 s/iter. Inference: 0.3581 s/iter. Eval: 0.0102 s/iter. Total: 0.3706 s/iter. ETA=0:06:09
[10/29 17:18:16] detectron2.evaluation.evaluator INFO: Inference done 294/1276. Dataloading: 0.0022 s/iter. Inference: 0.3586 s/iter. Eval: 0.0102 s/iter. Total: 0.3710 s/iter. ETA=0:06:04
[10/29 17:18:21] detectron2.evaluation.evaluator INFO: Inference done 308/1276. Dataloading: 0.0022 s/iter. Inference: 0.3588 s/iter. Eval: 0.0101 s/iter. Total: 0.3712 s/iter. ETA=0:05:59
[10/29 17:18:26] detectron2.evaluation.evaluator INFO: Inference done 322/1276. Dataloading: 0.0022 s/iter. Inference: 0.3585 s/iter. Eval: 0.0101 s/iter. Total: 0.3709 s/iter. ETA=0:05:53
[10/29 17:18:32] detectron2.evaluation.evaluator INFO: Inference done 336/1276. Dataloading: 0.0022 s/iter. Inference: 0.3586 s/iter. Eval: 0.0101 s/iter. Total: 0.3710 s/iter. ETA=0:05:48
[10/29 17:18:37] detectron2.evaluation.evaluator INFO: Inference done 350/1276. Dataloading: 0.0022 s/iter. Inference: 0.3592 s/iter. Eval: 0.0102 s/iter. Total: 0.3716 s/iter. ETA=0:05:44
[10/29 17:18:42] detectron2.evaluation.evaluator INFO: Inference done 365/1276. Dataloading: 0.0022 s/iter. Inference: 0.3586 s/iter. Eval: 0.0102 s/iter. Total: 0.3710 s/iter. ETA=0:05:37
[10/29 17:18:47] detectron2.evaluation.evaluator INFO: Inference done 379/1276. Dataloading: 0.0022 s/iter. Inference: 0.3582 s/iter. Eval: 0.0101 s/iter. Total: 0.3706 s/iter. ETA=0:05:32
[10/29 17:18:53] detectron2.evaluation.evaluator INFO: Inference done 393/1276. Dataloading: 0.0022 s/iter. Inference: 0.3583 s/iter. Eval: 0.0101 s/iter. Total: 0.3707 s/iter. ETA=0:05:27
[10/29 17:18:58] detectron2.evaluation.evaluator INFO: Inference done 407/1276. Dataloading: 0.0022 s/iter. Inference: 0.3584 s/iter. Eval: 0.0101 s/iter. Total: 0.3708 s/iter. ETA=0:05:22
[10/29 17:19:03] detectron2.evaluation.evaluator INFO: Inference done 421/1276. Dataloading: 0.0022 s/iter. Inference: 0.3581 s/iter. Eval: 0.0101 s/iter. Total: 0.3705 s/iter. ETA=0:05:16
[10/29 17:19:08] detectron2.evaluation.evaluator INFO: Inference done 435/1276. Dataloading: 0.0022 s/iter. Inference: 0.3578 s/iter. Eval: 0.0101 s/iter. Total: 0.3703 s/iter. ETA=0:05:11
[10/29 17:19:13] detectron2.evaluation.evaluator INFO: Inference done 448/1276. Dataloading: 0.0022 s/iter. Inference: 0.3584 s/iter. Eval: 0.0101 s/iter. Total: 0.3708 s/iter. ETA=0:05:07
[10/29 17:19:18] detectron2.evaluation.evaluator INFO: Inference done 462/1276. Dataloading: 0.0022 s/iter. Inference: 0.3585 s/iter. Eval: 0.0101 s/iter. Total: 0.3708 s/iter. ETA=0:05:01
[10/29 17:19:23] detectron2.evaluation.evaluator INFO: Inference done 476/1276. Dataloading: 0.0022 s/iter. Inference: 0.3583 s/iter. Eval: 0.0101 s/iter. Total: 0.3706 s/iter. ETA=0:04:56
[10/29 17:19:29] detectron2.evaluation.evaluator INFO: Inference done 491/1276. Dataloading: 0.0022 s/iter. Inference: 0.3579 s/iter. Eval: 0.0101 s/iter. Total: 0.3702 s/iter. ETA=0:04:50
[10/29 17:19:34] detectron2.evaluation.evaluator INFO: Inference done 505/1276. Dataloading: 0.0022 s/iter. Inference: 0.3579 s/iter. Eval: 0.0101 s/iter. Total: 0.3703 s/iter. ETA=0:04:45
[10/29 17:19:39] detectron2.evaluation.evaluator INFO: Inference done 519/1276. Dataloading: 0.0022 s/iter. Inference: 0.3580 s/iter. Eval: 0.0101 s/iter. Total: 0.3704 s/iter. ETA=0:04:40
[10/29 17:19:44] detectron2.evaluation.evaluator INFO: Inference done 532/1276. Dataloading: 0.0022 s/iter. Inference: 0.3585 s/iter. Eval: 0.0101 s/iter. Total: 0.3709 s/iter. ETA=0:04:35
[10/29 17:19:50] detectron2.evaluation.evaluator INFO: Inference done 546/1276. Dataloading: 0.0022 s/iter. Inference: 0.3586 s/iter. Eval: 0.0102 s/iter. Total: 0.3711 s/iter. ETA=0:04:30
[10/29 17:19:55] detectron2.evaluation.evaluator INFO: Inference done 560/1276. Dataloading: 0.0022 s/iter. Inference: 0.3587 s/iter. Eval: 0.0102 s/iter. Total: 0.3711 s/iter. ETA=0:04:25
[10/29 17:20:00] detectron2.evaluation.evaluator INFO: Inference done 575/1276. Dataloading: 0.0022 s/iter. Inference: 0.3580 s/iter. Eval: 0.0102 s/iter. Total: 0.3705 s/iter. ETA=0:04:19
[10/29 17:20:05] detectron2.evaluation.evaluator INFO: Inference done 589/1276. Dataloading: 0.0022 s/iter. Inference: 0.3582 s/iter. Eval: 0.0102 s/iter. Total: 0.3707 s/iter. ETA=0:04:14
[10/29 17:20:10] detectron2.evaluation.evaluator INFO: Inference done 603/1276. Dataloading: 0.0022 s/iter. Inference: 0.3579 s/iter. Eval: 0.0102 s/iter. Total: 0.3704 s/iter. ETA=0:04:09
[10/29 17:20:16] detectron2.evaluation.evaluator INFO: Inference done 617/1276. Dataloading: 0.0022 s/iter. Inference: 0.3582 s/iter. Eval: 0.0101 s/iter. Total: 0.3706 s/iter. ETA=0:04:04
[10/29 17:20:21] detectron2.evaluation.evaluator INFO: Inference done 631/1276. Dataloading: 0.0022 s/iter. Inference: 0.3579 s/iter. Eval: 0.0101 s/iter. Total: 0.3703 s/iter. ETA=0:03:58
[10/29 17:20:26] detectron2.evaluation.evaluator INFO: Inference done 645/1276. Dataloading: 0.0022 s/iter. Inference: 0.3578 s/iter. Eval: 0.0101 s/iter. Total: 0.3702 s/iter. ETA=0:03:53
[10/29 17:20:31] detectron2.evaluation.evaluator INFO: Inference done 659/1276. Dataloading: 0.0022 s/iter. Inference: 0.3576 s/iter. Eval: 0.0101 s/iter. Total: 0.3700 s/iter. ETA=0:03:48
[10/29 17:20:36] detectron2.evaluation.evaluator INFO: Inference done 673/1276. Dataloading: 0.0022 s/iter. Inference: 0.3577 s/iter. Eval: 0.0102 s/iter. Total: 0.3702 s/iter. ETA=0:03:43
[10/29 17:20:41] detectron2.evaluation.evaluator INFO: Inference done 687/1276. Dataloading: 0.0022 s/iter. Inference: 0.3576 s/iter. Eval: 0.0102 s/iter. Total: 0.3701 s/iter. ETA=0:03:38
[10/29 17:20:47] detectron2.evaluation.evaluator INFO: Inference done 701/1276. Dataloading: 0.0022 s/iter. Inference: 0.3577 s/iter. Eval: 0.0102 s/iter. Total: 0.3701 s/iter. ETA=0:03:32
[10/29 17:20:52] detectron2.evaluation.evaluator INFO: Inference done 715/1276. Dataloading: 0.0022 s/iter. Inference: 0.3576 s/iter. Eval: 0.0102 s/iter. Total: 0.3701 s/iter. ETA=0:03:27
[10/29 17:20:57] detectron2.evaluation.evaluator INFO: Inference done 731/1276. Dataloading: 0.0022 s/iter. Inference: 0.3568 s/iter. Eval: 0.0103 s/iter. Total: 0.3693 s/iter. ETA=0:03:21
[10/29 17:21:02] detectron2.evaluation.evaluator INFO: Inference done 744/1276. Dataloading: 0.0022 s/iter. Inference: 0.3570 s/iter. Eval: 0.0103 s/iter. Total: 0.3696 s/iter. ETA=0:03:16
[10/29 17:21:07] detectron2.evaluation.evaluator INFO: Inference done 758/1276. Dataloading: 0.0022 s/iter. Inference: 0.3570 s/iter. Eval: 0.0103 s/iter. Total: 0.3696 s/iter. ETA=0:03:11
[10/29 17:21:12] detectron2.evaluation.evaluator INFO: Inference done 772/1276. Dataloading: 0.0022 s/iter. Inference: 0.3570 s/iter. Eval: 0.0103 s/iter. Total: 0.3696 s/iter. ETA=0:03:06
[10/29 17:21:17] detectron2.evaluation.evaluator INFO: Inference done 786/1276. Dataloading: 0.0022 s/iter. Inference: 0.3569 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:03:01
[10/29 17:21:23] detectron2.evaluation.evaluator INFO: Inference done 800/1276. Dataloading: 0.0022 s/iter. Inference: 0.3568 s/iter. Eval: 0.0103 s/iter. Total: 0.3694 s/iter. ETA=0:02:55
[10/29 17:21:28] detectron2.evaluation.evaluator INFO: Inference done 814/1276. Dataloading: 0.0022 s/iter. Inference: 0.3571 s/iter. Eval: 0.0103 s/iter. Total: 0.3697 s/iter. ETA=0:02:50
[10/29 17:21:33] detectron2.evaluation.evaluator INFO: Inference done 829/1276. Dataloading: 0.0022 s/iter. Inference: 0.3568 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:02:45
[10/29 17:21:39] detectron2.evaluation.evaluator INFO: Inference done 843/1276. Dataloading: 0.0022 s/iter. Inference: 0.3569 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:02:40
[10/29 17:21:44] detectron2.evaluation.evaluator INFO: Inference done 857/1276. Dataloading: 0.0023 s/iter. Inference: 0.3569 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:02:34
[10/29 17:21:49] detectron2.evaluation.evaluator INFO: Inference done 871/1276. Dataloading: 0.0023 s/iter. Inference: 0.3571 s/iter. Eval: 0.0103 s/iter. Total: 0.3698 s/iter. ETA=0:02:29
[10/29 17:21:54] detectron2.evaluation.evaluator INFO: Inference done 885/1276. Dataloading: 0.0023 s/iter. Inference: 0.3570 s/iter. Eval: 0.0104 s/iter. Total: 0.3696 s/iter. ETA=0:02:24
[10/29 17:21:59] detectron2.evaluation.evaluator INFO: Inference done 899/1276. Dataloading: 0.0023 s/iter. Inference: 0.3570 s/iter. Eval: 0.0104 s/iter. Total: 0.3697 s/iter. ETA=0:02:19
[10/29 17:22:04] detectron2.evaluation.evaluator INFO: Inference done 913/1276. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0104 s/iter. Total: 0.3695 s/iter. ETA=0:02:14
[10/29 17:22:10] detectron2.evaluation.evaluator INFO: Inference done 928/1276. Dataloading: 0.0023 s/iter. Inference: 0.3565 s/iter. Eval: 0.0104 s/iter. Total: 0.3693 s/iter. ETA=0:02:08
[10/29 17:22:15] detectron2.evaluation.evaluator INFO: Inference done 942/1276. Dataloading: 0.0023 s/iter. Inference: 0.3565 s/iter. Eval: 0.0104 s/iter. Total: 0.3692 s/iter. ETA=0:02:03
[10/29 17:22:20] detectron2.evaluation.evaluator INFO: Inference done 956/1276. Dataloading: 0.0023 s/iter. Inference: 0.3565 s/iter. Eval: 0.0104 s/iter. Total: 0.3692 s/iter. ETA=0:01:58
[10/29 17:22:25] detectron2.evaluation.evaluator INFO: Inference done 970/1276. Dataloading: 0.0023 s/iter. Inference: 0.3566 s/iter. Eval: 0.0104 s/iter. Total: 0.3693 s/iter. ETA=0:01:53
[10/29 17:22:30] detectron2.evaluation.evaluator INFO: Inference done 984/1276. Dataloading: 0.0023 s/iter. Inference: 0.3566 s/iter. Eval: 0.0104 s/iter. Total: 0.3694 s/iter. ETA=0:01:47
[10/29 17:22:36] detectron2.evaluation.evaluator INFO: Inference done 998/1276. Dataloading: 0.0023 s/iter. Inference: 0.3566 s/iter. Eval: 0.0104 s/iter. Total: 0.3693 s/iter. ETA=0:01:42
[10/29 17:22:41] detectron2.evaluation.evaluator INFO: Inference done 1012/1276. Dataloading: 0.0023 s/iter. Inference: 0.3567 s/iter. Eval: 0.0104 s/iter. Total: 0.3694 s/iter. ETA=0:01:37
[10/29 17:22:46] detectron2.evaluation.evaluator INFO: Inference done 1026/1276. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0104 s/iter. Total: 0.3695 s/iter. ETA=0:01:32
[10/29 17:22:51] detectron2.evaluation.evaluator INFO: Inference done 1040/1276. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0104 s/iter. Total: 0.3695 s/iter. ETA=0:01:27
[10/29 17:22:56] detectron2.evaluation.evaluator INFO: Inference done 1054/1276. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0104 s/iter. Total: 0.3695 s/iter. ETA=0:01:22
[10/29 17:23:02] detectron2.evaluation.evaluator INFO: Inference done 1068/1276. Dataloading: 0.0023 s/iter. Inference: 0.3567 s/iter. Eval: 0.0103 s/iter. Total: 0.3694 s/iter. ETA=0:01:16
[10/29 17:23:07] detectron2.evaluation.evaluator INFO: Inference done 1082/1276. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:01:11
[10/29 17:23:12] detectron2.evaluation.evaluator INFO: Inference done 1096/1276. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:01:06
[10/29 17:23:17] detectron2.evaluation.evaluator INFO: Inference done 1110/1276. Dataloading: 0.0023 s/iter. Inference: 0.3568 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:01:01
[10/29 17:23:22] detectron2.evaluation.evaluator INFO: Inference done 1124/1276. Dataloading: 0.0023 s/iter. Inference: 0.3569 s/iter. Eval: 0.0103 s/iter. Total: 0.3695 s/iter. ETA=0:00:56
[10/29 17:23:28] detectron2.evaluation.evaluator INFO: Inference done 1138/1276. Dataloading: 0.0023 s/iter. Inference: 0.3571 s/iter. Eval: 0.0103 s/iter. Total: 0.3698 s/iter. ETA=0:00:51
[10/29 17:23:33] detectron2.evaluation.evaluator INFO: Inference done 1152/1276. Dataloading: 0.0023 s/iter. Inference: 0.3571 s/iter. Eval: 0.0103 s/iter. Total: 0.3697 s/iter. ETA=0:00:45
[10/29 17:23:38] detectron2.evaluation.evaluator INFO: Inference done 1166/1276. Dataloading: 0.0023 s/iter. Inference: 0.3571 s/iter. Eval: 0.0103 s/iter. Total: 0.3698 s/iter. ETA=0:00:40
[10/29 17:23:43] detectron2.evaluation.evaluator INFO: Inference done 1180/1276. Dataloading: 0.0023 s/iter. Inference: 0.3572 s/iter. Eval: 0.0103 s/iter. Total: 0.3698 s/iter. ETA=0:00:35
[10/29 17:23:49] detectron2.evaluation.evaluator INFO: Inference done 1194/1276. Dataloading: 0.0023 s/iter. Inference: 0.3573 s/iter. Eval: 0.0103 s/iter. Total: 0.3699 s/iter. ETA=0:00:30
[10/29 17:23:54] detectron2.evaluation.evaluator INFO: Inference done 1207/1276. Dataloading: 0.0023 s/iter. Inference: 0.3574 s/iter. Eval: 0.0103 s/iter. Total: 0.3700 s/iter. ETA=0:00:25
[10/29 17:23:59] detectron2.evaluation.evaluator INFO: Inference done 1222/1276. Dataloading: 0.0023 s/iter. Inference: 0.3572 s/iter. Eval: 0.0103 s/iter. Total: 0.3698 s/iter. ETA=0:00:19
[10/29 17:24:04] detectron2.evaluation.evaluator INFO: Inference done 1236/1276. Dataloading: 0.0023 s/iter. Inference: 0.3571 s/iter. Eval: 0.0103 s/iter. Total: 0.3697 s/iter. ETA=0:00:14
[10/29 17:24:09] detectron2.evaluation.evaluator INFO: Inference done 1250/1276. Dataloading: 0.0023 s/iter. Inference: 0.3571 s/iter. Eval: 0.0103 s/iter. Total: 0.3697 s/iter. ETA=0:00:09
[10/29 17:24:14] detectron2.evaluation.evaluator INFO: Inference done 1264/1276. Dataloading: 0.0023 s/iter. Inference: 0.3572 s/iter. Eval: 0.0103 s/iter. Total: 0.3698 s/iter. ETA=0:00:04
[10/29 17:24:20] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:51.590272 (0.371039 s / iter per device, on 4 devices)
[10/29 17:24:20] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:34 (0.357360 s / iter per device, on 4 devices)
[10/29 17:24:50] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[10/29 17:24:50] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/29 17:24:50] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[10/29 17:24:50] detectron2.data.common INFO: Serialized dataset takes 15.18 MiB
[10/29 17:24:50] detectron2.evaluation.evaluator INFO: Start inference on 500 batches
[10/29 17:25:23] detectron2.evaluation.evaluator INFO: Inference done 1/500. Dataloading: 6.1828 s/iter. Inference: 26.2812 s/iter. Eval: 0.0262 s/iter. Total: 32.4927 s/iter. ETA=4:30:13
[10/29 17:25:28] detectron2.evaluation.evaluator INFO: Inference done 14/500. Dataloading: 0.0019 s/iter. Inference: 0.3579 s/iter. Eval: 0.0205 s/iter. Total: 0.3803 s/iter. ETA=0:03:04
[10/29 17:25:33] detectron2.evaluation.evaluator INFO: Inference done 27/500. Dataloading: 0.0022 s/iter. Inference: 0.3636 s/iter. Eval: 0.0238 s/iter. Total: 0.3897 s/iter. ETA=0:03:04
[10/29 17:25:38] detectron2.evaluation.evaluator INFO: Inference done 41/500. Dataloading: 0.0023 s/iter. Inference: 0.3600 s/iter. Eval: 0.0217 s/iter. Total: 0.3840 s/iter. ETA=0:02:56
[10/29 17:25:43] detectron2.evaluation.evaluator INFO: Inference done 55/500. Dataloading: 0.0023 s/iter. Inference: 0.3574 s/iter. Eval: 0.0212 s/iter. Total: 0.3810 s/iter. ETA=0:02:49
[10/29 17:25:49] detectron2.evaluation.evaluator INFO: Inference done 71/500. Dataloading: 0.0023 s/iter. Inference: 0.3461 s/iter. Eval: 0.0203 s/iter. Total: 0.3687 s/iter. ETA=0:02:38
[10/29 17:25:54] detectron2.evaluation.evaluator INFO: Inference done 85/500. Dataloading: 0.0023 s/iter. Inference: 0.3469 s/iter. Eval: 0.0207 s/iter. Total: 0.3700 s/iter. ETA=0:02:33
[10/29 17:25:59] detectron2.evaluation.evaluator INFO: Inference done 99/500. Dataloading: 0.0023 s/iter. Inference: 0.3487 s/iter. Eval: 0.0211 s/iter. Total: 0.3722 s/iter. ETA=0:02:29
[10/29 17:26:04] detectron2.evaluation.evaluator INFO: Inference done 114/500. Dataloading: 0.0023 s/iter. Inference: 0.3444 s/iter. Eval: 0.0200 s/iter. Total: 0.3669 s/iter. ETA=0:02:21
[10/29 17:26:10] detectron2.evaluation.evaluator INFO: Inference done 129/500. Dataloading: 0.0024 s/iter. Inference: 0.3441 s/iter. Eval: 0.0190 s/iter. Total: 0.3655 s/iter. ETA=0:02:15
[10/29 17:26:15] detectron2.evaluation.evaluator INFO: Inference done 143/500. Dataloading: 0.0024 s/iter. Inference: 0.3451 s/iter. Eval: 0.0186 s/iter. Total: 0.3662 s/iter. ETA=0:02:10
[10/29 17:26:20] detectron2.evaluation.evaluator INFO: Inference done 157/500. Dataloading: 0.0024 s/iter. Inference: 0.3450 s/iter. Eval: 0.0183 s/iter. Total: 0.3658 s/iter. ETA=0:02:05
[10/29 17:26:25] detectron2.evaluation.evaluator INFO: Inference done 171/500. Dataloading: 0.0024 s/iter. Inference: 0.3452 s/iter. Eval: 0.0179 s/iter. Total: 0.3656 s/iter. ETA=0:02:00
[10/29 17:26:30] detectron2.evaluation.evaluator INFO: Inference done 185/500. Dataloading: 0.0024 s/iter. Inference: 0.3470 s/iter. Eval: 0.0178 s/iter. Total: 0.3673 s/iter. ETA=0:01:55
[10/29 17:26:36] detectron2.evaluation.evaluator INFO: Inference done 199/500. Dataloading: 0.0024 s/iter. Inference: 0.3471 s/iter. Eval: 0.0179 s/iter. Total: 0.3674 s/iter. ETA=0:01:50
[10/29 17:26:41] detectron2.evaluation.evaluator INFO: Inference done 213/500. Dataloading: 0.0024 s/iter. Inference: 0.3471 s/iter. Eval: 0.0177 s/iter. Total: 0.3672 s/iter. ETA=0:01:45
[10/29 17:26:46] detectron2.evaluation.evaluator INFO: Inference done 227/500. Dataloading: 0.0024 s/iter. Inference: 0.3474 s/iter. Eval: 0.0175 s/iter. Total: 0.3673 s/iter. ETA=0:01:40
[10/29 17:26:51] detectron2.evaluation.evaluator INFO: Inference done 242/500. Dataloading: 0.0024 s/iter. Inference: 0.3472 s/iter. Eval: 0.0171 s/iter. Total: 0.3667 s/iter. ETA=0:01:34
[10/29 17:26:56] detectron2.evaluation.evaluator INFO: Inference done 257/500. Dataloading: 0.0024 s/iter. Inference: 0.3456 s/iter. Eval: 0.0171 s/iter. Total: 0.3651 s/iter. ETA=0:01:28
[10/29 17:27:02] detectron2.evaluation.evaluator INFO: Inference done 276/500. Dataloading: 0.0024 s/iter. Inference: 0.3402 s/iter. Eval: 0.0164 s/iter. Total: 0.3591 s/iter. ETA=0:01:20
[10/29 17:27:07] detectron2.evaluation.evaluator INFO: Inference done 290/500. Dataloading: 0.0024 s/iter. Inference: 0.3409 s/iter. Eval: 0.0168 s/iter. Total: 0.3601 s/iter. ETA=0:01:15
[10/29 17:27:12] detectron2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0024 s/iter. Inference: 0.3412 s/iter. Eval: 0.0170 s/iter. Total: 0.3606 s/iter. ETA=0:01:10
[10/29 17:27:17] detectron2.evaluation.evaluator INFO: Inference done 318/500. Dataloading: 0.0024 s/iter. Inference: 0.3415 s/iter. Eval: 0.0171 s/iter. Total: 0.3611 s/iter. ETA=0:01:05
[10/29 17:27:23] detectron2.evaluation.evaluator INFO: Inference done 332/500. Dataloading: 0.0024 s/iter. Inference: 0.3417 s/iter. Eval: 0.0173 s/iter. Total: 0.3615 s/iter. ETA=0:01:00
[10/29 17:27:28] detectron2.evaluation.evaluator INFO: Inference done 346/500. Dataloading: 0.0024 s/iter. Inference: 0.3422 s/iter. Eval: 0.0176 s/iter. Total: 0.3622 s/iter. ETA=0:00:55
[10/29 17:27:33] detectron2.evaluation.evaluator INFO: Inference done 360/500. Dataloading: 0.0024 s/iter. Inference: 0.3424 s/iter. Eval: 0.0177 s/iter. Total: 0.3626 s/iter. ETA=0:00:50
[10/29 17:27:38] detectron2.evaluation.evaluator INFO: Inference done 379/500. Dataloading: 0.0024 s/iter. Inference: 0.3380 s/iter. Eval: 0.0171 s/iter. Total: 0.3575 s/iter. ETA=0:00:43
[10/29 17:27:43] detectron2.evaluation.evaluator INFO: Inference done 393/500. Dataloading: 0.0024 s/iter. Inference: 0.3387 s/iter. Eval: 0.0171 s/iter. Total: 0.3582 s/iter. ETA=0:00:38
[10/29 17:27:48] detectron2.evaluation.evaluator INFO: Inference done 409/500. Dataloading: 0.0024 s/iter. Inference: 0.3373 s/iter. Eval: 0.0168 s/iter. Total: 0.3566 s/iter. ETA=0:00:32
[10/29 17:27:54] detectron2.evaluation.evaluator INFO: Inference done 423/500. Dataloading: 0.0024 s/iter. Inference: 0.3381 s/iter. Eval: 0.0168 s/iter. Total: 0.3573 s/iter. ETA=0:00:27
[10/29 17:27:59] detectron2.evaluation.evaluator INFO: Inference done 437/500. Dataloading: 0.0024 s/iter. Inference: 0.3389 s/iter. Eval: 0.0168 s/iter. Total: 0.3581 s/iter. ETA=0:00:22
[10/29 17:28:04] detectron2.evaluation.evaluator INFO: Inference done 452/500. Dataloading: 0.0024 s/iter. Inference: 0.3387 s/iter. Eval: 0.0168 s/iter. Total: 0.3580 s/iter. ETA=0:00:17
[10/29 17:28:10] detectron2.evaluation.evaluator INFO: Inference done 467/500. Dataloading: 0.0024 s/iter. Inference: 0.3383 s/iter. Eval: 0.0169 s/iter. Total: 0.3576 s/iter. ETA=0:00:11
[10/29 17:28:15] detectron2.evaluation.evaluator INFO: Inference done 483/500. Dataloading: 0.0024 s/iter. Inference: 0.3373 s/iter. Eval: 0.0168 s/iter. Total: 0.3565 s/iter. ETA=0:00:06
[10/29 17:28:20] detectron2.evaluation.evaluator INFO: Inference done 498/500. Dataloading: 0.0024 s/iter. Inference: 0.3371 s/iter. Eval: 0.0168 s/iter. Total: 0.3564 s/iter. ETA=0:00:00
[10/29 17:28:22] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:57.610543 (0.358809 s / iter per device, on 4 devices)
[10/29 17:28:22] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:46 (0.336841 s / iter per device, on 4 devices)
[12/06 22:56:29] detectron2 INFO: Rank of current process: 1. World size: 2
[12/06 22:56:30] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/06 22:56:30] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/06 22:56:30] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_pascal20_sem_seg_val",)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/06 22:58:59] detectron2 INFO: Rank of current process: 1. World size: 2
[12/06 22:58:59] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/06 22:58:59] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/06 22:58:59] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_pascal20_sem_seg_val",)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/06 22:59:15] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/06 22:59:15] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/06 22:59:15] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/06 22:59:15] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/06 22:59:15] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/06 22:59:15] detectron2.data.common INFO: Serializing 1449 elements to byte tensors and concatenating them all ...
[12/06 22:59:15] detectron2.data.common INFO: Serialized dataset takes 1.38 MiB
[12/06 22:59:15] detectron2.evaluation.evaluator INFO: Start inference on 724 batches
[12/06 22:59:26] detectron2.evaluation.evaluator INFO: Inference done 1/724. Dataloading: 5.3678 s/iter. Inference: 5.4117 s/iter. Eval: 0.0200 s/iter. Total: 10.8018 s/iter. ETA=2:10:09
[12/06 22:59:31] detectron2.evaluation.evaluator INFO: Inference done 16/724. Dataloading: 0.0018 s/iter. Inference: 0.3479 s/iter. Eval: 0.0092 s/iter. Total: 0.3589 s/iter. ETA=0:04:14
[12/06 22:59:36] detectron2.evaluation.evaluator INFO: Inference done 31/724. Dataloading: 0.0021 s/iter. Inference: 0.3462 s/iter. Eval: 0.0093 s/iter. Total: 0.3577 s/iter. ETA=0:04:07
[12/06 22:59:41] detectron2.evaluation.evaluator INFO: Inference done 46/724. Dataloading: 0.0022 s/iter. Inference: 0.3449 s/iter. Eval: 0.0091 s/iter. Total: 0.3562 s/iter. ETA=0:04:01
[12/06 22:59:47] detectron2.evaluation.evaluator INFO: Inference done 60/724. Dataloading: 0.0022 s/iter. Inference: 0.3488 s/iter. Eval: 0.0090 s/iter. Total: 0.3600 s/iter. ETA=0:03:59
[12/06 22:59:52] detectron2.evaluation.evaluator INFO: Inference done 74/724. Dataloading: 0.0022 s/iter. Inference: 0.3500 s/iter. Eval: 0.0090 s/iter. Total: 0.3613 s/iter. ETA=0:03:54
[12/06 22:59:57] detectron2.evaluation.evaluator INFO: Inference done 88/724. Dataloading: 0.0022 s/iter. Inference: 0.3510 s/iter. Eval: 0.0093 s/iter. Total: 0.3626 s/iter. ETA=0:03:50
[12/06 23:00:02] detectron2.evaluation.evaluator INFO: Inference done 102/724. Dataloading: 0.0022 s/iter. Inference: 0.3514 s/iter. Eval: 0.0092 s/iter. Total: 0.3629 s/iter. ETA=0:03:45
[12/06 23:00:07] detectron2.evaluation.evaluator INFO: Inference done 116/724. Dataloading: 0.0022 s/iter. Inference: 0.3513 s/iter. Eval: 0.0092 s/iter. Total: 0.3628 s/iter. ETA=0:03:40
[12/06 23:00:12] detectron2.evaluation.evaluator INFO: Inference done 130/724. Dataloading: 0.0022 s/iter. Inference: 0.3514 s/iter. Eval: 0.0092 s/iter. Total: 0.3629 s/iter. ETA=0:03:35
[12/06 23:00:17] detectron2.evaluation.evaluator INFO: Inference done 144/724. Dataloading: 0.0023 s/iter. Inference: 0.3522 s/iter. Eval: 0.0092 s/iter. Total: 0.3638 s/iter. ETA=0:03:30
[12/06 23:00:23] detectron2.evaluation.evaluator INFO: Inference done 158/724. Dataloading: 0.0023 s/iter. Inference: 0.3530 s/iter. Eval: 0.0090 s/iter. Total: 0.3644 s/iter. ETA=0:03:26
[12/06 23:00:28] detectron2.evaluation.evaluator INFO: Inference done 172/724. Dataloading: 0.0023 s/iter. Inference: 0.3543 s/iter. Eval: 0.0091 s/iter. Total: 0.3657 s/iter. ETA=0:03:21
[12/06 23:00:33] detectron2.evaluation.evaluator INFO: Inference done 186/724. Dataloading: 0.0023 s/iter. Inference: 0.3551 s/iter. Eval: 0.0091 s/iter. Total: 0.3666 s/iter. ETA=0:03:17
[12/06 23:00:38] detectron2.evaluation.evaluator INFO: Inference done 200/724. Dataloading: 0.0023 s/iter. Inference: 0.3549 s/iter. Eval: 0.0091 s/iter. Total: 0.3664 s/iter. ETA=0:03:12
[12/06 23:00:43] detectron2.evaluation.evaluator INFO: Inference done 214/724. Dataloading: 0.0023 s/iter. Inference: 0.3544 s/iter. Eval: 0.0092 s/iter. Total: 0.3660 s/iter. ETA=0:03:06
[12/06 23:00:48] detectron2.evaluation.evaluator INFO: Inference done 227/724. Dataloading: 0.0023 s/iter. Inference: 0.3560 s/iter. Eval: 0.0093 s/iter. Total: 0.3676 s/iter. ETA=0:03:02
[12/06 23:00:54] detectron2.evaluation.evaluator INFO: Inference done 241/724. Dataloading: 0.0023 s/iter. Inference: 0.3565 s/iter. Eval: 0.0093 s/iter. Total: 0.3681 s/iter. ETA=0:02:57
[12/06 23:00:59] detectron2.evaluation.evaluator INFO: Inference done 254/724. Dataloading: 0.0023 s/iter. Inference: 0.3576 s/iter. Eval: 0.0092 s/iter. Total: 0.3692 s/iter. ETA=0:02:53
[12/06 23:01:04] detectron2.evaluation.evaluator INFO: Inference done 268/724. Dataloading: 0.0023 s/iter. Inference: 0.3578 s/iter. Eval: 0.0092 s/iter. Total: 0.3693 s/iter. ETA=0:02:48
[12/06 23:01:09] detectron2.evaluation.evaluator INFO: Inference done 282/724. Dataloading: 0.0023 s/iter. Inference: 0.3578 s/iter. Eval: 0.0092 s/iter. Total: 0.3694 s/iter. ETA=0:02:43
[12/06 23:01:14] detectron2.evaluation.evaluator INFO: Inference done 297/724. Dataloading: 0.0023 s/iter. Inference: 0.3570 s/iter. Eval: 0.0092 s/iter. Total: 0.3685 s/iter. ETA=0:02:37
[12/06 23:01:20] detectron2.evaluation.evaluator INFO: Inference done 311/724. Dataloading: 0.0023 s/iter. Inference: 0.3572 s/iter. Eval: 0.0092 s/iter. Total: 0.3687 s/iter. ETA=0:02:32
[12/06 23:01:25] detectron2.evaluation.evaluator INFO: Inference done 325/724. Dataloading: 0.0023 s/iter. Inference: 0.3574 s/iter. Eval: 0.0092 s/iter. Total: 0.3689 s/iter. ETA=0:02:27
[12/06 23:01:30] detectron2.evaluation.evaluator INFO: Inference done 339/724. Dataloading: 0.0023 s/iter. Inference: 0.3577 s/iter. Eval: 0.0092 s/iter. Total: 0.3692 s/iter. ETA=0:02:22
[12/06 23:01:35] detectron2.evaluation.evaluator INFO: Inference done 353/724. Dataloading: 0.0023 s/iter. Inference: 0.3576 s/iter. Eval: 0.0091 s/iter. Total: 0.3691 s/iter. ETA=0:02:16
[12/06 23:01:40] detectron2.evaluation.evaluator INFO: Inference done 367/724. Dataloading: 0.0023 s/iter. Inference: 0.3575 s/iter. Eval: 0.0091 s/iter. Total: 0.3690 s/iter. ETA=0:02:11
[12/06 23:01:46] detectron2.evaluation.evaluator INFO: Inference done 374/724. Dataloading: 0.0096 s/iter. Inference: 0.3576 s/iter. Eval: 0.0091 s/iter. Total: 0.3764 s/iter. ETA=0:02:11
[12/06 23:01:51] detectron2.evaluation.evaluator INFO: Inference done 389/724. Dataloading: 0.0093 s/iter. Inference: 0.3570 s/iter. Eval: 0.0091 s/iter. Total: 0.3756 s/iter. ETA=0:02:05
[12/06 23:01:56] detectron2.evaluation.evaluator INFO: Inference done 403/724. Dataloading: 0.0091 s/iter. Inference: 0.3571 s/iter. Eval: 0.0092 s/iter. Total: 0.3754 s/iter. ETA=0:02:00
[12/06 23:02:02] detectron2.evaluation.evaluator INFO: Inference done 417/724. Dataloading: 0.0088 s/iter. Inference: 0.3575 s/iter. Eval: 0.0092 s/iter. Total: 0.3756 s/iter. ETA=0:01:55
[12/06 23:02:07] detectron2.evaluation.evaluator INFO: Inference done 431/724. Dataloading: 0.0086 s/iter. Inference: 0.3578 s/iter. Eval: 0.0092 s/iter. Total: 0.3757 s/iter. ETA=0:01:50
[12/06 23:02:12] detectron2.evaluation.evaluator INFO: Inference done 444/724. Dataloading: 0.0084 s/iter. Inference: 0.3584 s/iter. Eval: 0.0092 s/iter. Total: 0.3761 s/iter. ETA=0:01:45
[12/06 23:02:17] detectron2.evaluation.evaluator INFO: Inference done 458/724. Dataloading: 0.0082 s/iter. Inference: 0.3584 s/iter. Eval: 0.0093 s/iter. Total: 0.3760 s/iter. ETA=0:01:40
[12/06 23:02:23] detectron2.evaluation.evaluator INFO: Inference done 472/724. Dataloading: 0.0081 s/iter. Inference: 0.3589 s/iter. Eval: 0.0093 s/iter. Total: 0.3763 s/iter. ETA=0:01:34
[12/06 23:02:28] detectron2.evaluation.evaluator INFO: Inference done 486/724. Dataloading: 0.0079 s/iter. Inference: 0.3586 s/iter. Eval: 0.0093 s/iter. Total: 0.3758 s/iter. ETA=0:01:29
[12/06 23:02:33] detectron2.evaluation.evaluator INFO: Inference done 499/724. Dataloading: 0.0077 s/iter. Inference: 0.3593 s/iter. Eval: 0.0092 s/iter. Total: 0.3764 s/iter. ETA=0:01:24
[12/06 23:02:38] detectron2.evaluation.evaluator INFO: Inference done 513/724. Dataloading: 0.0076 s/iter. Inference: 0.3597 s/iter. Eval: 0.0092 s/iter. Total: 0.3766 s/iter. ETA=0:01:19
[12/06 23:02:43] detectron2.evaluation.evaluator INFO: Inference done 526/724. Dataloading: 0.0075 s/iter. Inference: 0.3600 s/iter. Eval: 0.0093 s/iter. Total: 0.3768 s/iter. ETA=0:01:14
[12/06 23:02:48] detectron2.evaluation.evaluator INFO: Inference done 540/724. Dataloading: 0.0073 s/iter. Inference: 0.3602 s/iter. Eval: 0.0093 s/iter. Total: 0.3768 s/iter. ETA=0:01:09
[12/06 23:02:54] detectron2.evaluation.evaluator INFO: Inference done 554/724. Dataloading: 0.0072 s/iter. Inference: 0.3605 s/iter. Eval: 0.0093 s/iter. Total: 0.3771 s/iter. ETA=0:01:04
[12/06 23:02:59] detectron2.evaluation.evaluator INFO: Inference done 567/724. Dataloading: 0.0071 s/iter. Inference: 0.3611 s/iter. Eval: 0.0093 s/iter. Total: 0.3776 s/iter. ETA=0:00:59
[12/06 23:03:04] detectron2.evaluation.evaluator INFO: Inference done 581/724. Dataloading: 0.0070 s/iter. Inference: 0.3615 s/iter. Eval: 0.0093 s/iter. Total: 0.3778 s/iter. ETA=0:00:54
[12/06 23:03:10] detectron2.evaluation.evaluator INFO: Inference done 595/724. Dataloading: 0.0068 s/iter. Inference: 0.3616 s/iter. Eval: 0.0093 s/iter. Total: 0.3778 s/iter. ETA=0:00:48
[12/06 23:03:15] detectron2.evaluation.evaluator INFO: Inference done 608/724. Dataloading: 0.0067 s/iter. Inference: 0.3622 s/iter. Eval: 0.0093 s/iter. Total: 0.3782 s/iter. ETA=0:00:43
[12/06 23:03:20] detectron2.evaluation.evaluator INFO: Inference done 621/724. Dataloading: 0.0066 s/iter. Inference: 0.3624 s/iter. Eval: 0.0093 s/iter. Total: 0.3784 s/iter. ETA=0:00:38
[12/06 23:03:25] detectron2.evaluation.evaluator INFO: Inference done 635/724. Dataloading: 0.0066 s/iter. Inference: 0.3626 s/iter. Eval: 0.0093 s/iter. Total: 0.3785 s/iter. ETA=0:00:33
[12/06 23:03:31] detectron2.evaluation.evaluator INFO: Inference done 649/724. Dataloading: 0.0065 s/iter. Inference: 0.3628 s/iter. Eval: 0.0092 s/iter. Total: 0.3786 s/iter. ETA=0:00:28
[12/06 23:03:36] detectron2.evaluation.evaluator INFO: Inference done 663/724. Dataloading: 0.0064 s/iter. Inference: 0.3626 s/iter. Eval: 0.0092 s/iter. Total: 0.3783 s/iter. ETA=0:00:23
[12/06 23:03:41] detectron2.evaluation.evaluator INFO: Inference done 677/724. Dataloading: 0.0063 s/iter. Inference: 0.3627 s/iter. Eval: 0.0092 s/iter. Total: 0.3783 s/iter. ETA=0:00:17
[12/06 23:03:46] detectron2.evaluation.evaluator INFO: Inference done 691/724. Dataloading: 0.0062 s/iter. Inference: 0.3628 s/iter. Eval: 0.0092 s/iter. Total: 0.3783 s/iter. ETA=0:00:12
[12/06 23:03:52] detectron2.evaluation.evaluator INFO: Inference done 705/724. Dataloading: 0.0061 s/iter. Inference: 0.3629 s/iter. Eval: 0.0092 s/iter. Total: 0.3783 s/iter. ETA=0:00:07
[12/06 23:03:57] detectron2.evaluation.evaluator INFO: Inference done 719/724. Dataloading: 0.0060 s/iter. Inference: 0.3631 s/iter. Eval: 0.0092 s/iter. Total: 0.3784 s/iter. ETA=0:00:01
[12/06 23:04:00] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:33.299353 (0.380110 s / iter per device, on 2 devices)
[12/06 23:04:00] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:20 (0.362866 s / iter per device, on 2 devices)
[12/06 23:09:48] detectron2 INFO: Rank of current process: 1. World size: 2
[12/06 23:09:49] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/06 23:09:49] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/06 23:09:49] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/06 23:10:14] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/06 23:10:14] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/06 23:10:14] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/06 23:12:55] detectron2 INFO: Rank of current process: 1. World size: 2
[12/06 23:12:55] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/06 23:12:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/06 23:12:55] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 00:08:26] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 00:08:27] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 00:08:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 00:08:27] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 00:44:10] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 00:44:11] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 00:44:11] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 00:44:11] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_pascal_ctx59_sem_seg_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 00:44:54] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 00:44:55] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 00:44:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 00:44:55] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_pascal_ctx59_sem_seg_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 00:46:42] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 00:46:42] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 00:46:42] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 00:46:42] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 09:41:55] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 09:41:55] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 09:41:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 09:41:55] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("openvocab_pascal20_sem_seg_val",[39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_pascal_ctx59_sem_seg_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 09:42:21] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 09:42:21] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 09:42:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 09:42:21] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 09:42:21] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 09:42:21] detectron2.data.common INFO: Serializing 1449 elements to byte tensors and concatenating them all ...
[12/07 09:42:21] detectron2.data.common INFO: Serialized dataset takes 1.38 MiB
[12/07 09:42:21] detectron2.evaluation.evaluator INFO: Start inference on 724 batches
[12/07 09:42:26] detectron2.evaluation.evaluator INFO: Inference done 1/724. Dataloading: 0.0391 s/iter. Inference: 5.4123 s/iter. Eval: 0.0117 s/iter. Total: 5.4654 s/iter. ETA=1:05:51
[12/07 09:42:32] detectron2.evaluation.evaluator INFO: Inference done 15/724. Dataloading: 0.0236 s/iter. Inference: 0.3494 s/iter. Eval: 0.0104 s/iter. Total: 0.3834 s/iter. ETA=0:04:31
[12/07 09:42:37] detectron2.evaluation.evaluator INFO: Inference done 29/724. Dataloading: 0.0230 s/iter. Inference: 0.3403 s/iter. Eval: 0.0101 s/iter. Total: 0.3734 s/iter. ETA=0:04:19
[12/07 09:42:42] detectron2.evaluation.evaluator INFO: Inference done 43/724. Dataloading: 0.0237 s/iter. Inference: 0.3436 s/iter. Eval: 0.0098 s/iter. Total: 0.3772 s/iter. ETA=0:04:16
[12/07 09:42:47] detectron2.evaluation.evaluator INFO: Inference done 56/724. Dataloading: 0.0234 s/iter. Inference: 0.3480 s/iter. Eval: 0.0093 s/iter. Total: 0.3808 s/iter. ETA=0:04:14
[12/07 09:42:53] detectron2.evaluation.evaluator INFO: Inference done 70/724. Dataloading: 0.0233 s/iter. Inference: 0.3466 s/iter. Eval: 0.0093 s/iter. Total: 0.3793 s/iter. ETA=0:04:08
[12/07 09:42:58] detectron2.evaluation.evaluator INFO: Inference done 83/724. Dataloading: 0.0233 s/iter. Inference: 0.3481 s/iter. Eval: 0.0093 s/iter. Total: 0.3808 s/iter. ETA=0:04:04
[12/07 09:43:03] detectron2.evaluation.evaluator INFO: Inference done 97/724. Dataloading: 0.0229 s/iter. Inference: 0.3476 s/iter. Eval: 0.0094 s/iter. Total: 0.3799 s/iter. ETA=0:03:58
[12/07 09:43:08] detectron2.evaluation.evaluator INFO: Inference done 111/724. Dataloading: 0.0226 s/iter. Inference: 0.3478 s/iter. Eval: 0.0093 s/iter. Total: 0.3797 s/iter. ETA=0:03:52
[12/07 09:43:13] detectron2.evaluation.evaluator INFO: Inference done 125/724. Dataloading: 0.0225 s/iter. Inference: 0.3477 s/iter. Eval: 0.0093 s/iter. Total: 0.3795 s/iter. ETA=0:03:47
[12/07 09:43:19] detectron2.evaluation.evaluator INFO: Inference done 138/724. Dataloading: 0.0223 s/iter. Inference: 0.3487 s/iter. Eval: 0.0092 s/iter. Total: 0.3803 s/iter. ETA=0:03:42
[12/07 09:43:24] detectron2.evaluation.evaluator INFO: Inference done 151/724. Dataloading: 0.0224 s/iter. Inference: 0.3495 s/iter. Eval: 0.0091 s/iter. Total: 0.3812 s/iter. ETA=0:03:38
[12/07 09:43:29] detectron2.evaluation.evaluator INFO: Inference done 164/724. Dataloading: 0.0224 s/iter. Inference: 0.3503 s/iter. Eval: 0.0091 s/iter. Total: 0.3819 s/iter. ETA=0:03:33
[12/07 09:43:34] detectron2.evaluation.evaluator INFO: Inference done 177/724. Dataloading: 0.0222 s/iter. Inference: 0.3516 s/iter. Eval: 0.0092 s/iter. Total: 0.3831 s/iter. ETA=0:03:29
[12/07 09:43:39] detectron2.evaluation.evaluator INFO: Inference done 190/724. Dataloading: 0.0223 s/iter. Inference: 0.3523 s/iter. Eval: 0.0092 s/iter. Total: 0.3839 s/iter. ETA=0:03:24
[12/07 09:43:44] detectron2.evaluation.evaluator INFO: Inference done 204/724. Dataloading: 0.0226 s/iter. Inference: 0.3516 s/iter. Eval: 0.0092 s/iter. Total: 0.3834 s/iter. ETA=0:03:19
[12/07 09:43:50] detectron2.evaluation.evaluator INFO: Inference done 218/724. Dataloading: 0.0226 s/iter. Inference: 0.3512 s/iter. Eval: 0.0092 s/iter. Total: 0.3831 s/iter. ETA=0:03:13
[12/07 09:43:55] detectron2.evaluation.evaluator INFO: Inference done 230/724. Dataloading: 0.0227 s/iter. Inference: 0.3530 s/iter. Eval: 0.0092 s/iter. Total: 0.3850 s/iter. ETA=0:03:10
[12/07 09:44:00] detectron2.evaluation.evaluator INFO: Inference done 243/724. Dataloading: 0.0226 s/iter. Inference: 0.3537 s/iter. Eval: 0.0092 s/iter. Total: 0.3856 s/iter. ETA=0:03:05
[12/07 09:44:05] detectron2.evaluation.evaluator INFO: Inference done 256/724. Dataloading: 0.0227 s/iter. Inference: 0.3543 s/iter. Eval: 0.0091 s/iter. Total: 0.3862 s/iter. ETA=0:03:00
[12/07 09:44:10] detectron2.evaluation.evaluator INFO: Inference done 269/724. Dataloading: 0.0226 s/iter. Inference: 0.3546 s/iter. Eval: 0.0090 s/iter. Total: 0.3864 s/iter. ETA=0:02:55
[12/07 09:44:15] detectron2.evaluation.evaluator INFO: Inference done 282/724. Dataloading: 0.0227 s/iter. Inference: 0.3546 s/iter. Eval: 0.0090 s/iter. Total: 0.3864 s/iter. ETA=0:02:50
[12/07 09:44:20] detectron2.evaluation.evaluator INFO: Inference done 296/724. Dataloading: 0.0228 s/iter. Inference: 0.3542 s/iter. Eval: 0.0090 s/iter. Total: 0.3860 s/iter. ETA=0:02:45
[12/07 09:44:25] detectron2.evaluation.evaluator INFO: Inference done 309/724. Dataloading: 0.0228 s/iter. Inference: 0.3542 s/iter. Eval: 0.0090 s/iter. Total: 0.3860 s/iter. ETA=0:02:40
[12/07 09:44:30] detectron2.evaluation.evaluator INFO: Inference done 322/724. Dataloading: 0.0228 s/iter. Inference: 0.3546 s/iter. Eval: 0.0090 s/iter. Total: 0.3865 s/iter. ETA=0:02:35
[12/07 09:44:36] detectron2.evaluation.evaluator INFO: Inference done 335/724. Dataloading: 0.0228 s/iter. Inference: 0.3549 s/iter. Eval: 0.0090 s/iter. Total: 0.3868 s/iter. ETA=0:02:30
[12/07 09:44:41] detectron2.evaluation.evaluator INFO: Inference done 349/724. Dataloading: 0.0226 s/iter. Inference: 0.3550 s/iter. Eval: 0.0090 s/iter. Total: 0.3867 s/iter. ETA=0:02:24
[12/07 09:44:46] detectron2.evaluation.evaluator INFO: Inference done 363/724. Dataloading: 0.0226 s/iter. Inference: 0.3549 s/iter. Eval: 0.0090 s/iter. Total: 0.3865 s/iter. ETA=0:02:19
[12/07 09:44:51] detectron2.evaluation.evaluator INFO: Inference done 376/724. Dataloading: 0.0226 s/iter. Inference: 0.3549 s/iter. Eval: 0.0090 s/iter. Total: 0.3866 s/iter. ETA=0:02:14
[12/07 09:44:57] detectron2.evaluation.evaluator INFO: Inference done 390/724. Dataloading: 0.0227 s/iter. Inference: 0.3546 s/iter. Eval: 0.0090 s/iter. Total: 0.3864 s/iter. ETA=0:02:09
[12/07 09:45:02] detectron2.evaluation.evaluator INFO: Inference done 403/724. Dataloading: 0.0227 s/iter. Inference: 0.3548 s/iter. Eval: 0.0091 s/iter. Total: 0.3866 s/iter. ETA=0:02:04
[12/07 09:45:07] detectron2.evaluation.evaluator INFO: Inference done 416/724. Dataloading: 0.0227 s/iter. Inference: 0.3550 s/iter. Eval: 0.0090 s/iter. Total: 0.3868 s/iter. ETA=0:01:59
[12/07 09:45:12] detectron2.evaluation.evaluator INFO: Inference done 429/724. Dataloading: 0.0226 s/iter. Inference: 0.3554 s/iter. Eval: 0.0091 s/iter. Total: 0.3872 s/iter. ETA=0:01:54
[12/07 09:45:17] detectron2.evaluation.evaluator INFO: Inference done 442/724. Dataloading: 0.0226 s/iter. Inference: 0.3559 s/iter. Eval: 0.0091 s/iter. Total: 0.3877 s/iter. ETA=0:01:49
[12/07 09:45:22] detectron2.evaluation.evaluator INFO: Inference done 455/724. Dataloading: 0.0226 s/iter. Inference: 0.3559 s/iter. Eval: 0.0091 s/iter. Total: 0.3877 s/iter. ETA=0:01:44
[12/07 09:45:27] detectron2.evaluation.evaluator INFO: Inference done 468/724. Dataloading: 0.0226 s/iter. Inference: 0.3561 s/iter. Eval: 0.0091 s/iter. Total: 0.3878 s/iter. ETA=0:01:39
[12/07 09:45:33] detectron2.evaluation.evaluator INFO: Inference done 481/724. Dataloading: 0.0227 s/iter. Inference: 0.3561 s/iter. Eval: 0.0091 s/iter. Total: 0.3879 s/iter. ETA=0:01:34
[12/07 09:45:38] detectron2.evaluation.evaluator INFO: Inference done 494/724. Dataloading: 0.0226 s/iter. Inference: 0.3565 s/iter. Eval: 0.0091 s/iter. Total: 0.3882 s/iter. ETA=0:01:29
[12/07 09:45:43] detectron2.evaluation.evaluator INFO: Inference done 507/724. Dataloading: 0.0227 s/iter. Inference: 0.3566 s/iter. Eval: 0.0090 s/iter. Total: 0.3884 s/iter. ETA=0:01:24
[12/07 09:45:48] detectron2.evaluation.evaluator INFO: Inference done 520/724. Dataloading: 0.0227 s/iter. Inference: 0.3568 s/iter. Eval: 0.0091 s/iter. Total: 0.3886 s/iter. ETA=0:01:19
[12/07 09:45:53] detectron2.evaluation.evaluator INFO: Inference done 533/724. Dataloading: 0.0227 s/iter. Inference: 0.3570 s/iter. Eval: 0.0091 s/iter. Total: 0.3888 s/iter. ETA=0:01:14
[12/07 09:45:58] detectron2.evaluation.evaluator INFO: Inference done 546/724. Dataloading: 0.0227 s/iter. Inference: 0.3572 s/iter. Eval: 0.0091 s/iter. Total: 0.3891 s/iter. ETA=0:01:09
[12/07 09:46:04] detectron2.evaluation.evaluator INFO: Inference done 559/724. Dataloading: 0.0227 s/iter. Inference: 0.3575 s/iter. Eval: 0.0091 s/iter. Total: 0.3894 s/iter. ETA=0:01:04
[12/07 09:46:09] detectron2.evaluation.evaluator INFO: Inference done 572/724. Dataloading: 0.0227 s/iter. Inference: 0.3579 s/iter. Eval: 0.0091 s/iter. Total: 0.3898 s/iter. ETA=0:00:59
[12/07 09:46:14] detectron2.evaluation.evaluator INFO: Inference done 585/724. Dataloading: 0.0227 s/iter. Inference: 0.3581 s/iter. Eval: 0.0091 s/iter. Total: 0.3899 s/iter. ETA=0:00:54
[12/07 09:46:19] detectron2.evaluation.evaluator INFO: Inference done 598/724. Dataloading: 0.0227 s/iter. Inference: 0.3581 s/iter. Eval: 0.0091 s/iter. Total: 0.3899 s/iter. ETA=0:00:49
[12/07 09:46:24] detectron2.evaluation.evaluator INFO: Inference done 611/724. Dataloading: 0.0226 s/iter. Inference: 0.3585 s/iter. Eval: 0.0091 s/iter. Total: 0.3904 s/iter. ETA=0:00:44
[12/07 09:46:30] detectron2.evaluation.evaluator INFO: Inference done 624/724. Dataloading: 0.0226 s/iter. Inference: 0.3588 s/iter. Eval: 0.0091 s/iter. Total: 0.3906 s/iter. ETA=0:00:39
[12/07 09:46:35] detectron2.evaluation.evaluator INFO: Inference done 637/724. Dataloading: 0.0226 s/iter. Inference: 0.3588 s/iter. Eval: 0.0091 s/iter. Total: 0.3906 s/iter. ETA=0:00:33
[12/07 09:46:40] detectron2.evaluation.evaluator INFO: Inference done 651/724. Dataloading: 0.0225 s/iter. Inference: 0.3588 s/iter. Eval: 0.0091 s/iter. Total: 0.3904 s/iter. ETA=0:00:28
[12/07 09:46:45] detectron2.evaluation.evaluator INFO: Inference done 665/724. Dataloading: 0.0225 s/iter. Inference: 0.3586 s/iter. Eval: 0.0091 s/iter. Total: 0.3902 s/iter. ETA=0:00:23
[12/07 09:46:51] detectron2.evaluation.evaluator INFO: Inference done 678/724. Dataloading: 0.0225 s/iter. Inference: 0.3588 s/iter. Eval: 0.0091 s/iter. Total: 0.3904 s/iter. ETA=0:00:17
[12/07 09:46:56] detectron2.evaluation.evaluator INFO: Inference done 691/724. Dataloading: 0.0224 s/iter. Inference: 0.3588 s/iter. Eval: 0.0091 s/iter. Total: 0.3903 s/iter. ETA=0:00:12
[12/07 09:47:01] detectron2.evaluation.evaluator INFO: Inference done 704/724. Dataloading: 0.0224 s/iter. Inference: 0.3588 s/iter. Eval: 0.0091 s/iter. Total: 0.3903 s/iter. ETA=0:00:07
[12/07 09:47:06] detectron2.evaluation.evaluator INFO: Inference done 717/724. Dataloading: 0.0223 s/iter. Inference: 0.3589 s/iter. Eval: 0.0091 s/iter. Total: 0.3904 s/iter. ETA=0:00:02
[12/07 09:47:08] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:40.548932 (0.390193 s / iter per device, on 2 devices)
[12/07 09:47:08] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:17 (0.358718 s / iter per device, on 2 devices)
[12/07 09:47:13] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 09:47:13] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 09:47:13] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 09:47:13] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 09:47:13] detectron2.evaluation.evaluator INFO: Start inference on 1000 batches
[12/07 09:48:54] detectron2 INFO: Rank of current process: 1. World size: 4
[12/07 09:48:55] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 09:48:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 09:48:55] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 09:49:23] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 09:49:23] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 09:49:23] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 09:49:23] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 09:49:23] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 09:49:23] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 09:49:23] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 09:49:23] detectron2.evaluation.evaluator INFO: Start inference on 500 batches
[12/07 09:50:50] detectron2.evaluation.evaluator INFO: Inference done 1/500. Dataloading: 0.0481 s/iter. Inference: 86.7273 s/iter. Eval: 0.0522 s/iter. Total: 86.8306 s/iter. ETA=12:02:08
[12/07 09:50:55] detectron2.evaluation.evaluator INFO: Inference done 13/500. Dataloading: 0.0231 s/iter. Inference: 0.3624 s/iter. Eval: 0.0230 s/iter. Total: 0.4086 s/iter. ETA=0:03:18
[12/07 09:51:00] detectron2.evaluation.evaluator INFO: Inference done 25/500. Dataloading: 0.0255 s/iter. Inference: 0.3755 s/iter. Eval: 0.0283 s/iter. Total: 0.4293 s/iter. ETA=0:03:23
[12/07 09:51:05] detectron2.evaluation.evaluator INFO: Inference done 37/500. Dataloading: 0.0261 s/iter. Inference: 0.3779 s/iter. Eval: 0.0280 s/iter. Total: 0.4320 s/iter. ETA=0:03:20
[12/07 09:51:10] detectron2.evaluation.evaluator INFO: Inference done 49/500. Dataloading: 0.0264 s/iter. Inference: 0.3780 s/iter. Eval: 0.0270 s/iter. Total: 0.4315 s/iter. ETA=0:03:14
[12/07 09:51:16] detectron2.evaluation.evaluator INFO: Inference done 64/500. Dataloading: 0.0249 s/iter. Inference: 0.3623 s/iter. Eval: 0.0245 s/iter. Total: 0.4118 s/iter. ETA=0:02:59
[12/07 09:51:21] detectron2.evaluation.evaluator INFO: Inference done 77/500. Dataloading: 0.0245 s/iter. Inference: 0.3600 s/iter. Eval: 0.0245 s/iter. Total: 0.4092 s/iter. ETA=0:02:53
[12/07 09:51:26] detectron2.evaluation.evaluator INFO: Inference done 89/500. Dataloading: 0.0249 s/iter. Inference: 0.3607 s/iter. Eval: 0.0250 s/iter. Total: 0.4107 s/iter. ETA=0:02:48
[12/07 09:51:31] detectron2.evaluation.evaluator INFO: Inference done 101/500. Dataloading: 0.0258 s/iter. Inference: 0.3635 s/iter. Eval: 0.0252 s/iter. Total: 0.4146 s/iter. ETA=0:02:45
[12/07 09:51:37] detectron2.evaluation.evaluator INFO: Inference done 116/500. Dataloading: 0.0252 s/iter. Inference: 0.3576 s/iter. Eval: 0.0240 s/iter. Total: 0.4069 s/iter. ETA=0:02:36
[12/07 09:51:42] detectron2.evaluation.evaluator INFO: Inference done 130/500. Dataloading: 0.0246 s/iter. Inference: 0.3559 s/iter. Eval: 0.0228 s/iter. Total: 0.4033 s/iter. ETA=0:02:29
[12/07 09:51:47] detectron2.evaluation.evaluator INFO: Inference done 143/500. Dataloading: 0.0244 s/iter. Inference: 0.3566 s/iter. Eval: 0.0222 s/iter. Total: 0.4032 s/iter. ETA=0:02:23
[12/07 09:51:52] detectron2.evaluation.evaluator INFO: Inference done 156/500. Dataloading: 0.0239 s/iter. Inference: 0.3562 s/iter. Eval: 0.0219 s/iter. Total: 0.4020 s/iter. ETA=0:02:18
[12/07 09:51:57] detectron2.evaluation.evaluator INFO: Inference done 169/500. Dataloading: 0.0235 s/iter. Inference: 0.3559 s/iter. Eval: 0.0215 s/iter. Total: 0.4009 s/iter. ETA=0:02:12
[12/07 09:52:02] detectron2.evaluation.evaluator INFO: Inference done 181/500. Dataloading: 0.0238 s/iter. Inference: 0.3574 s/iter. Eval: 0.0214 s/iter. Total: 0.4026 s/iter. ETA=0:02:08
[12/07 09:52:07] detectron2.evaluation.evaluator INFO: Inference done 194/500. Dataloading: 0.0236 s/iter. Inference: 0.3573 s/iter. Eval: 0.0212 s/iter. Total: 0.4021 s/iter. ETA=0:02:03
[12/07 09:52:12] detectron2.evaluation.evaluator INFO: Inference done 207/500. Dataloading: 0.0234 s/iter. Inference: 0.3566 s/iter. Eval: 0.0211 s/iter. Total: 0.4012 s/iter. ETA=0:01:57
[12/07 09:52:18] detectron2.evaluation.evaluator INFO: Inference done 219/500. Dataloading: 0.0233 s/iter. Inference: 0.3579 s/iter. Eval: 0.0209 s/iter. Total: 0.4022 s/iter. ETA=0:01:53
[12/07 09:52:23] detectron2.evaluation.evaluator INFO: Inference done 233/500. Dataloading: 0.0230 s/iter. Inference: 0.3571 s/iter. Eval: 0.0206 s/iter. Total: 0.4008 s/iter. ETA=0:01:47
[12/07 09:52:28] detectron2.evaluation.evaluator INFO: Inference done 246/500. Dataloading: 0.0227 s/iter. Inference: 0.3580 s/iter. Eval: 0.0202 s/iter. Total: 0.4010 s/iter. ETA=0:01:41
[12/07 09:52:33] detectron2.evaluation.evaluator INFO: Inference done 262/500. Dataloading: 0.0225 s/iter. Inference: 0.3538 s/iter. Eval: 0.0198 s/iter. Total: 0.3962 s/iter. ETA=0:01:34
[12/07 09:52:39] detectron2.evaluation.evaluator INFO: Inference done 278/500. Dataloading: 0.0222 s/iter. Inference: 0.3511 s/iter. Eval: 0.0194 s/iter. Total: 0.3928 s/iter. ETA=0:01:27
[12/07 09:52:44] detectron2.evaluation.evaluator INFO: Inference done 291/500. Dataloading: 0.0223 s/iter. Inference: 0.3518 s/iter. Eval: 0.0197 s/iter. Total: 0.3938 s/iter. ETA=0:01:22
[12/07 09:52:49] detectron2.evaluation.evaluator INFO: Inference done 304/500. Dataloading: 0.0224 s/iter. Inference: 0.3522 s/iter. Eval: 0.0200 s/iter. Total: 0.3946 s/iter. ETA=0:01:17
[12/07 09:52:55] detectron2.evaluation.evaluator INFO: Inference done 317/500. Dataloading: 0.0224 s/iter. Inference: 0.3525 s/iter. Eval: 0.0203 s/iter. Total: 0.3953 s/iter. ETA=0:01:12
[12/07 09:53:00] detectron2.evaluation.evaluator INFO: Inference done 330/500. Dataloading: 0.0224 s/iter. Inference: 0.3529 s/iter. Eval: 0.0205 s/iter. Total: 0.3958 s/iter. ETA=0:01:07
[12/07 09:53:05] detectron2.evaluation.evaluator INFO: Inference done 343/500. Dataloading: 0.0223 s/iter. Inference: 0.3535 s/iter. Eval: 0.0207 s/iter. Total: 0.3966 s/iter. ETA=0:01:02
[12/07 09:53:11] detectron2.evaluation.evaluator INFO: Inference done 356/500. Dataloading: 0.0223 s/iter. Inference: 0.3538 s/iter. Eval: 0.0208 s/iter. Total: 0.3970 s/iter. ETA=0:00:57
[12/07 09:53:16] detectron2.evaluation.evaluator INFO: Inference done 374/500. Dataloading: 0.0221 s/iter. Inference: 0.3492 s/iter. Eval: 0.0203 s/iter. Total: 0.3918 s/iter. ETA=0:00:49
[12/07 09:53:21] detectron2.evaluation.evaluator INFO: Inference done 387/500. Dataloading: 0.0221 s/iter. Inference: 0.3492 s/iter. Eval: 0.0202 s/iter. Total: 0.3916 s/iter. ETA=0:00:44
[12/07 09:53:26] detectron2.evaluation.evaluator INFO: Inference done 401/500. Dataloading: 0.0221 s/iter. Inference: 0.3484 s/iter. Eval: 0.0200 s/iter. Total: 0.3906 s/iter. ETA=0:00:38
[12/07 09:53:31] detectron2.evaluation.evaluator INFO: Inference done 415/500. Dataloading: 0.0221 s/iter. Inference: 0.3484 s/iter. Eval: 0.0198 s/iter. Total: 0.3904 s/iter. ETA=0:00:33
[12/07 09:53:37] detectron2.evaluation.evaluator INFO: Inference done 427/500. Dataloading: 0.0221 s/iter. Inference: 0.3491 s/iter. Eval: 0.0198 s/iter. Total: 0.3912 s/iter. ETA=0:00:28
[12/07 09:53:42] detectron2.evaluation.evaluator INFO: Inference done 439/500. Dataloading: 0.0223 s/iter. Inference: 0.3497 s/iter. Eval: 0.0200 s/iter. Total: 0.3920 s/iter. ETA=0:00:23
[12/07 09:53:47] detectron2.evaluation.evaluator INFO: Inference done 452/500. Dataloading: 0.0223 s/iter. Inference: 0.3496 s/iter. Eval: 0.0200 s/iter. Total: 0.3921 s/iter. ETA=0:00:18
[12/07 09:53:52] detectron2.evaluation.evaluator INFO: Inference done 466/500. Dataloading: 0.0224 s/iter. Inference: 0.3491 s/iter. Eval: 0.0200 s/iter. Total: 0.3916 s/iter. ETA=0:00:13
[12/07 09:53:57] detectron2.evaluation.evaluator INFO: Inference done 481/500. Dataloading: 0.0224 s/iter. Inference: 0.3481 s/iter. Eval: 0.0199 s/iter. Total: 0.3906 s/iter. ETA=0:00:07
[12/07 09:54:03] detectron2.evaluation.evaluator INFO: Inference done 495/500. Dataloading: 0.0225 s/iter. Inference: 0.3478 s/iter. Eval: 0.0199 s/iter. Total: 0.3903 s/iter. ETA=0:00:01
[12/07 09:54:05] detectron2.evaluation.evaluator INFO: Total inference time: 0:03:13.106953 (0.390115 s / iter per device, on 4 devices)
[12/07 09:54:05] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:52 (0.347652 s / iter per device, on 4 devices)
[12/07 09:58:46] detectron2 INFO: Rank of current process: 1. World size: 4
[12/07 09:58:47] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 09:58:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 09:58:47] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 09:59:32] detectron2 INFO: Rank of current process: 1. World size: 3
[12/07 09:59:33] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 09:59:33] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 09:59:33] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 10:07:48] detectron2 INFO: Rank of current process: 1. World size: 3
[12/07 10:07:48] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2                        NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 10:07:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=3, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 10:07:48] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 10:08:26] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 10:08:26] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 10:08:26] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 10:08:26] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 10:08:26] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 10:08:26] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 10:08:26] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 10:08:26] detectron2.evaluation.evaluator INFO: Start inference on 667 batches
[12/07 10:09:47] detectron2.evaluation.evaluator INFO: Inference done 1/667. Dataloading: 0.0227 s/iter. Inference: 80.8242 s/iter. Eval: 0.0210 s/iter. Total: 80.8706 s/iter. ETA=14:57:39
[12/07 10:09:53] detectron2.evaluation.evaluator INFO: Inference done 14/667. Dataloading: 0.0171 s/iter. Inference: 0.3601 s/iter. Eval: 0.0199 s/iter. Total: 0.3972 s/iter. ETA=0:04:19
[12/07 10:09:58] detectron2.evaluation.evaluator INFO: Inference done 28/667. Dataloading: 0.0181 s/iter. Inference: 0.3488 s/iter. Eval: 0.0191 s/iter. Total: 0.3860 s/iter. ETA=0:04:06
[12/07 10:10:03] detectron2.evaluation.evaluator INFO: Inference done 42/667. Dataloading: 0.0182 s/iter. Inference: 0.3480 s/iter. Eval: 0.0197 s/iter. Total: 0.3860 s/iter. ETA=0:04:01
[12/07 10:10:09] detectron2.evaluation.evaluator INFO: Inference done 55/667. Dataloading: 0.0181 s/iter. Inference: 0.3546 s/iter. Eval: 0.0193 s/iter. Total: 0.3920 s/iter. ETA=0:03:59
[12/07 10:10:14] detectron2.evaluation.evaluator INFO: Inference done 69/667. Dataloading: 0.0176 s/iter. Inference: 0.3497 s/iter. Eval: 0.0179 s/iter. Total: 0.3853 s/iter. ETA=0:03:50
[12/07 10:10:19] detectron2.evaluation.evaluator INFO: Inference done 83/667. Dataloading: 0.0177 s/iter. Inference: 0.3482 s/iter. Eval: 0.0175 s/iter. Total: 0.3834 s/iter. ETA=0:03:43
[12/07 10:10:24] detectron2.evaluation.evaluator INFO: Inference done 101/667. Dataloading: 0.0170 s/iter. Inference: 0.3326 s/iter. Eval: 0.0162 s/iter. Total: 0.3658 s/iter. ETA=0:03:27
[12/07 10:10:29] detectron2.evaluation.evaluator INFO: Inference done 115/667. Dataloading: 0.0170 s/iter. Inference: 0.3323 s/iter. Eval: 0.0164 s/iter. Total: 0.3658 s/iter. ETA=0:03:21
[12/07 10:10:34] detectron2.evaluation.evaluator INFO: Inference done 128/667. Dataloading: 0.0173 s/iter. Inference: 0.3349 s/iter. Eval: 0.0172 s/iter. Total: 0.3694 s/iter. ETA=0:03:19
[12/07 10:10:40] detectron2.evaluation.evaluator INFO: Inference done 141/667. Dataloading: 0.0175 s/iter. Inference: 0.3366 s/iter. Eval: 0.0179 s/iter. Total: 0.3721 s/iter. ETA=0:03:15
[12/07 10:10:45] detectron2.evaluation.evaluator INFO: Inference done 154/667. Dataloading: 0.0177 s/iter. Inference: 0.3381 s/iter. Eval: 0.0185 s/iter. Total: 0.3743 s/iter. ETA=0:03:12
[12/07 10:10:50] detectron2.evaluation.evaluator INFO: Inference done 167/667. Dataloading: 0.0179 s/iter. Inference: 0.3393 s/iter. Eval: 0.0190 s/iter. Total: 0.3762 s/iter. ETA=0:03:08
[12/07 10:10:55] detectron2.evaluation.evaluator INFO: Inference done 180/667. Dataloading: 0.0181 s/iter. Inference: 0.3408 s/iter. Eval: 0.0195 s/iter. Total: 0.3784 s/iter. ETA=0:03:04
[12/07 10:11:00] detectron2.evaluation.evaluator INFO: Inference done 193/667. Dataloading: 0.0182 s/iter. Inference: 0.3418 s/iter. Eval: 0.0197 s/iter. Total: 0.3797 s/iter. ETA=0:02:59
[12/07 10:11:06] detectron2.evaluation.evaluator INFO: Inference done 212/667. Dataloading: 0.0177 s/iter. Inference: 0.3338 s/iter. Eval: 0.0187 s/iter. Total: 0.3703 s/iter. ETA=0:02:48
[12/07 10:11:11] detectron2.evaluation.evaluator INFO: Inference done 225/667. Dataloading: 0.0177 s/iter. Inference: 0.3355 s/iter. Eval: 0.0186 s/iter. Total: 0.3718 s/iter. ETA=0:02:44
[12/07 10:11:16] detectron2.evaluation.evaluator INFO: Inference done 240/667. Dataloading: 0.0176 s/iter. Inference: 0.3339 s/iter. Eval: 0.0182 s/iter. Total: 0.3697 s/iter. ETA=0:02:37
[12/07 10:11:21] detectron2.evaluation.evaluator INFO: Inference done 254/667. Dataloading: 0.0176 s/iter. Inference: 0.3346 s/iter. Eval: 0.0182 s/iter. Total: 0.3704 s/iter. ETA=0:02:32
[12/07 10:11:26] detectron2.evaluation.evaluator INFO: Inference done 267/667. Dataloading: 0.0176 s/iter. Inference: 0.3361 s/iter. Eval: 0.0183 s/iter. Total: 0.3721 s/iter. ETA=0:02:28
[12/07 10:11:32] detectron2.evaluation.evaluator INFO: Inference done 281/667. Dataloading: 0.0176 s/iter. Inference: 0.3362 s/iter. Eval: 0.0184 s/iter. Total: 0.3722 s/iter. ETA=0:02:23
[12/07 10:11:37] detectron2.evaluation.evaluator INFO: Inference done 296/667. Dataloading: 0.0176 s/iter. Inference: 0.3356 s/iter. Eval: 0.0184 s/iter. Total: 0.3716 s/iter. ETA=0:02:17
[12/07 10:15:30] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 10:15:31] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 10:15:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 10:15:31] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 10:15:56] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 10:15:56] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 10:15:56] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 10:15:56] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 10:15:56] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 10:15:56] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 10:15:56] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 10:15:56] detectron2.evaluation.evaluator INFO: Start inference on 1000 batches
[12/07 10:17:19] detectron2.evaluation.evaluator INFO: Inference done 1/1000. Dataloading: 0.0263 s/iter. Inference: 82.5654 s/iter. Eval: 0.0253 s/iter. Total: 82.6193 s/iter. ETA=22:55:36
[12/07 10:17:24] detectron2.evaluation.evaluator INFO: Inference done 14/1000. Dataloading: 0.0164 s/iter. Inference: 0.3480 s/iter. Eval: 0.0224 s/iter. Total: 0.3868 s/iter. ETA=0:06:21
[12/07 10:17:29] detectron2.evaluation.evaluator INFO: Inference done 28/1000. Dataloading: 0.0171 s/iter. Inference: 0.3416 s/iter. Eval: 0.0207 s/iter. Total: 0.3794 s/iter. ETA=0:06:08
[12/07 10:17:35] detectron2.evaluation.evaluator INFO: Inference done 41/1000. Dataloading: 0.0178 s/iter. Inference: 0.3497 s/iter. Eval: 0.0216 s/iter. Total: 0.3892 s/iter. ETA=0:06:13
[12/07 10:17:40] detectron2.evaluation.evaluator INFO: Inference done 54/1000. Dataloading: 0.0177 s/iter. Inference: 0.3528 s/iter. Eval: 0.0204 s/iter. Total: 0.3910 s/iter. ETA=0:06:09
[12/07 10:17:45] detectron2.evaluation.evaluator INFO: Inference done 67/1000. Dataloading: 0.0175 s/iter. Inference: 0.3536 s/iter. Eval: 0.0193 s/iter. Total: 0.3905 s/iter. ETA=0:06:04
[12/07 10:17:50] detectron2.evaluation.evaluator INFO: Inference done 80/1000. Dataloading: 0.0176 s/iter. Inference: 0.3539 s/iter. Eval: 0.0195 s/iter. Total: 0.3911 s/iter. ETA=0:05:59
[12/07 10:17:55] detectron2.evaluation.evaluator INFO: Inference done 94/1000. Dataloading: 0.0177 s/iter. Inference: 0.3509 s/iter. Eval: 0.0198 s/iter. Total: 0.3885 s/iter. ETA=0:05:51
[12/07 10:18:01] detectron2.evaluation.evaluator INFO: Inference done 109/1000. Dataloading: 0.0176 s/iter. Inference: 0.3465 s/iter. Eval: 0.0199 s/iter. Total: 0.3841 s/iter. ETA=0:05:42
[12/07 10:18:06] detectron2.evaluation.evaluator INFO: Inference done 123/1000. Dataloading: 0.0175 s/iter. Inference: 0.3448 s/iter. Eval: 0.0194 s/iter. Total: 0.3818 s/iter. ETA=0:05:34
[12/07 10:18:11] detectron2.evaluation.evaluator INFO: Inference done 136/1000. Dataloading: 0.0177 s/iter. Inference: 0.3458 s/iter. Eval: 0.0199 s/iter. Total: 0.3834 s/iter. ETA=0:05:31
[12/07 10:18:16] detectron2.evaluation.evaluator INFO: Inference done 150/1000. Dataloading: 0.0176 s/iter. Inference: 0.3458 s/iter. Eval: 0.0198 s/iter. Total: 0.3833 s/iter. ETA=0:05:25
[12/07 10:18:22] detectron2.evaluation.evaluator INFO: Inference done 164/1000. Dataloading: 0.0176 s/iter. Inference: 0.3463 s/iter. Eval: 0.0197 s/iter. Total: 0.3837 s/iter. ETA=0:05:20
[12/07 10:18:27] detectron2.evaluation.evaluator INFO: Inference done 177/1000. Dataloading: 0.0177 s/iter. Inference: 0.3473 s/iter. Eval: 0.0200 s/iter. Total: 0.3851 s/iter. ETA=0:05:16
[12/07 10:18:32] detectron2.evaluation.evaluator INFO: Inference done 190/1000. Dataloading: 0.0177 s/iter. Inference: 0.3485 s/iter. Eval: 0.0201 s/iter. Total: 0.3864 s/iter. ETA=0:05:12
[12/07 10:18:37] detectron2.evaluation.evaluator INFO: Inference done 205/1000. Dataloading: 0.0177 s/iter. Inference: 0.3453 s/iter. Eval: 0.0197 s/iter. Total: 0.3827 s/iter. ETA=0:05:04
[12/07 10:18:42] detectron2.evaluation.evaluator INFO: Inference done 220/1000. Dataloading: 0.0175 s/iter. Inference: 0.3432 s/iter. Eval: 0.0192 s/iter. Total: 0.3800 s/iter. ETA=0:04:56
[12/07 10:18:48] detectron2.evaluation.evaluator INFO: Inference done 233/1000. Dataloading: 0.0176 s/iter. Inference: 0.3444 s/iter. Eval: 0.0192 s/iter. Total: 0.3813 s/iter. ETA=0:04:52
[12/07 10:18:53] detectron2.evaluation.evaluator INFO: Inference done 247/1000. Dataloading: 0.0175 s/iter. Inference: 0.3443 s/iter. Eval: 0.0191 s/iter. Total: 0.3811 s/iter. ETA=0:04:46
[12/07 10:18:58] detectron2.evaluation.evaluator INFO: Inference done 263/1000. Dataloading: 0.0174 s/iter. Inference: 0.3410 s/iter. Eval: 0.0188 s/iter. Total: 0.3773 s/iter. ETA=0:04:38
[12/07 10:19:03] detectron2.evaluation.evaluator INFO: Inference done 277/1000. Dataloading: 0.0174 s/iter. Inference: 0.3399 s/iter. Eval: 0.0189 s/iter. Total: 0.3763 s/iter. ETA=0:04:32
[12/07 10:19:08] detectron2.evaluation.evaluator INFO: Inference done 292/1000. Dataloading: 0.0174 s/iter. Inference: 0.3386 s/iter. Eval: 0.0188 s/iter. Total: 0.3748 s/iter. ETA=0:04:25
[12/07 10:19:14] detectron2.evaluation.evaluator INFO: Inference done 306/1000. Dataloading: 0.0173 s/iter. Inference: 0.3391 s/iter. Eval: 0.0186 s/iter. Total: 0.3752 s/iter. ETA=0:04:20
[12/07 10:19:19] detectron2.evaluation.evaluator INFO: Inference done 321/1000. Dataloading: 0.0173 s/iter. Inference: 0.3381 s/iter. Eval: 0.0187 s/iter. Total: 0.3743 s/iter. ETA=0:04:14
[12/07 10:19:24] detectron2.evaluation.evaluator INFO: Inference done 334/1000. Dataloading: 0.0174 s/iter. Inference: 0.3390 s/iter. Eval: 0.0189 s/iter. Total: 0.3753 s/iter. ETA=0:04:09
[12/07 10:19:29] detectron2.evaluation.evaluator INFO: Inference done 347/1000. Dataloading: 0.0174 s/iter. Inference: 0.3399 s/iter. Eval: 0.0190 s/iter. Total: 0.3764 s/iter. ETA=0:04:05
[12/07 10:19:34] detectron2.evaluation.evaluator INFO: Inference done 364/1000. Dataloading: 0.0172 s/iter. Inference: 0.3368 s/iter. Eval: 0.0185 s/iter. Total: 0.3726 s/iter. ETA=0:03:56
[12/07 10:19:39] detectron2.evaluation.evaluator INFO: Inference done 377/1000. Dataloading: 0.0172 s/iter. Inference: 0.3372 s/iter. Eval: 0.0186 s/iter. Total: 0.3731 s/iter. ETA=0:03:52
[12/07 10:19:45] detectron2.evaluation.evaluator INFO: Inference done 390/1000. Dataloading: 0.0173 s/iter. Inference: 0.3385 s/iter. Eval: 0.0188 s/iter. Total: 0.3747 s/iter. ETA=0:03:48
[12/07 10:19:50] detectron2.evaluation.evaluator INFO: Inference done 403/1000. Dataloading: 0.0174 s/iter. Inference: 0.3396 s/iter. Eval: 0.0187 s/iter. Total: 0.3757 s/iter. ETA=0:03:44
[12/07 10:19:55] detectron2.evaluation.evaluator INFO: Inference done 422/1000. Dataloading: 0.0172 s/iter. Inference: 0.3357 s/iter. Eval: 0.0183 s/iter. Total: 0.3713 s/iter. ETA=0:03:34
[12/07 10:20:00] detectron2.evaluation.evaluator INFO: Inference done 435/1000. Dataloading: 0.0172 s/iter. Inference: 0.3361 s/iter. Eval: 0.0184 s/iter. Total: 0.3717 s/iter. ETA=0:03:30
[12/07 10:20:06] detectron2.evaluation.evaluator INFO: Inference done 448/1000. Dataloading: 0.0172 s/iter. Inference: 0.3369 s/iter. Eval: 0.0183 s/iter. Total: 0.3725 s/iter. ETA=0:03:25
[12/07 10:20:11] detectron2.evaluation.evaluator INFO: Inference done 462/1000. Dataloading: 0.0172 s/iter. Inference: 0.3371 s/iter. Eval: 0.0184 s/iter. Total: 0.3727 s/iter. ETA=0:03:20
[12/07 10:20:16] detectron2.evaluation.evaluator INFO: Inference done 475/1000. Dataloading: 0.0172 s/iter. Inference: 0.3376 s/iter. Eval: 0.0185 s/iter. Total: 0.3734 s/iter. ETA=0:03:16
[12/07 10:20:22] detectron2.evaluation.evaluator INFO: Inference done 490/1000. Dataloading: 0.0172 s/iter. Inference: 0.3373 s/iter. Eval: 0.0184 s/iter. Total: 0.3729 s/iter. ETA=0:03:10
[12/07 10:20:27] detectron2.evaluation.evaluator INFO: Inference done 504/1000. Dataloading: 0.0172 s/iter. Inference: 0.3372 s/iter. Eval: 0.0183 s/iter. Total: 0.3728 s/iter. ETA=0:03:04
[12/07 10:20:32] detectron2.evaluation.evaluator INFO: Inference done 516/1000. Dataloading: 0.0172 s/iter. Inference: 0.3381 s/iter. Eval: 0.0185 s/iter. Total: 0.3738 s/iter. ETA=0:03:00
[12/07 10:20:37] detectron2.evaluation.evaluator INFO: Inference done 528/1000. Dataloading: 0.0173 s/iter. Inference: 0.3391 s/iter. Eval: 0.0186 s/iter. Total: 0.3750 s/iter. ETA=0:02:57
[12/07 10:20:42] detectron2.evaluation.evaluator INFO: Inference done 542/1000. Dataloading: 0.0173 s/iter. Inference: 0.3393 s/iter. Eval: 0.0186 s/iter. Total: 0.3752 s/iter. ETA=0:02:51
[12/07 10:20:47] detectron2.evaluation.evaluator INFO: Inference done 556/1000. Dataloading: 0.0172 s/iter. Inference: 0.3390 s/iter. Eval: 0.0186 s/iter. Total: 0.3748 s/iter. ETA=0:02:46
[12/07 10:20:53] detectron2.evaluation.evaluator INFO: Inference done 571/1000. Dataloading: 0.0172 s/iter. Inference: 0.3385 s/iter. Eval: 0.0185 s/iter. Total: 0.3743 s/iter. ETA=0:02:40
[12/07 10:20:58] detectron2.evaluation.evaluator INFO: Inference done 584/1000. Dataloading: 0.0172 s/iter. Inference: 0.3389 s/iter. Eval: 0.0187 s/iter. Total: 0.3749 s/iter. ETA=0:02:35
[12/07 10:21:03] detectron2.evaluation.evaluator INFO: Inference done 597/1000. Dataloading: 0.0173 s/iter. Inference: 0.3393 s/iter. Eval: 0.0188 s/iter. Total: 0.3755 s/iter. ETA=0:02:31
[12/07 10:21:08] detectron2.evaluation.evaluator INFO: Inference done 612/1000. Dataloading: 0.0172 s/iter. Inference: 0.3387 s/iter. Eval: 0.0186 s/iter. Total: 0.3746 s/iter. ETA=0:02:25
[12/07 10:21:13] detectron2.evaluation.evaluator INFO: Inference done 628/1000. Dataloading: 0.0172 s/iter. Inference: 0.3376 s/iter. Eval: 0.0185 s/iter. Total: 0.3733 s/iter. ETA=0:02:18
[12/07 10:21:19] detectron2.evaluation.evaluator INFO: Inference done 641/1000. Dataloading: 0.0172 s/iter. Inference: 0.3383 s/iter. Eval: 0.0185 s/iter. Total: 0.3741 s/iter. ETA=0:02:14
[12/07 10:21:24] detectron2.evaluation.evaluator INFO: Inference done 656/1000. Dataloading: 0.0171 s/iter. Inference: 0.3380 s/iter. Eval: 0.0185 s/iter. Total: 0.3736 s/iter. ETA=0:02:08
[12/07 10:21:29] detectron2.evaluation.evaluator INFO: Inference done 670/1000. Dataloading: 0.0171 s/iter. Inference: 0.3379 s/iter. Eval: 0.0183 s/iter. Total: 0.3733 s/iter. ETA=0:02:03
[12/07 10:21:34] detectron2.evaluation.evaluator INFO: Inference done 683/1000. Dataloading: 0.0171 s/iter. Inference: 0.3383 s/iter. Eval: 0.0183 s/iter. Total: 0.3737 s/iter. ETA=0:01:58
[12/07 10:21:39] detectron2.evaluation.evaluator INFO: Inference done 696/1000. Dataloading: 0.0171 s/iter. Inference: 0.3387 s/iter. Eval: 0.0183 s/iter. Total: 0.3743 s/iter. ETA=0:01:53
[12/07 10:21:44] detectron2.evaluation.evaluator INFO: Inference done 709/1000. Dataloading: 0.0172 s/iter. Inference: 0.3390 s/iter. Eval: 0.0184 s/iter. Total: 0.3746 s/iter. ETA=0:01:49
[12/07 10:21:50] detectron2.evaluation.evaluator INFO: Inference done 723/1000. Dataloading: 0.0172 s/iter. Inference: 0.3392 s/iter. Eval: 0.0184 s/iter. Total: 0.3748 s/iter. ETA=0:01:43
[12/07 10:21:55] detectron2.evaluation.evaluator INFO: Inference done 736/1000. Dataloading: 0.0172 s/iter. Inference: 0.3395 s/iter. Eval: 0.0184 s/iter. Total: 0.3751 s/iter. ETA=0:01:39
[12/07 10:22:00] detectron2.evaluation.evaluator INFO: Inference done 749/1000. Dataloading: 0.0172 s/iter. Inference: 0.3399 s/iter. Eval: 0.0183 s/iter. Total: 0.3755 s/iter. ETA=0:01:34
[12/07 10:22:05] detectron2.evaluation.evaluator INFO: Inference done 767/1000. Dataloading: 0.0171 s/iter. Inference: 0.3381 s/iter. Eval: 0.0181 s/iter. Total: 0.3734 s/iter. ETA=0:01:26
[12/07 10:22:10] detectron2.evaluation.evaluator INFO: Inference done 780/1000. Dataloading: 0.0171 s/iter. Inference: 0.3385 s/iter. Eval: 0.0181 s/iter. Total: 0.3738 s/iter. ETA=0:01:22
[12/07 10:22:16] detectron2.evaluation.evaluator INFO: Inference done 793/1000. Dataloading: 0.0171 s/iter. Inference: 0.3389 s/iter. Eval: 0.0182 s/iter. Total: 0.3743 s/iter. ETA=0:01:17
[12/07 10:22:21] detectron2.evaluation.evaluator INFO: Inference done 806/1000. Dataloading: 0.0172 s/iter. Inference: 0.3393 s/iter. Eval: 0.0183 s/iter. Total: 0.3748 s/iter. ETA=0:01:12
[12/07 10:22:26] detectron2.evaluation.evaluator INFO: Inference done 819/1000. Dataloading: 0.0172 s/iter. Inference: 0.3396 s/iter. Eval: 0.0184 s/iter. Total: 0.3752 s/iter. ETA=0:01:07
[12/07 10:22:31] detectron2.evaluation.evaluator INFO: Inference done 832/1000. Dataloading: 0.0172 s/iter. Inference: 0.3399 s/iter. Eval: 0.0185 s/iter. Total: 0.3756 s/iter. ETA=0:01:03
[12/07 10:22:37] detectron2.evaluation.evaluator INFO: Inference done 845/1000. Dataloading: 0.0172 s/iter. Inference: 0.3402 s/iter. Eval: 0.0185 s/iter. Total: 0.3761 s/iter. ETA=0:00:58
[12/07 10:22:42] detectron2.evaluation.evaluator INFO: Inference done 858/1000. Dataloading: 0.0173 s/iter. Inference: 0.3405 s/iter. Eval: 0.0186 s/iter. Total: 0.3765 s/iter. ETA=0:00:53
[12/07 10:22:47] detectron2.evaluation.evaluator INFO: Inference done 877/1000. Dataloading: 0.0172 s/iter. Inference: 0.3385 s/iter. Eval: 0.0184 s/iter. Total: 0.3741 s/iter. ETA=0:00:46
[12/07 10:22:52] detectron2.evaluation.evaluator INFO: Inference done 890/1000. Dataloading: 0.0172 s/iter. Inference: 0.3389 s/iter. Eval: 0.0185 s/iter. Total: 0.3746 s/iter. ETA=0:00:41
[12/07 10:22:57] detectron2.evaluation.evaluator INFO: Inference done 904/1000. Dataloading: 0.0172 s/iter. Inference: 0.3389 s/iter. Eval: 0.0184 s/iter. Total: 0.3745 s/iter. ETA=0:00:35
[12/07 10:23:03] detectron2.evaluation.evaluator INFO: Inference done 919/1000. Dataloading: 0.0172 s/iter. Inference: 0.3386 s/iter. Eval: 0.0183 s/iter. Total: 0.3741 s/iter. ETA=0:00:30
[12/07 10:23:08] detectron2.evaluation.evaluator INFO: Inference done 932/1000. Dataloading: 0.0172 s/iter. Inference: 0.3389 s/iter. Eval: 0.0183 s/iter. Total: 0.3745 s/iter. ETA=0:00:25
[12/07 10:23:13] detectron2.evaluation.evaluator INFO: Inference done 946/1000. Dataloading: 0.0172 s/iter. Inference: 0.3390 s/iter. Eval: 0.0183 s/iter. Total: 0.3746 s/iter. ETA=0:00:20
[12/07 10:23:18] detectron2.evaluation.evaluator INFO: Inference done 961/1000. Dataloading: 0.0171 s/iter. Inference: 0.3386 s/iter. Eval: 0.0183 s/iter. Total: 0.3741 s/iter. ETA=0:00:14
[12/07 10:23:23] detectron2.evaluation.evaluator INFO: Inference done 974/1000. Dataloading: 0.0172 s/iter. Inference: 0.3387 s/iter. Eval: 0.0184 s/iter. Total: 0.3743 s/iter. ETA=0:00:09
[12/07 10:23:28] detectron2.evaluation.evaluator INFO: Inference done 988/1000. Dataloading: 0.0171 s/iter. Inference: 0.3386 s/iter. Eval: 0.0184 s/iter. Total: 0.3742 s/iter. ETA=0:00:04
[12/07 10:23:33] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:11.872413 (0.373741 s / iter per device, on 2 devices)
[12/07 10:23:33] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:05:36 (0.338247 s / iter per device, on 2 devices)
[12/07 10:23:33] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 10:23:33] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 10:23:33] detectron2.data.common INFO: Serializing 5104 elements to byte tensors and concatenating them all ...
[12/07 10:23:33] detectron2.data.common INFO: Serialized dataset takes 39.02 MiB
[12/07 10:23:34] detectron2.evaluation.evaluator INFO: Start inference on 2552 batches
[12/07 10:24:09] detectron2.evaluation.evaluator INFO: Inference done 1/2552. Dataloading: 0.0890 s/iter. Inference: 35.7517 s/iter. Eval: 0.0120 s/iter. Total: 35.8547 s/iter. ETA=1 day, 1:24:25
[12/07 10:24:15] detectron2.evaluation.evaluator INFO: Inference done 14/2552. Dataloading: 0.0328 s/iter. Inference: 0.3532 s/iter. Eval: 0.0125 s/iter. Total: 0.3985 s/iter. ETA=0:16:51
[12/07 10:24:20] detectron2.evaluation.evaluator INFO: Inference done 27/2552. Dataloading: 0.0363 s/iter. Inference: 0.3585 s/iter. Eval: 0.0123 s/iter. Total: 0.4071 s/iter. ETA=0:17:07
[12/07 10:24:25] detectron2.evaluation.evaluator INFO: Inference done 40/2552. Dataloading: 0.0355 s/iter. Inference: 0.3602 s/iter. Eval: 0.0123 s/iter. Total: 0.4080 s/iter. ETA=0:17:04
[12/07 10:24:31] detectron2.evaluation.evaluator INFO: Inference done 53/2552. Dataloading: 0.0351 s/iter. Inference: 0.3606 s/iter. Eval: 0.0120 s/iter. Total: 0.4077 s/iter. ETA=0:16:58
[12/07 10:24:36] detectron2.evaluation.evaluator INFO: Inference done 65/2552. Dataloading: 0.0360 s/iter. Inference: 0.3629 s/iter. Eval: 0.0119 s/iter. Total: 0.4108 s/iter. ETA=0:17:01
[12/07 10:24:41] detectron2.evaluation.evaluator INFO: Inference done 77/2552. Dataloading: 0.0364 s/iter. Inference: 0.3638 s/iter. Eval: 0.0116 s/iter. Total: 0.4118 s/iter. ETA=0:16:59
[12/07 10:24:46] detectron2.evaluation.evaluator INFO: Inference done 89/2552. Dataloading: 0.0362 s/iter. Inference: 0.3652 s/iter. Eval: 0.0115 s/iter. Total: 0.4130 s/iter. ETA=0:16:57
[12/07 10:24:51] detectron2.evaluation.evaluator INFO: Inference done 101/2552. Dataloading: 0.0363 s/iter. Inference: 0.3672 s/iter. Eval: 0.0115 s/iter. Total: 0.4151 s/iter. ETA=0:16:57
[12/07 10:24:56] detectron2.evaluation.evaluator INFO: Inference done 114/2552. Dataloading: 0.0361 s/iter. Inference: 0.3657 s/iter. Eval: 0.0115 s/iter. Total: 0.4134 s/iter. ETA=0:16:47
[12/07 10:25:01] detectron2.evaluation.evaluator INFO: Inference done 127/2552. Dataloading: 0.0362 s/iter. Inference: 0.3639 s/iter. Eval: 0.0115 s/iter. Total: 0.4117 s/iter. ETA=0:16:38
[12/07 10:25:07] detectron2.evaluation.evaluator INFO: Inference done 140/2552. Dataloading: 0.0363 s/iter. Inference: 0.3634 s/iter. Eval: 0.0116 s/iter. Total: 0.4114 s/iter. ETA=0:16:32
[12/07 10:25:12] detectron2.evaluation.evaluator INFO: Inference done 153/2552. Dataloading: 0.0363 s/iter. Inference: 0.3634 s/iter. Eval: 0.0117 s/iter. Total: 0.4114 s/iter. ETA=0:16:26
[12/07 10:25:17] detectron2.evaluation.evaluator INFO: Inference done 165/2552. Dataloading: 0.0368 s/iter. Inference: 0.3638 s/iter. Eval: 0.0117 s/iter. Total: 0.4124 s/iter. ETA=0:16:24
[12/07 10:25:22] detectron2.evaluation.evaluator INFO: Inference done 177/2552. Dataloading: 0.0369 s/iter. Inference: 0.3641 s/iter. Eval: 0.0118 s/iter. Total: 0.4128 s/iter. ETA=0:16:20
[12/07 10:25:27] detectron2.evaluation.evaluator INFO: Inference done 190/2552. Dataloading: 0.0370 s/iter. Inference: 0.3633 s/iter. Eval: 0.0118 s/iter. Total: 0.4122 s/iter. ETA=0:16:13
[12/07 10:25:33] detectron2.evaluation.evaluator INFO: Inference done 203/2552. Dataloading: 0.0370 s/iter. Inference: 0.3631 s/iter. Eval: 0.0118 s/iter. Total: 0.4120 s/iter. ETA=0:16:07
[12/07 10:25:38] detectron2.evaluation.evaluator INFO: Inference done 216/2552. Dataloading: 0.0371 s/iter. Inference: 0.3631 s/iter. Eval: 0.0119 s/iter. Total: 0.4121 s/iter. ETA=0:16:02
[12/07 10:25:43] detectron2.evaluation.evaluator INFO: Inference done 229/2552. Dataloading: 0.0371 s/iter. Inference: 0.3629 s/iter. Eval: 0.0119 s/iter. Total: 0.4119 s/iter. ETA=0:15:56
[12/07 10:25:49] detectron2.evaluation.evaluator INFO: Inference done 242/2552. Dataloading: 0.0371 s/iter. Inference: 0.3624 s/iter. Eval: 0.0119 s/iter. Total: 0.4115 s/iter. ETA=0:15:50
[12/07 10:25:54] detectron2.evaluation.evaluator INFO: Inference done 255/2552. Dataloading: 0.0371 s/iter. Inference: 0.3621 s/iter. Eval: 0.0119 s/iter. Total: 0.4111 s/iter. ETA=0:15:44
[12/07 10:25:59] detectron2.evaluation.evaluator INFO: Inference done 268/2552. Dataloading: 0.0368 s/iter. Inference: 0.3626 s/iter. Eval: 0.0118 s/iter. Total: 0.4113 s/iter. ETA=0:15:39
[12/07 10:26:04] detectron2.evaluation.evaluator INFO: Inference done 280/2552. Dataloading: 0.0369 s/iter. Inference: 0.3629 s/iter. Eval: 0.0118 s/iter. Total: 0.4116 s/iter. ETA=0:15:35
[12/07 10:26:09] detectron2.evaluation.evaluator INFO: Inference done 292/2552. Dataloading: 0.0369 s/iter. Inference: 0.3633 s/iter. Eval: 0.0118 s/iter. Total: 0.4121 s/iter. ETA=0:15:31
[12/07 10:26:15] detectron2.evaluation.evaluator INFO: Inference done 305/2552. Dataloading: 0.0370 s/iter. Inference: 0.3624 s/iter. Eval: 0.0117 s/iter. Total: 0.4112 s/iter. ETA=0:15:23
[12/07 10:26:20] detectron2.evaluation.evaluator INFO: Inference done 317/2552. Dataloading: 0.0368 s/iter. Inference: 0.3631 s/iter. Eval: 0.0117 s/iter. Total: 0.4116 s/iter. ETA=0:15:19
[12/07 10:26:25] detectron2.evaluation.evaluator INFO: Inference done 329/2552. Dataloading: 0.0366 s/iter. Inference: 0.3639 s/iter. Eval: 0.0116 s/iter. Total: 0.4122 s/iter. ETA=0:15:16
[12/07 10:26:30] detectron2.evaluation.evaluator INFO: Inference done 341/2552. Dataloading: 0.0366 s/iter. Inference: 0.3641 s/iter. Eval: 0.0116 s/iter. Total: 0.4124 s/iter. ETA=0:15:11
[12/07 10:26:35] detectron2.evaluation.evaluator INFO: Inference done 354/2552. Dataloading: 0.0367 s/iter. Inference: 0.3638 s/iter. Eval: 0.0116 s/iter. Total: 0.4122 s/iter. ETA=0:15:05
[12/07 10:26:40] detectron2.evaluation.evaluator INFO: Inference done 367/2552. Dataloading: 0.0368 s/iter. Inference: 0.3637 s/iter. Eval: 0.0116 s/iter. Total: 0.4122 s/iter. ETA=0:15:00
[12/07 10:26:46] detectron2.evaluation.evaluator INFO: Inference done 380/2552. Dataloading: 0.0367 s/iter. Inference: 0.3633 s/iter. Eval: 0.0116 s/iter. Total: 0.4116 s/iter. ETA=0:14:53
[12/07 10:26:51] detectron2.evaluation.evaluator INFO: Inference done 393/2552. Dataloading: 0.0365 s/iter. Inference: 0.3634 s/iter. Eval: 0.0116 s/iter. Total: 0.4115 s/iter. ETA=0:14:48
[12/07 10:26:56] detectron2.evaluation.evaluator INFO: Inference done 406/2552. Dataloading: 0.0365 s/iter. Inference: 0.3634 s/iter. Eval: 0.0116 s/iter. Total: 0.4115 s/iter. ETA=0:14:43
[12/07 10:27:01] detectron2.evaluation.evaluator INFO: Inference done 418/2552. Dataloading: 0.0364 s/iter. Inference: 0.3638 s/iter. Eval: 0.0115 s/iter. Total: 0.4118 s/iter. ETA=0:14:38
[12/07 10:27:06] detectron2.evaluation.evaluator INFO: Inference done 430/2552. Dataloading: 0.0364 s/iter. Inference: 0.3640 s/iter. Eval: 0.0115 s/iter. Total: 0.4120 s/iter. ETA=0:14:34
[12/07 10:27:12] detectron2.evaluation.evaluator INFO: Inference done 443/2552. Dataloading: 0.0364 s/iter. Inference: 0.3640 s/iter. Eval: 0.0115 s/iter. Total: 0.4120 s/iter. ETA=0:14:28
[12/07 10:27:17] detectron2.evaluation.evaluator INFO: Inference done 456/2552. Dataloading: 0.0362 s/iter. Inference: 0.3640 s/iter. Eval: 0.0115 s/iter. Total: 0.4119 s/iter. ETA=0:14:23
[12/07 10:27:22] detectron2.evaluation.evaluator INFO: Inference done 469/2552. Dataloading: 0.0361 s/iter. Inference: 0.3643 s/iter. Eval: 0.0116 s/iter. Total: 0.4119 s/iter. ETA=0:14:18
[12/07 10:27:28] detectron2.evaluation.evaluator INFO: Inference done 482/2552. Dataloading: 0.0361 s/iter. Inference: 0.3640 s/iter. Eval: 0.0116 s/iter. Total: 0.4117 s/iter. ETA=0:14:12
[12/07 10:27:33] detectron2.evaluation.evaluator INFO: Inference done 495/2552. Dataloading: 0.0360 s/iter. Inference: 0.3641 s/iter. Eval: 0.0115 s/iter. Total: 0.4117 s/iter. ETA=0:14:06
[12/07 10:27:38] detectron2.evaluation.evaluator INFO: Inference done 508/2552. Dataloading: 0.0357 s/iter. Inference: 0.3644 s/iter. Eval: 0.0116 s/iter. Total: 0.4117 s/iter. ETA=0:14:01
[12/07 10:27:44] detectron2.evaluation.evaluator INFO: Inference done 521/2552. Dataloading: 0.0355 s/iter. Inference: 0.3644 s/iter. Eval: 0.0116 s/iter. Total: 0.4115 s/iter. ETA=0:13:55
[12/07 10:27:49] detectron2.evaluation.evaluator INFO: Inference done 534/2552. Dataloading: 0.0354 s/iter. Inference: 0.3644 s/iter. Eval: 0.0116 s/iter. Total: 0.4115 s/iter. ETA=0:13:50
[12/07 10:27:54] detectron2.evaluation.evaluator INFO: Inference done 547/2552. Dataloading: 0.0355 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4113 s/iter. ETA=0:13:44
[12/07 10:27:59] detectron2.evaluation.evaluator INFO: Inference done 560/2552. Dataloading: 0.0355 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4114 s/iter. ETA=0:13:39
[12/07 10:28:05] detectron2.evaluation.evaluator INFO: Inference done 573/2552. Dataloading: 0.0355 s/iter. Inference: 0.3644 s/iter. Eval: 0.0116 s/iter. Total: 0.4115 s/iter. ETA=0:13:34
[12/07 10:28:10] detectron2.evaluation.evaluator INFO: Inference done 586/2552. Dataloading: 0.0356 s/iter. Inference: 0.3645 s/iter. Eval: 0.0116 s/iter. Total: 0.4117 s/iter. ETA=0:13:29
[12/07 10:28:15] detectron2.evaluation.evaluator INFO: Inference done 599/2552. Dataloading: 0.0354 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4112 s/iter. ETA=0:13:22
[12/07 10:28:21] detectron2.evaluation.evaluator INFO: Inference done 612/2552. Dataloading: 0.0352 s/iter. Inference: 0.3641 s/iter. Eval: 0.0116 s/iter. Total: 0.4110 s/iter. ETA=0:13:17
[12/07 10:28:26] detectron2.evaluation.evaluator INFO: Inference done 625/2552. Dataloading: 0.0350 s/iter. Inference: 0.3643 s/iter. Eval: 0.0116 s/iter. Total: 0.4110 s/iter. ETA=0:13:11
[12/07 10:28:31] detectron2.evaluation.evaluator INFO: Inference done 638/2552. Dataloading: 0.0349 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4108 s/iter. ETA=0:13:06
[12/07 10:28:37] detectron2.evaluation.evaluator INFO: Inference done 651/2552. Dataloading: 0.0348 s/iter. Inference: 0.3643 s/iter. Eval: 0.0116 s/iter. Total: 0.4108 s/iter. ETA=0:13:00
[12/07 10:28:42] detectron2.evaluation.evaluator INFO: Inference done 664/2552. Dataloading: 0.0346 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4105 s/iter. ETA=0:12:54
[12/07 10:28:47] detectron2.evaluation.evaluator INFO: Inference done 677/2552. Dataloading: 0.0345 s/iter. Inference: 0.3640 s/iter. Eval: 0.0116 s/iter. Total: 0.4102 s/iter. ETA=0:12:49
[12/07 10:28:52] detectron2.evaluation.evaluator INFO: Inference done 690/2552. Dataloading: 0.0343 s/iter. Inference: 0.3639 s/iter. Eval: 0.0116 s/iter. Total: 0.4099 s/iter. ETA=0:12:43
[12/07 10:28:57] detectron2.evaluation.evaluator INFO: Inference done 703/2552. Dataloading: 0.0341 s/iter. Inference: 0.3638 s/iter. Eval: 0.0116 s/iter. Total: 0.4096 s/iter. ETA=0:12:37
[12/07 10:29:02] detectron2.evaluation.evaluator INFO: Inference done 716/2552. Dataloading: 0.0340 s/iter. Inference: 0.3639 s/iter. Eval: 0.0116 s/iter. Total: 0.4096 s/iter. ETA=0:12:31
[12/07 10:29:08] detectron2.evaluation.evaluator INFO: Inference done 729/2552. Dataloading: 0.0338 s/iter. Inference: 0.3639 s/iter. Eval: 0.0116 s/iter. Total: 0.4094 s/iter. ETA=0:12:26
[12/07 10:29:13] detectron2.evaluation.evaluator INFO: Inference done 742/2552. Dataloading: 0.0336 s/iter. Inference: 0.3640 s/iter. Eval: 0.0116 s/iter. Total: 0.4093 s/iter. ETA=0:12:20
[12/07 10:29:18] detectron2.evaluation.evaluator INFO: Inference done 754/2552. Dataloading: 0.0335 s/iter. Inference: 0.3643 s/iter. Eval: 0.0116 s/iter. Total: 0.4095 s/iter. ETA=0:12:16
[12/07 10:29:23] detectron2.evaluation.evaluator INFO: Inference done 767/2552. Dataloading: 0.0334 s/iter. Inference: 0.3643 s/iter. Eval: 0.0116 s/iter. Total: 0.4093 s/iter. ETA=0:12:10
[12/07 10:29:28] detectron2.evaluation.evaluator INFO: Inference done 780/2552. Dataloading: 0.0333 s/iter. Inference: 0.3644 s/iter. Eval: 0.0116 s/iter. Total: 0.4093 s/iter. ETA=0:12:05
[12/07 10:29:33] detectron2.evaluation.evaluator INFO: Inference done 793/2552. Dataloading: 0.0333 s/iter. Inference: 0.3641 s/iter. Eval: 0.0116 s/iter. Total: 0.4090 s/iter. ETA=0:11:59
[12/07 10:29:39] detectron2.evaluation.evaluator INFO: Inference done 806/2552. Dataloading: 0.0332 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4090 s/iter. ETA=0:11:54
[12/07 10:29:44] detectron2.evaluation.evaluator INFO: Inference done 819/2552. Dataloading: 0.0330 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4089 s/iter. ETA=0:11:48
[12/07 10:29:49] detectron2.evaluation.evaluator INFO: Inference done 832/2552. Dataloading: 0.0330 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4089 s/iter. ETA=0:11:43
[12/07 10:29:55] detectron2.evaluation.evaluator INFO: Inference done 845/2552. Dataloading: 0.0329 s/iter. Inference: 0.3643 s/iter. Eval: 0.0116 s/iter. Total: 0.4088 s/iter. ETA=0:11:37
[12/07 10:30:00] detectron2.evaluation.evaluator INFO: Inference done 858/2552. Dataloading: 0.0328 s/iter. Inference: 0.3643 s/iter. Eval: 0.0116 s/iter. Total: 0.4088 s/iter. ETA=0:11:32
[12/07 10:30:05] detectron2.evaluation.evaluator INFO: Inference done 871/2552. Dataloading: 0.0327 s/iter. Inference: 0.3642 s/iter. Eval: 0.0116 s/iter. Total: 0.4085 s/iter. ETA=0:11:26
[12/07 10:30:10] detectron2.evaluation.evaluator INFO: Inference done 884/2552. Dataloading: 0.0326 s/iter. Inference: 0.3640 s/iter. Eval: 0.0116 s/iter. Total: 0.4082 s/iter. ETA=0:11:20
[12/07 10:30:15] detectron2.evaluation.evaluator INFO: Inference done 898/2552. Dataloading: 0.0325 s/iter. Inference: 0.3636 s/iter. Eval: 0.0116 s/iter. Total: 0.4077 s/iter. ETA=0:11:14
[12/07 10:30:20] detectron2.evaluation.evaluator INFO: Inference done 911/2552. Dataloading: 0.0324 s/iter. Inference: 0.3634 s/iter. Eval: 0.0116 s/iter. Total: 0.4075 s/iter. ETA=0:11:08
[12/07 10:30:26] detectron2.evaluation.evaluator INFO: Inference done 924/2552. Dataloading: 0.0324 s/iter. Inference: 0.3635 s/iter. Eval: 0.0116 s/iter. Total: 0.4075 s/iter. ETA=0:11:03
[12/07 10:30:31] detectron2.evaluation.evaluator INFO: Inference done 936/2552. Dataloading: 0.0324 s/iter. Inference: 0.3636 s/iter. Eval: 0.0116 s/iter. Total: 0.4077 s/iter. ETA=0:10:58
[12/07 10:30:36] detectron2.evaluation.evaluator INFO: Inference done 948/2552. Dataloading: 0.0325 s/iter. Inference: 0.3638 s/iter. Eval: 0.0116 s/iter. Total: 0.4080 s/iter. ETA=0:10:54
[12/07 10:30:41] detectron2.evaluation.evaluator INFO: Inference done 961/2552. Dataloading: 0.0325 s/iter. Inference: 0.3636 s/iter. Eval: 0.0115 s/iter. Total: 0.4077 s/iter. ETA=0:10:48
[12/07 10:30:46] detectron2.evaluation.evaluator INFO: Inference done 974/2552. Dataloading: 0.0325 s/iter. Inference: 0.3635 s/iter. Eval: 0.0115 s/iter. Total: 0.4076 s/iter. ETA=0:10:43
[12/07 10:30:51] detectron2.evaluation.evaluator INFO: Inference done 988/2552. Dataloading: 0.0324 s/iter. Inference: 0.3631 s/iter. Eval: 0.0115 s/iter. Total: 0.4072 s/iter. ETA=0:10:36
[12/07 10:30:57] detectron2.evaluation.evaluator INFO: Inference done 1001/2552. Dataloading: 0.0324 s/iter. Inference: 0.3632 s/iter. Eval: 0.0115 s/iter. Total: 0.4071 s/iter. ETA=0:10:31
[12/07 10:31:02] detectron2.evaluation.evaluator INFO: Inference done 1014/2552. Dataloading: 0.0323 s/iter. Inference: 0.3632 s/iter. Eval: 0.0115 s/iter. Total: 0.4071 s/iter. ETA=0:10:26
[12/07 10:31:07] detectron2.evaluation.evaluator INFO: Inference done 1027/2552. Dataloading: 0.0324 s/iter. Inference: 0.3630 s/iter. Eval: 0.0115 s/iter. Total: 0.4070 s/iter. ETA=0:10:20
[12/07 10:31:12] detectron2.evaluation.evaluator INFO: Inference done 1040/2552. Dataloading: 0.0325 s/iter. Inference: 0.3630 s/iter. Eval: 0.0116 s/iter. Total: 0.4071 s/iter. ETA=0:10:15
[12/07 10:31:18] detectron2.evaluation.evaluator INFO: Inference done 1053/2552. Dataloading: 0.0325 s/iter. Inference: 0.3629 s/iter. Eval: 0.0115 s/iter. Total: 0.4070 s/iter. ETA=0:10:10
[12/07 10:31:23] detectron2.evaluation.evaluator INFO: Inference done 1066/2552. Dataloading: 0.0325 s/iter. Inference: 0.3627 s/iter. Eval: 0.0115 s/iter. Total: 0.4068 s/iter. ETA=0:10:04
[12/07 10:31:28] detectron2.evaluation.evaluator INFO: Inference done 1079/2552. Dataloading: 0.0326 s/iter. Inference: 0.3625 s/iter. Eval: 0.0116 s/iter. Total: 0.4067 s/iter. ETA=0:09:59
[12/07 10:31:33] detectron2.evaluation.evaluator INFO: Inference done 1092/2552. Dataloading: 0.0326 s/iter. Inference: 0.3625 s/iter. Eval: 0.0115 s/iter. Total: 0.4067 s/iter. ETA=0:09:53
[12/07 10:31:38] detectron2.evaluation.evaluator INFO: Inference done 1105/2552. Dataloading: 0.0326 s/iter. Inference: 0.3624 s/iter. Eval: 0.0115 s/iter. Total: 0.4066 s/iter. ETA=0:09:48
[12/07 10:31:44] detectron2.evaluation.evaluator INFO: Inference done 1118/2552. Dataloading: 0.0325 s/iter. Inference: 0.3623 s/iter. Eval: 0.0115 s/iter. Total: 0.4064 s/iter. ETA=0:09:42
[12/07 10:31:49] detectron2.evaluation.evaluator INFO: Inference done 1131/2552. Dataloading: 0.0325 s/iter. Inference: 0.3622 s/iter. Eval: 0.0115 s/iter. Total: 0.4063 s/iter. ETA=0:09:37
[12/07 10:31:54] detectron2.evaluation.evaluator INFO: Inference done 1144/2552. Dataloading: 0.0326 s/iter. Inference: 0.3621 s/iter. Eval: 0.0115 s/iter. Total: 0.4063 s/iter. ETA=0:09:32
[12/07 10:31:59] detectron2.evaluation.evaluator INFO: Inference done 1157/2552. Dataloading: 0.0326 s/iter. Inference: 0.3621 s/iter. Eval: 0.0116 s/iter. Total: 0.4064 s/iter. ETA=0:09:26
[12/07 10:32:04] detectron2.evaluation.evaluator INFO: Inference done 1170/2552. Dataloading: 0.0327 s/iter. Inference: 0.3619 s/iter. Eval: 0.0116 s/iter. Total: 0.4062 s/iter. ETA=0:09:21
[12/07 10:32:10] detectron2.evaluation.evaluator INFO: Inference done 1183/2552. Dataloading: 0.0327 s/iter. Inference: 0.3620 s/iter. Eval: 0.0116 s/iter. Total: 0.4063 s/iter. ETA=0:09:16
[12/07 10:32:15] detectron2.evaluation.evaluator INFO: Inference done 1197/2552. Dataloading: 0.0326 s/iter. Inference: 0.3618 s/iter. Eval: 0.0116 s/iter. Total: 0.4060 s/iter. ETA=0:09:10
[12/07 10:32:20] detectron2.evaluation.evaluator INFO: Inference done 1209/2552. Dataloading: 0.0327 s/iter. Inference: 0.3619 s/iter. Eval: 0.0115 s/iter. Total: 0.4062 s/iter. ETA=0:09:05
[12/07 10:32:25] detectron2.evaluation.evaluator INFO: Inference done 1222/2552. Dataloading: 0.0327 s/iter. Inference: 0.3617 s/iter. Eval: 0.0115 s/iter. Total: 0.4060 s/iter. ETA=0:09:00
[12/07 10:32:31] detectron2.evaluation.evaluator INFO: Inference done 1235/2552. Dataloading: 0.0327 s/iter. Inference: 0.3617 s/iter. Eval: 0.0115 s/iter. Total: 0.4060 s/iter. ETA=0:08:54
[12/07 10:32:36] detectron2.evaluation.evaluator INFO: Inference done 1248/2552. Dataloading: 0.0327 s/iter. Inference: 0.3616 s/iter. Eval: 0.0115 s/iter. Total: 0.4059 s/iter. ETA=0:08:49
[12/07 10:32:41] detectron2.evaluation.evaluator INFO: Inference done 1261/2552. Dataloading: 0.0328 s/iter. Inference: 0.3614 s/iter. Eval: 0.0115 s/iter. Total: 0.4057 s/iter. ETA=0:08:43
[12/07 10:32:46] detectron2.evaluation.evaluator INFO: Inference done 1274/2552. Dataloading: 0.0328 s/iter. Inference: 0.3614 s/iter. Eval: 0.0115 s/iter. Total: 0.4058 s/iter. ETA=0:08:38
[12/07 10:32:51] detectron2.evaluation.evaluator INFO: Inference done 1287/2552. Dataloading: 0.0328 s/iter. Inference: 0.3614 s/iter. Eval: 0.0115 s/iter. Total: 0.4058 s/iter. ETA=0:08:33
[12/07 10:32:57] detectron2.evaluation.evaluator INFO: Inference done 1300/2552. Dataloading: 0.0329 s/iter. Inference: 0.3614 s/iter. Eval: 0.0115 s/iter. Total: 0.4059 s/iter. ETA=0:08:28
[12/07 10:33:02] detectron2.evaluation.evaluator INFO: Inference done 1313/2552. Dataloading: 0.0329 s/iter. Inference: 0.3613 s/iter. Eval: 0.0115 s/iter. Total: 0.4058 s/iter. ETA=0:08:22
[12/07 10:33:07] detectron2.evaluation.evaluator INFO: Inference done 1326/2552. Dataloading: 0.0330 s/iter. Inference: 0.3612 s/iter. Eval: 0.0115 s/iter. Total: 0.4057 s/iter. ETA=0:08:17
[12/07 10:33:13] detectron2.evaluation.evaluator INFO: Inference done 1339/2552. Dataloading: 0.0330 s/iter. Inference: 0.3613 s/iter. Eval: 0.0115 s/iter. Total: 0.4058 s/iter. ETA=0:08:12
[12/07 10:33:18] detectron2.evaluation.evaluator INFO: Inference done 1352/2552. Dataloading: 0.0330 s/iter. Inference: 0.3612 s/iter. Eval: 0.0115 s/iter. Total: 0.4058 s/iter. ETA=0:08:06
[12/07 10:33:23] detectron2.evaluation.evaluator INFO: Inference done 1365/2552. Dataloading: 0.0330 s/iter. Inference: 0.3613 s/iter. Eval: 0.0115 s/iter. Total: 0.4058 s/iter. ETA=0:08:01
[12/07 10:33:28] detectron2.evaluation.evaluator INFO: Inference done 1378/2552. Dataloading: 0.0330 s/iter. Inference: 0.3612 s/iter. Eval: 0.0115 s/iter. Total: 0.4057 s/iter. ETA=0:07:56
[12/07 10:33:33] detectron2.evaluation.evaluator INFO: Inference done 1391/2552. Dataloading: 0.0330 s/iter. Inference: 0.3611 s/iter. Eval: 0.0115 s/iter. Total: 0.4057 s/iter. ETA=0:07:50
[12/07 10:33:39] detectron2.evaluation.evaluator INFO: Inference done 1404/2552. Dataloading: 0.0330 s/iter. Inference: 0.3610 s/iter. Eval: 0.0115 s/iter. Total: 0.4056 s/iter. ETA=0:07:45
[12/07 10:33:44] detectron2.evaluation.evaluator INFO: Inference done 1417/2552. Dataloading: 0.0330 s/iter. Inference: 0.3609 s/iter. Eval: 0.0115 s/iter. Total: 0.4054 s/iter. ETA=0:07:40
[12/07 10:33:49] detectron2.evaluation.evaluator INFO: Inference done 1430/2552. Dataloading: 0.0330 s/iter. Inference: 0.3607 s/iter. Eval: 0.0115 s/iter. Total: 0.4053 s/iter. ETA=0:07:34
[12/07 10:33:54] detectron2.evaluation.evaluator INFO: Inference done 1442/2552. Dataloading: 0.0330 s/iter. Inference: 0.3608 s/iter. Eval: 0.0115 s/iter. Total: 0.4054 s/iter. ETA=0:07:30
[12/07 10:33:59] detectron2.evaluation.evaluator INFO: Inference done 1455/2552. Dataloading: 0.0331 s/iter. Inference: 0.3607 s/iter. Eval: 0.0115 s/iter. Total: 0.4053 s/iter. ETA=0:07:24
[12/07 10:34:04] detectron2.evaluation.evaluator INFO: Inference done 1468/2552. Dataloading: 0.0331 s/iter. Inference: 0.3605 s/iter. Eval: 0.0115 s/iter. Total: 0.4052 s/iter. ETA=0:07:19
[12/07 10:34:09] detectron2.evaluation.evaluator INFO: Inference done 1481/2552. Dataloading: 0.0331 s/iter. Inference: 0.3605 s/iter. Eval: 0.0115 s/iter. Total: 0.4051 s/iter. ETA=0:07:13
[12/07 10:34:14] detectron2.evaluation.evaluator INFO: Inference done 1494/2552. Dataloading: 0.0331 s/iter. Inference: 0.3605 s/iter. Eval: 0.0115 s/iter. Total: 0.4051 s/iter. ETA=0:07:08
[12/07 10:34:20] detectron2.evaluation.evaluator INFO: Inference done 1507/2552. Dataloading: 0.0331 s/iter. Inference: 0.3605 s/iter. Eval: 0.0115 s/iter. Total: 0.4052 s/iter. ETA=0:07:03
[12/07 10:34:25] detectron2.evaluation.evaluator INFO: Inference done 1520/2552. Dataloading: 0.0331 s/iter. Inference: 0.3606 s/iter. Eval: 0.0115 s/iter. Total: 0.4053 s/iter. ETA=0:06:58
[12/07 10:34:30] detectron2.evaluation.evaluator INFO: Inference done 1533/2552. Dataloading: 0.0331 s/iter. Inference: 0.3606 s/iter. Eval: 0.0115 s/iter. Total: 0.4053 s/iter. ETA=0:06:53
[12/07 10:34:36] detectron2.evaluation.evaluator INFO: Inference done 1546/2552. Dataloading: 0.0331 s/iter. Inference: 0.3607 s/iter. Eval: 0.0115 s/iter. Total: 0.4053 s/iter. ETA=0:06:47
[12/07 10:34:41] detectron2.evaluation.evaluator INFO: Inference done 1559/2552. Dataloading: 0.0331 s/iter. Inference: 0.3607 s/iter. Eval: 0.0115 s/iter. Total: 0.4054 s/iter. ETA=0:06:42
[12/07 10:34:46] detectron2.evaluation.evaluator INFO: Inference done 1572/2552. Dataloading: 0.0331 s/iter. Inference: 0.3607 s/iter. Eval: 0.0115 s/iter. Total: 0.4054 s/iter. ETA=0:06:37
[12/07 10:34:52] detectron2.evaluation.evaluator INFO: Inference done 1585/2552. Dataloading: 0.0331 s/iter. Inference: 0.3607 s/iter. Eval: 0.0115 s/iter. Total: 0.4053 s/iter. ETA=0:06:31
[12/07 10:34:57] detectron2.evaluation.evaluator INFO: Inference done 1598/2552. Dataloading: 0.0331 s/iter. Inference: 0.3606 s/iter. Eval: 0.0115 s/iter. Total: 0.4052 s/iter. ETA=0:06:26
[12/07 10:35:02] detectron2.evaluation.evaluator INFO: Inference done 1611/2552. Dataloading: 0.0331 s/iter. Inference: 0.3604 s/iter. Eval: 0.0115 s/iter. Total: 0.4051 s/iter. ETA=0:06:21
[12/07 10:35:07] detectron2.evaluation.evaluator INFO: Inference done 1624/2552. Dataloading: 0.0331 s/iter. Inference: 0.3605 s/iter. Eval: 0.0115 s/iter. Total: 0.4051 s/iter. ETA=0:06:15
[12/07 10:35:12] detectron2.evaluation.evaluator INFO: Inference done 1637/2552. Dataloading: 0.0331 s/iter. Inference: 0.3604 s/iter. Eval: 0.0115 s/iter. Total: 0.4051 s/iter. ETA=0:06:10
[12/07 10:35:17] detectron2.evaluation.evaluator INFO: Inference done 1650/2552. Dataloading: 0.0331 s/iter. Inference: 0.3603 s/iter. Eval: 0.0115 s/iter. Total: 0.4050 s/iter. ETA=0:06:05
[12/07 10:35:23] detectron2.evaluation.evaluator INFO: Inference done 1663/2552. Dataloading: 0.0332 s/iter. Inference: 0.3603 s/iter. Eval: 0.0115 s/iter. Total: 0.4050 s/iter. ETA=0:06:00
[12/07 10:35:28] detectron2.evaluation.evaluator INFO: Inference done 1676/2552. Dataloading: 0.0331 s/iter. Inference: 0.3603 s/iter. Eval: 0.0115 s/iter. Total: 0.4050 s/iter. ETA=0:05:54
[12/07 10:35:33] detectron2.evaluation.evaluator INFO: Inference done 1689/2552. Dataloading: 0.0332 s/iter. Inference: 0.3603 s/iter. Eval: 0.0115 s/iter. Total: 0.4050 s/iter. ETA=0:05:49
[12/07 10:35:38] detectron2.evaluation.evaluator INFO: Inference done 1701/2552. Dataloading: 0.0332 s/iter. Inference: 0.3604 s/iter. Eval: 0.0115 s/iter. Total: 0.4051 s/iter. ETA=0:05:44
[12/07 10:35:43] detectron2.evaluation.evaluator INFO: Inference done 1714/2552. Dataloading: 0.0332 s/iter. Inference: 0.3603 s/iter. Eval: 0.0115 s/iter. Total: 0.4050 s/iter. ETA=0:05:39
[12/07 10:35:49] detectron2.evaluation.evaluator INFO: Inference done 1727/2552. Dataloading: 0.0331 s/iter. Inference: 0.3603 s/iter. Eval: 0.0115 s/iter. Total: 0.4050 s/iter. ETA=0:05:34
[12/07 10:35:54] detectron2.evaluation.evaluator INFO: Inference done 1740/2552. Dataloading: 0.0332 s/iter. Inference: 0.3602 s/iter. Eval: 0.0115 s/iter. Total: 0.4049 s/iter. ETA=0:05:28
[12/07 10:35:59] detectron2.evaluation.evaluator INFO: Inference done 1754/2552. Dataloading: 0.0331 s/iter. Inference: 0.3601 s/iter. Eval: 0.0115 s/iter. Total: 0.4047 s/iter. ETA=0:05:22
[12/07 10:36:04] detectron2.evaluation.evaluator INFO: Inference done 1767/2552. Dataloading: 0.0331 s/iter. Inference: 0.3600 s/iter. Eval: 0.0115 s/iter. Total: 0.4047 s/iter. ETA=0:05:17
[12/07 10:36:09] detectron2.evaluation.evaluator INFO: Inference done 1780/2552. Dataloading: 0.0331 s/iter. Inference: 0.3600 s/iter. Eval: 0.0115 s/iter. Total: 0.4047 s/iter. ETA=0:05:12
[12/07 10:36:15] detectron2.evaluation.evaluator INFO: Inference done 1793/2552. Dataloading: 0.0331 s/iter. Inference: 0.3599 s/iter. Eval: 0.0115 s/iter. Total: 0.4046 s/iter. ETA=0:05:07
[12/07 10:36:20] detectron2.evaluation.evaluator INFO: Inference done 1806/2552. Dataloading: 0.0331 s/iter. Inference: 0.3599 s/iter. Eval: 0.0115 s/iter. Total: 0.4046 s/iter. ETA=0:05:01
[12/07 10:36:25] detectron2.evaluation.evaluator INFO: Inference done 1819/2552. Dataloading: 0.0331 s/iter. Inference: 0.3600 s/iter. Eval: 0.0115 s/iter. Total: 0.4046 s/iter. ETA=0:04:56
[12/07 10:36:30] detectron2.evaluation.evaluator INFO: Inference done 1833/2552. Dataloading: 0.0331 s/iter. Inference: 0.3598 s/iter. Eval: 0.0115 s/iter. Total: 0.4044 s/iter. ETA=0:04:50
[12/07 10:36:35] detectron2.evaluation.evaluator INFO: Inference done 1846/2552. Dataloading: 0.0331 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4043 s/iter. ETA=0:04:45
[12/07 10:36:41] detectron2.evaluation.evaluator INFO: Inference done 1859/2552. Dataloading: 0.0331 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4043 s/iter. ETA=0:04:40
[12/07 10:36:46] detectron2.evaluation.evaluator INFO: Inference done 1872/2552. Dataloading: 0.0331 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4044 s/iter. ETA=0:04:34
[12/07 10:36:51] detectron2.evaluation.evaluator INFO: Inference done 1885/2552. Dataloading: 0.0331 s/iter. Inference: 0.3597 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:04:29
[12/07 10:36:57] detectron2.evaluation.evaluator INFO: Inference done 1898/2552. Dataloading: 0.0331 s/iter. Inference: 0.3597 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:04:24
[12/07 10:37:02] detectron2.evaluation.evaluator INFO: Inference done 1911/2552. Dataloading: 0.0331 s/iter. Inference: 0.3596 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:04:19
[12/07 10:37:07] detectron2.evaluation.evaluator INFO: Inference done 1924/2552. Dataloading: 0.0331 s/iter. Inference: 0.3596 s/iter. Eval: 0.0114 s/iter. Total: 0.4042 s/iter. ETA=0:04:13
[12/07 10:37:12] detectron2.evaluation.evaluator INFO: Inference done 1936/2552. Dataloading: 0.0331 s/iter. Inference: 0.3597 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:04:09
[12/07 10:37:17] detectron2.evaluation.evaluator INFO: Inference done 1949/2552. Dataloading: 0.0331 s/iter. Inference: 0.3597 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:04:03
[12/07 10:37:23] detectron2.evaluation.evaluator INFO: Inference done 1962/2552. Dataloading: 0.0331 s/iter. Inference: 0.3598 s/iter. Eval: 0.0115 s/iter. Total: 0.4044 s/iter. ETA=0:03:58
[12/07 10:37:28] detectron2.evaluation.evaluator INFO: Inference done 1975/2552. Dataloading: 0.0331 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4044 s/iter. ETA=0:03:53
[12/07 10:37:33] detectron2.evaluation.evaluator INFO: Inference done 1988/2552. Dataloading: 0.0330 s/iter. Inference: 0.3599 s/iter. Eval: 0.0114 s/iter. Total: 0.4045 s/iter. ETA=0:03:48
[12/07 10:37:39] detectron2.evaluation.evaluator INFO: Inference done 2001/2552. Dataloading: 0.0331 s/iter. Inference: 0.3600 s/iter. Eval: 0.0114 s/iter. Total: 0.4045 s/iter. ETA=0:03:42
[12/07 10:37:44] detectron2.evaluation.evaluator INFO: Inference done 2015/2552. Dataloading: 0.0330 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4044 s/iter. ETA=0:03:37
[12/07 10:37:49] detectron2.evaluation.evaluator INFO: Inference done 2029/2552. Dataloading: 0.0330 s/iter. Inference: 0.3597 s/iter. Eval: 0.0114 s/iter. Total: 0.4042 s/iter. ETA=0:03:31
[12/07 10:37:55] detectron2.evaluation.evaluator INFO: Inference done 2042/2552. Dataloading: 0.0330 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4042 s/iter. ETA=0:03:26
[12/07 10:38:00] detectron2.evaluation.evaluator INFO: Inference done 2055/2552. Dataloading: 0.0330 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4042 s/iter. ETA=0:03:20
[12/07 10:38:05] detectron2.evaluation.evaluator INFO: Inference done 2068/2552. Dataloading: 0.0330 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:03:15
[12/07 10:38:10] detectron2.evaluation.evaluator INFO: Inference done 2081/2552. Dataloading: 0.0329 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4042 s/iter. ETA=0:03:10
[12/07 10:38:15] detectron2.evaluation.evaluator INFO: Inference done 2093/2552. Dataloading: 0.0329 s/iter. Inference: 0.3599 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:03:05
[12/07 10:38:21] detectron2.evaluation.evaluator INFO: Inference done 2106/2552. Dataloading: 0.0329 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:03:00
[12/07 10:38:26] detectron2.evaluation.evaluator INFO: Inference done 2119/2552. Dataloading: 0.0329 s/iter. Inference: 0.3598 s/iter. Eval: 0.0114 s/iter. Total: 0.4042 s/iter. ETA=0:02:55
[12/07 10:38:31] detectron2.evaluation.evaluator INFO: Inference done 2132/2552. Dataloading: 0.0329 s/iter. Inference: 0.3599 s/iter. Eval: 0.0114 s/iter. Total: 0.4042 s/iter. ETA=0:02:49
[12/07 10:38:36] detectron2.evaluation.evaluator INFO: Inference done 2145/2552. Dataloading: 0.0329 s/iter. Inference: 0.3599 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:02:44
[12/07 10:38:42] detectron2.evaluation.evaluator INFO: Inference done 2158/2552. Dataloading: 0.0329 s/iter. Inference: 0.3599 s/iter. Eval: 0.0114 s/iter. Total: 0.4043 s/iter. ETA=0:02:39
[12/07 10:38:47] detectron2.evaluation.evaluator INFO: Inference done 2171/2552. Dataloading: 0.0329 s/iter. Inference: 0.3598 s/iter. Eval: 0.0115 s/iter. Total: 0.4042 s/iter. ETA=0:02:34
[12/07 10:38:52] detectron2.evaluation.evaluator INFO: Inference done 2184/2552. Dataloading: 0.0329 s/iter. Inference: 0.3599 s/iter. Eval: 0.0115 s/iter. Total: 0.4042 s/iter. ETA=0:02:28
[12/07 10:38:57] detectron2.evaluation.evaluator INFO: Inference done 2197/2552. Dataloading: 0.0329 s/iter. Inference: 0.3598 s/iter. Eval: 0.0115 s/iter. Total: 0.4042 s/iter. ETA=0:02:23
[12/07 10:39:02] detectron2.evaluation.evaluator INFO: Inference done 2210/2552. Dataloading: 0.0329 s/iter. Inference: 0.3598 s/iter. Eval: 0.0115 s/iter. Total: 0.4042 s/iter. ETA=0:02:18
[12/07 10:39:08] detectron2.evaluation.evaluator INFO: Inference done 2223/2552. Dataloading: 0.0329 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4042 s/iter. ETA=0:02:12
[12/07 10:39:13] detectron2.evaluation.evaluator INFO: Inference done 2236/2552. Dataloading: 0.0329 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4041 s/iter. ETA=0:02:07
[12/07 10:39:18] detectron2.evaluation.evaluator INFO: Inference done 2249/2552. Dataloading: 0.0328 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4041 s/iter. ETA=0:02:02
[12/07 10:39:23] detectron2.evaluation.evaluator INFO: Inference done 2262/2552. Dataloading: 0.0328 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4041 s/iter. ETA=0:01:57
[12/07 10:39:28] detectron2.evaluation.evaluator INFO: Inference done 2275/2552. Dataloading: 0.0328 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4041 s/iter. ETA=0:01:51
[12/07 10:39:33] detectron2.evaluation.evaluator INFO: Inference done 2288/2552. Dataloading: 0.0328 s/iter. Inference: 0.3597 s/iter. Eval: 0.0115 s/iter. Total: 0.4040 s/iter. ETA=0:01:46
[12/07 10:39:39] detectron2.evaluation.evaluator INFO: Inference done 2302/2552. Dataloading: 0.0328 s/iter. Inference: 0.3595 s/iter. Eval: 0.0115 s/iter. Total: 0.4038 s/iter. ETA=0:01:40
[12/07 10:39:44] detectron2.evaluation.evaluator INFO: Inference done 2315/2552. Dataloading: 0.0328 s/iter. Inference: 0.3595 s/iter. Eval: 0.0114 s/iter. Total: 0.4038 s/iter. ETA=0:01:35
[12/07 10:39:49] detectron2.evaluation.evaluator INFO: Inference done 2329/2552. Dataloading: 0.0327 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4036 s/iter. ETA=0:01:30
[12/07 10:39:54] detectron2.evaluation.evaluator INFO: Inference done 2342/2552. Dataloading: 0.0327 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4036 s/iter. ETA=0:01:24
[12/07 10:39:59] detectron2.evaluation.evaluator INFO: Inference done 2354/2552. Dataloading: 0.0327 s/iter. Inference: 0.3595 s/iter. Eval: 0.0114 s/iter. Total: 0.4037 s/iter. ETA=0:01:19
[12/07 10:40:05] detectron2.evaluation.evaluator INFO: Inference done 2367/2552. Dataloading: 0.0327 s/iter. Inference: 0.3595 s/iter. Eval: 0.0114 s/iter. Total: 0.4037 s/iter. ETA=0:01:14
[12/07 10:40:10] detectron2.evaluation.evaluator INFO: Inference done 2380/2552. Dataloading: 0.0326 s/iter. Inference: 0.3595 s/iter. Eval: 0.0114 s/iter. Total: 0.4036 s/iter. ETA=0:01:09
[12/07 10:40:15] detectron2.evaluation.evaluator INFO: Inference done 2393/2552. Dataloading: 0.0326 s/iter. Inference: 0.3595 s/iter. Eval: 0.0114 s/iter. Total: 0.4036 s/iter. ETA=0:01:04
[12/07 10:40:20] detectron2.evaluation.evaluator INFO: Inference done 2406/2552. Dataloading: 0.0326 s/iter. Inference: 0.3595 s/iter. Eval: 0.0114 s/iter. Total: 0.4036 s/iter. ETA=0:00:58
[12/07 10:40:26] detectron2.evaluation.evaluator INFO: Inference done 2420/2552. Dataloading: 0.0325 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4035 s/iter. ETA=0:00:53
[12/07 10:40:31] detectron2.evaluation.evaluator INFO: Inference done 2434/2552. Dataloading: 0.0325 s/iter. Inference: 0.3593 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:47
[12/07 10:40:36] detectron2.evaluation.evaluator INFO: Inference done 2447/2552. Dataloading: 0.0325 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:42
[12/07 10:40:41] detectron2.evaluation.evaluator INFO: Inference done 2460/2552. Dataloading: 0.0325 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:37
[12/07 10:40:47] detectron2.evaluation.evaluator INFO: Inference done 2473/2552. Dataloading: 0.0325 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:31
[12/07 10:40:52] detectron2.evaluation.evaluator INFO: Inference done 2486/2552. Dataloading: 0.0325 s/iter. Inference: 0.3593 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:26
[12/07 10:40:57] detectron2.evaluation.evaluator INFO: Inference done 2498/2552. Dataloading: 0.0324 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:21
[12/07 10:41:02] detectron2.evaluation.evaluator INFO: Inference done 2511/2552. Dataloading: 0.0324 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:16
[12/07 10:41:07] detectron2.evaluation.evaluator INFO: Inference done 2524/2552. Dataloading: 0.0324 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4033 s/iter. ETA=0:00:11
[12/07 10:41:12] detectron2.evaluation.evaluator INFO: Inference done 2537/2552. Dataloading: 0.0324 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4032 s/iter. ETA=0:00:06
[12/07 10:41:17] detectron2.evaluation.evaluator INFO: Inference done 2550/2552. Dataloading: 0.0323 s/iter. Inference: 0.3594 s/iter. Eval: 0.0114 s/iter. Total: 0.4032 s/iter. ETA=0:00:00
[12/07 10:41:18] detectron2.evaluation.evaluator INFO: Total inference time: 0:17:06.846359 (0.403159 s / iter per device, on 2 devices)
[12/07 10:41:18] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:15:15 (0.359375 s / iter per device, on 2 devices)
[12/07 10:41:19] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 10:41:19] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 10:41:19] detectron2.data.common INFO: Serializing 5104 elements to byte tensors and concatenating them all ...
[12/07 10:41:19] detectron2.data.common INFO: Serialized dataset takes 8.84 MiB
[12/07 10:41:19] detectron2.evaluation.evaluator INFO: Start inference on 2552 batches
[12/07 10:41:30] detectron2.evaluation.evaluator INFO: Inference done 1/2552. Dataloading: 0.0436 s/iter. Inference: 10.4735 s/iter. Eval: 0.0084 s/iter. Total: 10.5277 s/iter. ETA=7:27:36
[12/07 10:41:35] detectron2.evaluation.evaluator INFO: Inference done 15/2552. Dataloading: 0.0193 s/iter. Inference: 0.3503 s/iter. Eval: 0.0109 s/iter. Total: 0.3804 s/iter. ETA=0:16:05
[12/07 10:41:40] detectron2.evaluation.evaluator INFO: Inference done 29/2552. Dataloading: 0.0201 s/iter. Inference: 0.3496 s/iter. Eval: 0.0104 s/iter. Total: 0.3802 s/iter. ETA=0:15:59
[12/07 10:41:46] detectron2.evaluation.evaluator INFO: Inference done 42/2552. Dataloading: 0.0208 s/iter. Inference: 0.3563 s/iter. Eval: 0.0100 s/iter. Total: 0.3871 s/iter. ETA=0:16:11
[12/07 10:41:51] detectron2.evaluation.evaluator INFO: Inference done 56/2552. Dataloading: 0.0215 s/iter. Inference: 0.3542 s/iter. Eval: 0.0100 s/iter. Total: 0.3858 s/iter. ETA=0:16:03
[12/07 10:41:56] detectron2.evaluation.evaluator INFO: Inference done 69/2552. Dataloading: 0.0215 s/iter. Inference: 0.3562 s/iter. Eval: 0.0100 s/iter. Total: 0.3876 s/iter. ETA=0:16:02
[12/07 10:42:01] detectron2.evaluation.evaluator INFO: Inference done 82/2552. Dataloading: 0.0213 s/iter. Inference: 0.3583 s/iter. Eval: 0.0098 s/iter. Total: 0.3895 s/iter. ETA=0:16:02
[12/07 10:42:07] detectron2.evaluation.evaluator INFO: Inference done 95/2552. Dataloading: 0.0219 s/iter. Inference: 0.3592 s/iter. Eval: 0.0100 s/iter. Total: 0.3912 s/iter. ETA=0:16:01
[12/07 10:42:12] detectron2.evaluation.evaluator INFO: Inference done 108/2552. Dataloading: 0.0218 s/iter. Inference: 0.3586 s/iter. Eval: 0.0100 s/iter. Total: 0.3904 s/iter. ETA=0:15:54
[12/07 10:42:17] detectron2.evaluation.evaluator INFO: Inference done 122/2552. Dataloading: 0.0216 s/iter. Inference: 0.3577 s/iter. Eval: 0.0100 s/iter. Total: 0.3893 s/iter. ETA=0:15:46
[12/07 10:42:22] detectron2.evaluation.evaluator INFO: Inference done 136/2552. Dataloading: 0.0215 s/iter. Inference: 0.3563 s/iter. Eval: 0.0099 s/iter. Total: 0.3877 s/iter. ETA=0:15:36
[12/07 10:42:27] detectron2.evaluation.evaluator INFO: Inference done 149/2552. Dataloading: 0.0215 s/iter. Inference: 0.3567 s/iter. Eval: 0.0098 s/iter. Total: 0.3880 s/iter. ETA=0:15:32
[12/07 10:42:32] detectron2.evaluation.evaluator INFO: Inference done 162/2552. Dataloading: 0.0214 s/iter. Inference: 0.3571 s/iter. Eval: 0.0098 s/iter. Total: 0.3882 s/iter. ETA=0:15:27
[12/07 10:42:38] detectron2.evaluation.evaluator INFO: Inference done 176/2552. Dataloading: 0.0214 s/iter. Inference: 0.3569 s/iter. Eval: 0.0098 s/iter. Total: 0.3881 s/iter. ETA=0:15:22
[12/07 10:42:43] detectron2.evaluation.evaluator INFO: Inference done 189/2552. Dataloading: 0.0214 s/iter. Inference: 0.3566 s/iter. Eval: 0.0097 s/iter. Total: 0.3878 s/iter. ETA=0:15:16
[12/07 10:42:48] detectron2.evaluation.evaluator INFO: Inference done 203/2552. Dataloading: 0.0212 s/iter. Inference: 0.3565 s/iter. Eval: 0.0097 s/iter. Total: 0.3875 s/iter. ETA=0:15:10
[12/07 10:42:53] detectron2.evaluation.evaluator INFO: Inference done 216/2552. Dataloading: 0.0212 s/iter. Inference: 0.3564 s/iter. Eval: 0.0097 s/iter. Total: 0.3874 s/iter. ETA=0:15:04
[12/07 10:42:58] detectron2.evaluation.evaluator INFO: Inference done 229/2552. Dataloading: 0.0211 s/iter. Inference: 0.3564 s/iter. Eval: 0.0098 s/iter. Total: 0.3873 s/iter. ETA=0:14:59
[12/07 10:43:03] detectron2.evaluation.evaluator INFO: Inference done 243/2552. Dataloading: 0.0209 s/iter. Inference: 0.3553 s/iter. Eval: 0.0098 s/iter. Total: 0.3861 s/iter. ETA=0:14:51
[12/07 10:43:08] detectron2.evaluation.evaluator INFO: Inference done 256/2552. Dataloading: 0.0209 s/iter. Inference: 0.3557 s/iter. Eval: 0.0097 s/iter. Total: 0.3864 s/iter. ETA=0:14:47
[12/07 10:43:13] detectron2.evaluation.evaluator INFO: Inference done 269/2552. Dataloading: 0.0208 s/iter. Inference: 0.3562 s/iter. Eval: 0.0097 s/iter. Total: 0.3868 s/iter. ETA=0:14:43
[12/07 10:43:19] detectron2.evaluation.evaluator INFO: Inference done 282/2552. Dataloading: 0.0208 s/iter. Inference: 0.3566 s/iter. Eval: 0.0097 s/iter. Total: 0.3871 s/iter. ETA=0:14:38
[12/07 10:43:24] detectron2.evaluation.evaluator INFO: Inference done 295/2552. Dataloading: 0.0207 s/iter. Inference: 0.3567 s/iter. Eval: 0.0097 s/iter. Total: 0.3872 s/iter. ETA=0:14:33
[12/07 10:43:29] detectron2.evaluation.evaluator INFO: Inference done 309/2552. Dataloading: 0.0206 s/iter. Inference: 0.3562 s/iter. Eval: 0.0096 s/iter. Total: 0.3865 s/iter. ETA=0:14:26
[12/07 10:43:34] detectron2.evaluation.evaluator INFO: Inference done 322/2552. Dataloading: 0.0206 s/iter. Inference: 0.3573 s/iter. Eval: 0.0096 s/iter. Total: 0.3876 s/iter. ETA=0:14:24
[12/07 10:43:39] detectron2.evaluation.evaluator INFO: Inference done 335/2552. Dataloading: 0.0206 s/iter. Inference: 0.3581 s/iter. Eval: 0.0096 s/iter. Total: 0.3884 s/iter. ETA=0:14:20
[12/07 10:43:45] detectron2.evaluation.evaluator INFO: Inference done 349/2552. Dataloading: 0.0205 s/iter. Inference: 0.3580 s/iter. Eval: 0.0096 s/iter. Total: 0.3881 s/iter. ETA=0:14:14
[12/07 10:43:50] detectron2.evaluation.evaluator INFO: Inference done 363/2552. Dataloading: 0.0204 s/iter. Inference: 0.3577 s/iter. Eval: 0.0096 s/iter. Total: 0.3877 s/iter. ETA=0:14:08
[12/07 10:43:55] detectron2.evaluation.evaluator INFO: Inference done 377/2552. Dataloading: 0.0204 s/iter. Inference: 0.3572 s/iter. Eval: 0.0096 s/iter. Total: 0.3872 s/iter. ETA=0:14:02
[12/07 10:44:00] detectron2.evaluation.evaluator INFO: Inference done 390/2552. Dataloading: 0.0204 s/iter. Inference: 0.3571 s/iter. Eval: 0.0096 s/iter. Total: 0.3872 s/iter. ETA=0:13:57
[12/07 10:44:05] detectron2.evaluation.evaluator INFO: Inference done 403/2552. Dataloading: 0.0203 s/iter. Inference: 0.3574 s/iter. Eval: 0.0095 s/iter. Total: 0.3873 s/iter. ETA=0:13:52
[12/07 10:44:11] detectron2.evaluation.evaluator INFO: Inference done 416/2552. Dataloading: 0.0203 s/iter. Inference: 0.3578 s/iter. Eval: 0.0095 s/iter. Total: 0.3877 s/iter. ETA=0:13:48
[12/07 10:44:16] detectron2.evaluation.evaluator INFO: Inference done 429/2552. Dataloading: 0.0202 s/iter. Inference: 0.3581 s/iter. Eval: 0.0095 s/iter. Total: 0.3880 s/iter. ETA=0:13:43
[12/07 10:44:21] detectron2.evaluation.evaluator INFO: Inference done 442/2552. Dataloading: 0.0203 s/iter. Inference: 0.3580 s/iter. Eval: 0.0095 s/iter. Total: 0.3879 s/iter. ETA=0:13:38
[12/07 10:44:26] detectron2.evaluation.evaluator INFO: Inference done 455/2552. Dataloading: 0.0202 s/iter. Inference: 0.3582 s/iter. Eval: 0.0096 s/iter. Total: 0.3880 s/iter. ETA=0:13:33
[12/07 10:44:31] detectron2.evaluation.evaluator INFO: Inference done 468/2552. Dataloading: 0.0202 s/iter. Inference: 0.3583 s/iter. Eval: 0.0096 s/iter. Total: 0.3882 s/iter. ETA=0:13:28
[12/07 10:44:36] detectron2.evaluation.evaluator INFO: Inference done 482/2552. Dataloading: 0.0202 s/iter. Inference: 0.3582 s/iter. Eval: 0.0096 s/iter. Total: 0.3880 s/iter. ETA=0:13:23
[12/07 10:44:42] detectron2.evaluation.evaluator INFO: Inference done 495/2552. Dataloading: 0.0201 s/iter. Inference: 0.3583 s/iter. Eval: 0.0096 s/iter. Total: 0.3881 s/iter. ETA=0:13:18
[12/07 10:44:47] detectron2.evaluation.evaluator INFO: Inference done 508/2552. Dataloading: 0.0201 s/iter. Inference: 0.3586 s/iter. Eval: 0.0096 s/iter. Total: 0.3883 s/iter. ETA=0:13:13
[12/07 10:44:52] detectron2.evaluation.evaluator INFO: Inference done 521/2552. Dataloading: 0.0201 s/iter. Inference: 0.3586 s/iter. Eval: 0.0096 s/iter. Total: 0.3884 s/iter. ETA=0:13:08
[12/07 10:44:57] detectron2.evaluation.evaluator INFO: Inference done 534/2552. Dataloading: 0.0201 s/iter. Inference: 0.3587 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:13:03
[12/07 10:45:02] detectron2.evaluation.evaluator INFO: Inference done 548/2552. Dataloading: 0.0201 s/iter. Inference: 0.3586 s/iter. Eval: 0.0096 s/iter. Total: 0.3883 s/iter. ETA=0:12:58
[12/07 10:45:07] detectron2.evaluation.evaluator INFO: Inference done 561/2552. Dataloading: 0.0201 s/iter. Inference: 0.3585 s/iter. Eval: 0.0096 s/iter. Total: 0.3883 s/iter. ETA=0:12:53
[12/07 10:45:12] detectron2.evaluation.evaluator INFO: Inference done 574/2552. Dataloading: 0.0201 s/iter. Inference: 0.3587 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:12:48
[12/07 10:45:18] detectron2.evaluation.evaluator INFO: Inference done 588/2552. Dataloading: 0.0201 s/iter. Inference: 0.3587 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:12:42
[12/07 10:45:23] detectron2.evaluation.evaluator INFO: Inference done 601/2552. Dataloading: 0.0201 s/iter. Inference: 0.3586 s/iter. Eval: 0.0097 s/iter. Total: 0.3884 s/iter. ETA=0:12:37
[12/07 10:45:28] detectron2.evaluation.evaluator INFO: Inference done 614/2552. Dataloading: 0.0201 s/iter. Inference: 0.3586 s/iter. Eval: 0.0096 s/iter. Total: 0.3884 s/iter. ETA=0:12:32
[12/07 10:45:33] detectron2.evaluation.evaluator INFO: Inference done 627/2552. Dataloading: 0.0201 s/iter. Inference: 0.3587 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:12:27
[12/07 10:45:38] detectron2.evaluation.evaluator INFO: Inference done 640/2552. Dataloading: 0.0201 s/iter. Inference: 0.3587 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:12:22
[12/07 10:45:43] detectron2.evaluation.evaluator INFO: Inference done 653/2552. Dataloading: 0.0201 s/iter. Inference: 0.3588 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:12:17
[12/07 10:45:48] detectron2.evaluation.evaluator INFO: Inference done 667/2552. Dataloading: 0.0200 s/iter. Inference: 0.3585 s/iter. Eval: 0.0097 s/iter. Total: 0.3882 s/iter. ETA=0:12:11
[12/07 10:45:54] detectron2.evaluation.evaluator INFO: Inference done 681/2552. Dataloading: 0.0200 s/iter. Inference: 0.3583 s/iter. Eval: 0.0096 s/iter. Total: 0.3881 s/iter. ETA=0:12:06
[12/07 10:45:59] detectron2.evaluation.evaluator INFO: Inference done 694/2552. Dataloading: 0.0200 s/iter. Inference: 0.3584 s/iter. Eval: 0.0096 s/iter. Total: 0.3881 s/iter. ETA=0:12:01
[12/07 10:46:04] detectron2.evaluation.evaluator INFO: Inference done 708/2552. Dataloading: 0.0200 s/iter. Inference: 0.3583 s/iter. Eval: 0.0096 s/iter. Total: 0.3880 s/iter. ETA=0:11:55
[12/07 10:46:09] detectron2.evaluation.evaluator INFO: Inference done 721/2552. Dataloading: 0.0200 s/iter. Inference: 0.3583 s/iter. Eval: 0.0097 s/iter. Total: 0.3880 s/iter. ETA=0:11:50
[12/07 10:46:14] detectron2.evaluation.evaluator INFO: Inference done 734/2552. Dataloading: 0.0200 s/iter. Inference: 0.3586 s/iter. Eval: 0.0096 s/iter. Total: 0.3883 s/iter. ETA=0:11:45
[12/07 10:46:19] detectron2.evaluation.evaluator INFO: Inference done 747/2552. Dataloading: 0.0200 s/iter. Inference: 0.3586 s/iter. Eval: 0.0096 s/iter. Total: 0.3883 s/iter. ETA=0:11:40
[12/07 10:46:25] detectron2.evaluation.evaluator INFO: Inference done 760/2552. Dataloading: 0.0200 s/iter. Inference: 0.3589 s/iter. Eval: 0.0096 s/iter. Total: 0.3886 s/iter. ETA=0:11:36
[12/07 10:46:30] detectron2.evaluation.evaluator INFO: Inference done 774/2552. Dataloading: 0.0200 s/iter. Inference: 0.3588 s/iter. Eval: 0.0097 s/iter. Total: 0.3885 s/iter. ETA=0:11:30
[12/07 10:46:36] detectron2.evaluation.evaluator INFO: Inference done 788/2552. Dataloading: 0.0200 s/iter. Inference: 0.3588 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:11:25
[12/07 10:46:41] detectron2.evaluation.evaluator INFO: Inference done 801/2552. Dataloading: 0.0200 s/iter. Inference: 0.3588 s/iter. Eval: 0.0096 s/iter. Total: 0.3884 s/iter. ETA=0:11:20
[12/07 10:46:46] detectron2.evaluation.evaluator INFO: Inference done 814/2552. Dataloading: 0.0199 s/iter. Inference: 0.3589 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:11:15
[12/07 10:46:51] detectron2.evaluation.evaluator INFO: Inference done 827/2552. Dataloading: 0.0199 s/iter. Inference: 0.3589 s/iter. Eval: 0.0096 s/iter. Total: 0.3885 s/iter. ETA=0:11:10
[12/07 10:46:56] detectron2.evaluation.evaluator INFO: Inference done 840/2552. Dataloading: 0.0199 s/iter. Inference: 0.3588 s/iter. Eval: 0.0096 s/iter. Total: 0.3884 s/iter. ETA=0:11:05
[12/07 10:47:01] detectron2.evaluation.evaluator INFO: Inference done 853/2552. Dataloading: 0.0199 s/iter. Inference: 0.3590 s/iter. Eval: 0.0096 s/iter. Total: 0.3886 s/iter. ETA=0:11:00
[12/07 10:47:06] detectron2.evaluation.evaluator INFO: Inference done 867/2552. Dataloading: 0.0199 s/iter. Inference: 0.3588 s/iter. Eval: 0.0096 s/iter. Total: 0.3884 s/iter. ETA=0:10:54
[12/07 10:47:11] detectron2.evaluation.evaluator INFO: Inference done 881/2552. Dataloading: 0.0199 s/iter. Inference: 0.3585 s/iter. Eval: 0.0096 s/iter. Total: 0.3880 s/iter. ETA=0:10:48
[12/07 10:47:16] detectron2.evaluation.evaluator INFO: Inference done 895/2552. Dataloading: 0.0199 s/iter. Inference: 0.3582 s/iter. Eval: 0.0096 s/iter. Total: 0.3878 s/iter. ETA=0:10:42
[12/07 10:47:22] detectron2.evaluation.evaluator INFO: Inference done 909/2552. Dataloading: 0.0198 s/iter. Inference: 0.3581 s/iter. Eval: 0.0096 s/iter. Total: 0.3876 s/iter. ETA=0:10:36
[12/07 10:47:27] detectron2.evaluation.evaluator INFO: Inference done 923/2552. Dataloading: 0.0198 s/iter. Inference: 0.3580 s/iter. Eval: 0.0096 s/iter. Total: 0.3876 s/iter. ETA=0:10:31
[12/07 10:47:32] detectron2.evaluation.evaluator INFO: Inference done 936/2552. Dataloading: 0.0198 s/iter. Inference: 0.3583 s/iter. Eval: 0.0096 s/iter. Total: 0.3878 s/iter. ETA=0:10:26
[12/07 10:47:38] detectron2.evaluation.evaluator INFO: Inference done 949/2552. Dataloading: 0.0199 s/iter. Inference: 0.3584 s/iter. Eval: 0.0096 s/iter. Total: 0.3880 s/iter. ETA=0:10:21
[12/07 10:47:43] detectron2.evaluation.evaluator INFO: Inference done 963/2552. Dataloading: 0.0198 s/iter. Inference: 0.3583 s/iter. Eval: 0.0096 s/iter. Total: 0.3878 s/iter. ETA=0:10:16
[12/07 10:47:48] detectron2.evaluation.evaluator INFO: Inference done 977/2552. Dataloading: 0.0198 s/iter. Inference: 0.3581 s/iter. Eval: 0.0096 s/iter. Total: 0.3876 s/iter. ETA=0:10:10
[12/07 10:47:54] detectron2.evaluation.evaluator INFO: Inference done 992/2552. Dataloading: 0.0198 s/iter. Inference: 0.3578 s/iter. Eval: 0.0096 s/iter. Total: 0.3873 s/iter. ETA=0:10:04
[12/07 10:47:59] detectron2.evaluation.evaluator INFO: Inference done 1005/2552. Dataloading: 0.0198 s/iter. Inference: 0.3579 s/iter. Eval: 0.0096 s/iter. Total: 0.3873 s/iter. ETA=0:09:59
[12/07 10:48:04] detectron2.evaluation.evaluator INFO: Inference done 1019/2552. Dataloading: 0.0198 s/iter. Inference: 0.3578 s/iter. Eval: 0.0096 s/iter. Total: 0.3873 s/iter. ETA=0:09:53
[12/07 10:48:09] detectron2.evaluation.evaluator INFO: Inference done 1033/2552. Dataloading: 0.0198 s/iter. Inference: 0.3577 s/iter. Eval: 0.0096 s/iter. Total: 0.3872 s/iter. ETA=0:09:48
[12/07 10:48:15] detectron2.evaluation.evaluator INFO: Inference done 1047/2552. Dataloading: 0.0198 s/iter. Inference: 0.3576 s/iter. Eval: 0.0096 s/iter. Total: 0.3872 s/iter. ETA=0:09:42
[12/07 10:48:20] detectron2.evaluation.evaluator INFO: Inference done 1061/2552. Dataloading: 0.0198 s/iter. Inference: 0.3575 s/iter. Eval: 0.0096 s/iter. Total: 0.3870 s/iter. ETA=0:09:36
[12/07 10:48:25] detectron2.evaluation.evaluator INFO: Inference done 1075/2552. Dataloading: 0.0198 s/iter. Inference: 0.3573 s/iter. Eval: 0.0096 s/iter. Total: 0.3868 s/iter. ETA=0:09:31
[12/07 10:48:30] detectron2.evaluation.evaluator INFO: Inference done 1088/2552. Dataloading: 0.0198 s/iter. Inference: 0.3574 s/iter. Eval: 0.0096 s/iter. Total: 0.3869 s/iter. ETA=0:09:26
[12/07 10:48:36] detectron2.evaluation.evaluator INFO: Inference done 1102/2552. Dataloading: 0.0199 s/iter. Inference: 0.3572 s/iter. Eval: 0.0096 s/iter. Total: 0.3867 s/iter. ETA=0:09:20
[12/07 10:48:41] detectron2.evaluation.evaluator INFO: Inference done 1116/2552. Dataloading: 0.0198 s/iter. Inference: 0.3571 s/iter. Eval: 0.0096 s/iter. Total: 0.3866 s/iter. ETA=0:09:15
[12/07 10:48:46] detectron2.evaluation.evaluator INFO: Inference done 1130/2552. Dataloading: 0.0199 s/iter. Inference: 0.3570 s/iter. Eval: 0.0096 s/iter. Total: 0.3865 s/iter. ETA=0:09:09
[12/07 10:48:52] detectron2.evaluation.evaluator INFO: Inference done 1144/2552. Dataloading: 0.0198 s/iter. Inference: 0.3569 s/iter. Eval: 0.0096 s/iter. Total: 0.3865 s/iter. ETA=0:09:04
[12/07 10:48:57] detectron2.evaluation.evaluator INFO: Inference done 1157/2552. Dataloading: 0.0198 s/iter. Inference: 0.3569 s/iter. Eval: 0.0096 s/iter. Total: 0.3864 s/iter. ETA=0:08:59
[12/07 10:49:02] detectron2.evaluation.evaluator INFO: Inference done 1171/2552. Dataloading: 0.0198 s/iter. Inference: 0.3567 s/iter. Eval: 0.0096 s/iter. Total: 0.3862 s/iter. ETA=0:08:53
[12/07 10:49:07] detectron2.evaluation.evaluator INFO: Inference done 1184/2552. Dataloading: 0.0198 s/iter. Inference: 0.3568 s/iter. Eval: 0.0096 s/iter. Total: 0.3862 s/iter. ETA=0:08:48
[12/07 10:49:12] detectron2.evaluation.evaluator INFO: Inference done 1198/2552. Dataloading: 0.0198 s/iter. Inference: 0.3566 s/iter. Eval: 0.0096 s/iter. Total: 0.3861 s/iter. ETA=0:08:42
[12/07 10:49:17] detectron2.evaluation.evaluator INFO: Inference done 1211/2552. Dataloading: 0.0198 s/iter. Inference: 0.3568 s/iter. Eval: 0.0096 s/iter. Total: 0.3862 s/iter. ETA=0:08:37
[12/07 10:49:22] detectron2.evaluation.evaluator INFO: Inference done 1225/2552. Dataloading: 0.0198 s/iter. Inference: 0.3567 s/iter. Eval: 0.0096 s/iter. Total: 0.3861 s/iter. ETA=0:08:32
[12/07 10:49:28] detectron2.evaluation.evaluator INFO: Inference done 1239/2552. Dataloading: 0.0198 s/iter. Inference: 0.3565 s/iter. Eval: 0.0096 s/iter. Total: 0.3860 s/iter. ETA=0:08:26
[12/07 10:49:33] detectron2.evaluation.evaluator INFO: Inference done 1253/2552. Dataloading: 0.0198 s/iter. Inference: 0.3564 s/iter. Eval: 0.0096 s/iter. Total: 0.3858 s/iter. ETA=0:08:21
[12/07 10:49:38] detectron2.evaluation.evaluator INFO: Inference done 1267/2552. Dataloading: 0.0198 s/iter. Inference: 0.3563 s/iter. Eval: 0.0096 s/iter. Total: 0.3858 s/iter. ETA=0:08:15
[12/07 10:49:44] detectron2.evaluation.evaluator INFO: Inference done 1281/2552. Dataloading: 0.0198 s/iter. Inference: 0.3563 s/iter. Eval: 0.0096 s/iter. Total: 0.3858 s/iter. ETA=0:08:10
[12/07 10:49:49] detectron2.evaluation.evaluator INFO: Inference done 1294/2552. Dataloading: 0.0198 s/iter. Inference: 0.3564 s/iter. Eval: 0.0096 s/iter. Total: 0.3858 s/iter. ETA=0:08:05
[12/07 10:49:54] detectron2.evaluation.evaluator INFO: Inference done 1308/2552. Dataloading: 0.0198 s/iter. Inference: 0.3563 s/iter. Eval: 0.0096 s/iter. Total: 0.3857 s/iter. ETA=0:07:59
[12/07 10:49:59] detectron2.evaluation.evaluator INFO: Inference done 1322/2552. Dataloading: 0.0198 s/iter. Inference: 0.3562 s/iter. Eval: 0.0096 s/iter. Total: 0.3856 s/iter. ETA=0:07:54
[12/07 10:50:04] detectron2.evaluation.evaluator INFO: Inference done 1335/2552. Dataloading: 0.0198 s/iter. Inference: 0.3562 s/iter. Eval: 0.0095 s/iter. Total: 0.3856 s/iter. ETA=0:07:49
[12/07 10:50:09] detectron2.evaluation.evaluator INFO: Inference done 1348/2552. Dataloading: 0.0198 s/iter. Inference: 0.3563 s/iter. Eval: 0.0095 s/iter. Total: 0.3856 s/iter. ETA=0:07:44
[12/07 10:50:14] detectron2.evaluation.evaluator INFO: Inference done 1361/2552. Dataloading: 0.0198 s/iter. Inference: 0.3563 s/iter. Eval: 0.0095 s/iter. Total: 0.3856 s/iter. ETA=0:07:39
[12/07 10:50:34] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 10:50:34] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 10:50:34] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 10:50:34] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 10:52:03] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 10:52:04] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 10:52:04] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 10:52:04] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 10:52:23] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 10:52:23] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 10:52:23] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 10:52:23] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 10:52:23] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 10:52:23] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 10:52:23] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 10:52:23] detectron2.evaluation.evaluator INFO: Start inference on 1000 batches
[12/07 10:53:47] detectron2.evaluation.evaluator INFO: Inference done 1/1000. Dataloading: 0.0229 s/iter. Inference: 83.8863 s/iter. Eval: 0.0243 s/iter. Total: 83.9357 s/iter. ETA=23:17:31
[12/07 10:53:53] detectron2.evaluation.evaluator INFO: Inference done 11/1000. Dataloading: 0.0162 s/iter. Inference: 0.5770 s/iter. Eval: 0.0242 s/iter. Total: 0.6174 s/iter. ETA=0:10:10
[12/07 10:53:59] detectron2.evaluation.evaluator INFO: Inference done 20/1000. Dataloading: 0.0173 s/iter. Inference: 0.5599 s/iter. Eval: 0.0212 s/iter. Total: 0.5984 s/iter. ETA=0:09:46
[12/07 10:54:04] detectron2.evaluation.evaluator INFO: Inference done 29/1000. Dataloading: 0.0175 s/iter. Inference: 0.5653 s/iter. Eval: 0.0206 s/iter. Total: 0.6033 s/iter. ETA=0:09:45
[12/07 10:54:09] detectron2.evaluation.evaluator INFO: Inference done 37/1000. Dataloading: 0.0179 s/iter. Inference: 0.5699 s/iter. Eval: 0.0212 s/iter. Total: 0.6090 s/iter. ETA=0:09:46
[12/07 10:54:14] detectron2.evaluation.evaluator INFO: Inference done 46/1000. Dataloading: 0.0176 s/iter. Inference: 0.5666 s/iter. Eval: 0.0201 s/iter. Total: 0.6044 s/iter. ETA=0:09:36
[12/07 10:54:19] detectron2.evaluation.evaluator INFO: Inference done 54/1000. Dataloading: 0.0177 s/iter. Inference: 0.5701 s/iter. Eval: 0.0201 s/iter. Total: 0.6079 s/iter. ETA=0:09:35
[12/07 10:54:25] detectron2.evaluation.evaluator INFO: Inference done 63/1000. Dataloading: 0.0175 s/iter. Inference: 0.5686 s/iter. Eval: 0.0191 s/iter. Total: 0.6053 s/iter. ETA=0:09:27
[12/07 10:54:30] detectron2.evaluation.evaluator INFO: Inference done 71/1000. Dataloading: 0.0175 s/iter. Inference: 0.5724 s/iter. Eval: 0.0186 s/iter. Total: 0.6086 s/iter. ETA=0:09:25
[12/07 10:54:35] detectron2.evaluation.evaluator INFO: Inference done 80/1000. Dataloading: 0.0177 s/iter. Inference: 0.5720 s/iter. Eval: 0.0193 s/iter. Total: 0.6090 s/iter. ETA=0:09:20
[12/07 10:54:41] detectron2.evaluation.evaluator INFO: Inference done 89/1000. Dataloading: 0.0177 s/iter. Inference: 0.5693 s/iter. Eval: 0.0194 s/iter. Total: 0.6064 s/iter. ETA=0:09:12
[12/07 10:58:05] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 10:58:06] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 10:58:06] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 10:58:06] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 10:58:23] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 10:58:23] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 10:58:23] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 10:58:23] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 10:58:23] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 10:58:23] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 10:58:23] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 10:58:23] detectron2.evaluation.evaluator INFO: Start inference on 1000 batches
[12/07 10:59:39] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 10:59:39] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 10:59:39] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 10:59:39] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 11:00:05] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 11:00:05] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 11:00:05] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 11:00:05] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 11:00:05] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 11:00:05] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 11:00:05] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 11:00:05] detectron2.evaluation.evaluator INFO: Start inference on 1000 batches
[12/07 11:02:32] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 11:02:32] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 11:02:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 11:02:32] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 11:03:17] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 11:03:17] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 11:03:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 11:03:17] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 11:03:17] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 11:03:17] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 11:03:17] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 11:03:17] detectron2.evaluation.evaluator INFO: Start inference on 1000 batches
[12/07 11:08:40] detectron2 INFO: Rank of current process: 1. World size: 2
[12/07 11:08:41] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/07 11:08:41] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=2, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[12/07 11:08:41] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;245m# TEST: ("openvocab_pascal20_sem_seg_val", "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx459_sem_seg_val', 'openvocab_pascal_ctx59_sem_seg_val', 'openvocab_ade20k_panoptic_val') [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m([39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[12/07 11:09:00] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[12/07 11:09:00] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[12/07 11:09:00] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/07 11:09:00] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/07 11:09:00] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 11:09:00] detectron2.data.common INFO: Serializing 2000 elements to byte tensors and concatenating them all ...
[12/07 11:09:00] detectron2.data.common INFO: Serialized dataset takes 27.14 MiB
[12/07 11:09:00] detectron2.evaluation.evaluator INFO: Start inference on 1000 batches
