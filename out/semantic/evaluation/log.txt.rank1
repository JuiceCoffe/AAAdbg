[10/29 16:58:47] detectron2 INFO: Rank of current process: 1. World size: 4
[10/29 16:58:47] detectron2 INFO: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.14 (main, Oct 21 2025, 18:31:21) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/data/hmp/TASK/OVS/AAAdbg/detectron2/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 12.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.5.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3                      NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   550.144.03
CUDA_HOME                        /usr/local/cuda-12.4
Pillow                           9.3.0
torchvision                      0.20.1+cu121 @/data/hmp/conda_envs/dinov3/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.7.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2024.2-Product Build 20240605 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/29 16:58:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/semantic/eval_dino.yaml', resume=False, eval_only=True, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50185', opts=[])
[10/29 16:58:47] detectron2 INFO: Contents of args.config_file=configs/semantic/eval_dino.yaml:
[38;5;245m# python train_net.py --config-file configs/semantic/eval.yaml  --num-gpus 8 --eval-only[39m

[38;5;204m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./train_semantic_large.yaml[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDINOv3TXT[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMAFT_Plus[39m[38;5;186m"[39m


[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("openvocab_pascal20_sem_seg_val",[39m[38;5;141m [39m[38;5;141m"openvocab_ade20k_full_sem_seg_val",[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx459_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_pascal_ctx59_sem_seg_val',[39m[38;5;141m [39m[38;5;141m'openvocab_ade20k_panoptic_val')[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# TEST: ( 'openvocab_ade20k_panoptic_val',)[39m

[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./out/semantic/evaluation[39m

[10/29 16:59:04] detectron2.engine.defaults INFO: Model:
MAFT_Plus(
  (backbone): DINOv3TXT(
    (model): DINOTxt(
      (visual_model): VisionTower(
        (backbone): DinoVisionTransformer(
          (patch_embed): PatchEmbed(
            (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
            (norm): Identity()
          )
          (rope_embed): RopePositionEmbedding()
          (blocks): ModuleList(
            (0-23): 24 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): LinearKMaskedBias(in_features=1024, out_features=3072, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): LayerScale()
            )
          )
          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (head): Identity()
        )
        (head): VisionHead(
          (ln_final): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (blocks): ModuleList(
            (0-1): 2 x SelfAttentionBlock(
              (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): SelfAttention(
                (qkv): Linear(in_features=1024, out_features=3072, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=1024, out_features=1024, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ls1): LayerScale()
              (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (mlp): SwiGLUFFN(
                (w1): Linear(in_features=1024, out_features=2752, bias=True)
                (w2): Linear(in_features=1024, out_features=2752, bias=True)
                (w3): Linear(in_features=2752, out_features=1024, bias=True)
              )
              (ls2): LayerScale()
            )
          )
          (linear_projection): Identity()
        )
      )
      (text_model): TextTower(
        (backbone): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (dropout): Dropout(p=0.0, inplace=False)
          (blocks): ModuleList(
            (0-23): 24 x CausalSelfAttentionBlock(
              (ls1): Identity()
              (attention_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (attention): CausalSelfAttention(
                (qkv): Linear(in_features=1280, out_features=3840, bias=False)
                (proj): Linear(in_features=1280, out_features=1280, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (ffn_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (feed_forward): Mlp(
                (fc1): Linear(in_features=1280, out_features=5120, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=5120, out_features=1280, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (ls2): Identity()
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
        (head): TextHead(
          (ln_final): Identity()
          (blocks): ModuleList(
            (0): Identity()
          )
          (linear_projection): Linear(in_features=1280, out_features=2048, bias=False)
        )
      )
    )
  )
  (void_embedding): Embedding(1, 2048)
)
[10/29 16:59:04] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from  ...
[10/29 16:59:04] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[10/29 16:59:04] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[10/29 16:59:04] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/29 16:59:04] detectron2.data.common INFO: Serializing 1449 elements to byte tensors and concatenating them all ...
[10/29 16:59:04] detectron2.data.common INFO: Serialized dataset takes 1.38 MiB
[10/29 16:59:05] detectron2.evaluation.evaluator INFO: Start inference on 362 batches
[10/29 16:59:18] detectron2.evaluation.evaluator INFO: Inference done 1/362. Dataloading: 7.9787 s/iter. Inference: 5.4377 s/iter. Eval: 0.0145 s/iter. Total: 13.4334 s/iter. ETA=1:20:49
[10/29 16:59:23] detectron2.evaluation.evaluator INFO: Inference done 15/362. Dataloading: 0.0021 s/iter. Inference: 0.3393 s/iter. Eval: 0.0106 s/iter. Total: 0.3519 s/iter. ETA=0:02:02
[10/29 16:59:28] detectron2.evaluation.evaluator INFO: Inference done 30/362. Dataloading: 0.0022 s/iter. Inference: 0.3396 s/iter. Eval: 0.0103 s/iter. Total: 0.3528 s/iter. ETA=0:01:57
[10/29 16:59:34] detectron2.evaluation.evaluator INFO: Inference done 45/362. Dataloading: 0.0022 s/iter. Inference: 0.3402 s/iter. Eval: 0.0102 s/iter. Total: 0.3531 s/iter. ETA=0:01:51
[10/29 16:59:39] detectron2.evaluation.evaluator INFO: Inference done 59/362. Dataloading: 0.0022 s/iter. Inference: 0.3431 s/iter. Eval: 0.0100 s/iter. Total: 0.3556 s/iter. ETA=0:01:47
[10/29 16:59:44] detectron2.evaluation.evaluator INFO: Inference done 74/362. Dataloading: 0.0022 s/iter. Inference: 0.3423 s/iter. Eval: 0.0101 s/iter. Total: 0.3549 s/iter. ETA=0:01:42
[10/29 16:59:49] detectron2.evaluation.evaluator INFO: Inference done 89/362. Dataloading: 0.0022 s/iter. Inference: 0.3413 s/iter. Eval: 0.0098 s/iter. Total: 0.3536 s/iter. ETA=0:01:36
[10/29 16:59:54] detectron2.evaluation.evaluator INFO: Inference done 104/362. Dataloading: 0.0022 s/iter. Inference: 0.3413 s/iter. Eval: 0.0096 s/iter. Total: 0.3534 s/iter. ETA=0:01:31
[10/29 16:59:59] detectron2.evaluation.evaluator INFO: Inference done 118/362. Dataloading: 0.0022 s/iter. Inference: 0.3423 s/iter. Eval: 0.0096 s/iter. Total: 0.3543 s/iter. ETA=0:01:26
[10/29 17:00:05] detectron2.evaluation.evaluator INFO: Inference done 133/362. Dataloading: 0.0022 s/iter. Inference: 0.3416 s/iter. Eval: 0.0097 s/iter. Total: 0.3537 s/iter. ETA=0:01:21
[10/29 17:00:10] detectron2.evaluation.evaluator INFO: Inference done 147/362. Dataloading: 0.0022 s/iter. Inference: 0.3439 s/iter. Eval: 0.0096 s/iter. Total: 0.3559 s/iter. ETA=0:01:16
[10/29 17:00:15] detectron2.evaluation.evaluator INFO: Inference done 161/362. Dataloading: 0.0022 s/iter. Inference: 0.3448 s/iter. Eval: 0.0096 s/iter. Total: 0.3568 s/iter. ETA=0:01:11
