# python train_net.py --config-file configs/semantic/train_semantic_large.yaml  --num-gpus 8 

_BASE_: ../maskformer2_R50_bs16_50ep.yaml
MODEL:
  META_ARCHITECTURE: "MAFT_Plus_FreezeClipV"  # FCCLIP MAFT_Plus
  SEM_SEG_HEAD:
    NAME: "FCCLIPHead"
    NUM_CLASSES: 171
  FC_CLIP:
    CLIP_MODEL_NAME: "convnext_large_d_320"  
    CLIP_PRETRAINED_WEIGHTS: "laion2b_s29b_b131k_ft_soup" 
    EMBED_DIM: 768
    GEOMETRIC_ENSEMBLE_ALPHA: -1.
    GEOMETRIC_ENSEMBLE_BETA: -1.
  rc_weights: 0.1

INPUT:
  DATASET_MAPPER_NAME: "mask_former_semantic" # mask_former_semantic coco_panoptic_lsj
DATASETS:
  TRAIN: ("openvocab_coco_2017_train_stuff_sem_seg",)  #  openvocab_coco_2017_train_panoptic_with_sem_seg
  TEST: ("openvocab_pascal20_sem_seg_val", 'openvocab_ade20k_panoptic_val', "openvocab_ade20k_full_sem_seg_val", 'openvocab_pascal_ctx59_sem_seg_val') 

SOLVER:
  IMS_PER_BATCH: 8 # 8
  BASE_LR: 0.00005 # 0.0001
  MAX_ITER: 150000 # 295000 # 55000 

OUTPUT_DIR: ./out/semantic/MAFT_Plus_FreezeClipV_large/b8lr5e-5st150k


# TEST:
#   EVAL_PERIOD: 50